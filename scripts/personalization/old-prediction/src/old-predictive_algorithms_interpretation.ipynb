{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ded855-2c7d-4b66-941f-08baefeff998",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Evaluation\n",
    "This notebook demonstrates the interpretation and evaluation of the models (as trained in `predictive_algorithms_training.ipynb`):\n",
    "- Performance Evaluation: Comparing models based on metrics such as concordance index (C-Index), integrated Brier score (IBS), calibration error (CE), and time-dependent AUC.\n",
    "- Visualization: Generating survival curves and feature importance plots to interpret model predictions and uncover key insights.\n",
    "\n",
    "In the file `utils/settings.py` all the experiment settings can be set (e.g. OS or PFS, grouped treatments or not), then the experiment can be run in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d8fe66-6bd6-42e4-98f4-c8c1ea8068a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22badec3-1d43-48b9-bceb-30bfef7d3ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import dill\n",
    "import torch\n",
    "import nbimporter\n",
    "import shap\n",
    "\n",
    "import os\n",
    "os.chdir('/data/repos/actin-personalization/scripts/personalization/prediction')\n",
    "\n",
    "from src.models import *\n",
    "from src.data.data_processing import DataSplitter, DataPreprocessor\n",
    "from src.data.lookups import lookup_manager\n",
    "from src.utils.settings import settings\n",
    "from src.predictive_algorithms_training import get_data, plot_different_models_survival_curves\n",
    "\n",
    "preprocessor = DataPreprocessor(settings.db_config_path, settings.db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f88038-4db9-48a9-bdb7-218d5d3c4f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df, X_train, X_test, y_train, y_test, encoded_columns = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ee6cb-19af-49d3-bb78-d05e4329ea8e",
   "metadata": {},
   "source": [
    "## Model outcome & metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63289b29-954f-480e-a077-e87e5a3dca16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load models & outcomes\n",
    "The pretrained models and outcomes are stored in the Google Cloud Storage bucket: `gs://actin-personalization-models-v1/trained_models/`. \n",
    "\n",
    "To download the saved models from the bucket to the trained_models map, run the following command in your terminal:\n",
    "\n",
    "`gsutil -m cp -r gs://actin-personalization-models-v1/trained_models/./trained_models/`\n",
    "\n",
    "Make sure the trained_models folder is inside the models folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b352418-ebec-4b4d-83e1-3ce48bf2c6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model_outcomes():\n",
    "    csv_file = os.path.join(f\"{settings.save_path}\", f\"{settings.outcome}_model_outcomes.csv\")\n",
    "    \n",
    "    if os.path.exists(csv_file):\n",
    "        results_df = pd.read_csv(csv_file)\n",
    "        print(f\"Loaded model outcomes from {csv_file}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No saved outcomes found for {settings.outcome} in {settings.save_path}\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9f06e2-50cd-4e66-95c7-8b9a87e68edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_trained_model(model_name, model_class, model_kwargs={}):\n",
    "    model_file_prefix = os.path.join(settings.save_path, f\"{settings.outcome}_{model_name}\")\n",
    "    nn_file = model_file_prefix + \".pt\"\n",
    "    sk_file = model_file_prefix + \".pkl\"\n",
    "        \n",
    "    if model_name in ['CoxPH', 'RandomSurvivalForest', 'GradientBoosting', 'AalenAdditive']:\n",
    "        with open(sk_file, \"rb\") as f:\n",
    "            model = dill.load(f)\n",
    "        print(f\"Model {model_name} loaded from {sk_file}\")\n",
    "        return model\n",
    "    else:\n",
    "        model = model_class(**model_kwargs)\n",
    "    \n",
    "        state = torch.load(nn_file, map_location=torch.device('cpu'))\n",
    "        \n",
    "        model.model.net.load_state_dict(state['net_state'])\n",
    "    \n",
    "        if 'labtrans' in state:\n",
    "            model.labtrans             = state['labtrans']\n",
    "            model.model.duration_index = model.labtrans.cuts\n",
    "        \n",
    "        if 'baseline_hazards' in state:\n",
    "            model.model.baseline_hazards_ = state['baseline_hazards']\n",
    "            model.model.baseline_cumulative_hazards_ = state['baseline_cumulative_hazards']\n",
    "            \n",
    "            print(f\"Baseline hazards loaded for {model_name}.\")\n",
    "            \n",
    "        model.model.net.eval()     \n",
    "        print(f\"Model {model_name} loaded from {nn_file}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "def load_all_trained_models(X_train):\n",
    "    loaded_models = {}\n",
    "    config_mgr = ExperimentConfig(settings.json_config_file)\n",
    "    loaded_configs = config_mgr.load_model_configs()\n",
    "\n",
    "    for model_name, (model_class, model_kwargs) in loaded_configs.items():\n",
    "        print(model_name, model_class)\n",
    "        try:\n",
    "            loaded_model = load_trained_model(\n",
    "                model_name=model_name, \n",
    "                model_class=model_class, \n",
    "                model_kwargs=model_kwargs\n",
    "            )\n",
    "            loaded_models[model_name] = loaded_model\n",
    "\n",
    "            ModelTrainer._set_attention_indices(loaded_models[model_name], list(X_train.columns))\n",
    "        except:\n",
    "            print(f'Could not load: {model_name}')\n",
    "            continue\n",
    "    return loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b21db4a-eb3a-4af5-827e-337e7e497171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_outcomes = load_model_outcomes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09cb005-8968-45ae-ae28-5ba2fbf8abc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_models = load_all_trained_models(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9982662e-0f4c-4148-80fe-989a61af6bf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Metric comparison\n",
    "\n",
    "The trained models are evaluated using the following metrics:\n",
    "\n",
    "- **C-Index**: The Concordance Index measures how well the predicted survival times align with the actual outcomes. It is a measure of discrimination, indicating the model's ability to correctly rank the survival times of patients. A higher value indicates better predictive accuracy.\n",
    "\n",
    "- **Integrated Brier Score (IBS)**: This metric evaluates the accuracy of the survival probability predictions over time. It combines the squared differences between predicted and actual survival probabilities, weighted by the survival distribution. Lower values indicate better predictive performance.\n",
    "\n",
    "- **Calibration Error (CE)**: Calibration error assesses how well the predicted survival probabilities match the observed probabilities. It indicates whether the model is systematically overestimating or underestimating survival probabilities. Lower values signify better calibration.\n",
    "\n",
    "- **Area Under the Curve (AUC)**: For survival models, AUC is typically computed over a time-dependent ROC curve, reflecting the model's discrimination ability at different time points. Higher AUC values indicate better overall performance.\n",
    "\n",
    "This section visualizes the comparison of model performance metrics (C-Index, IBS, CE, AUC) for OS and PFS. The bar plots highlight the strengths and weaknesses of each model in the two prediction tasks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c5be4-028e-48a0-9904-1cf99436cf60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_holdout_metrics(df):\n",
    "    if df['holdout'].apply(lambda x: isinstance(x, str)).any():\n",
    "        df['holdout'] = df['holdout'].apply(ast.literal_eval)\n",
    "    \n",
    "    holdout_metrics = df['holdout'].apply(pd.Series)\n",
    "    holdout_metrics['Model'] = df['Model']\n",
    "    \n",
    "    return holdout_metrics\n",
    "\n",
    "def plot_all_metrics(df, holdout=True):\n",
    "    metrics = ['c_index', 'ibs', 'ce', 'auc']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for ax, metric in zip(axes, metrics):\n",
    "        sns.barplot(x='Model', y=metric, data=df, ax=ax, palette='Set1')\n",
    "        title = f\"{metric.upper()} Comparison\"\n",
    "        \n",
    "        ax.set_title(title)\n",
    "        ax.set(xlabel='Model', ylabel=metric.upper())\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        if metric in ['c_index', 'auc']:\n",
    "            ax.set_ylim(0, 1)\n",
    "        \n",
    "        min_val, max_val = df[metric].min(), df[metric].max()\n",
    "        cmap = sns.light_palette(\"#79C\", as_cmap=True)\n",
    "        for patch in ax.patches:\n",
    "            height = patch.get_height()\n",
    "            normalized = (height - min_val) / (max_val - min_val) if max_val > min_val else 0.5\n",
    "            patch.set_facecolor(cmap(0.4 + 0.8 * normalized))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ab86d-6573-4d83-8d36-8d6fbe4a89f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_all_metrics(model_outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d0bc5-3d6c-4293-912a-cdd6b5ae8393",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time-Dependent ROC-AUC\n",
    "\n",
    "This section visualizes the ROC curves and computes the AUC for survival models at specific time intervals. By evaluating the models' discriminative performance over time, we identify which models perform best at different prediction horizons.\n",
    "\n",
    "Time interval:\n",
    "- **Overall Survival (OS)**: For OS, the follow-up times in the dataset extend up to 5 years, allowing us to evaluate model performance over this longer horizon. As survival outcomes often have a broader timespan, a 5-year evaluation provides a comprehensive view of the model's ability to predict long-term survival.\n",
    "\n",
    "The ROC curves for the models are plotted for each time interval, showcasing how well the models distinguish patients at risk across the respective timeframes for OS and PFS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169551f6-ef77-4553-bb99-5dc742b2cc18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "\n",
    "def calculate_time_dependent_auc_for_models(model_dict, X_train, y_train, X_test, y_test, time_points):\n",
    "  \n",
    "    y_train_df = pd.DataFrame({'duration': y_train[settings.duration_col], 'event': y_train[settings.event_col]}, index=X_train.index)\n",
    "    y_train_struct = Surv.from_dataframe('event', 'duration', y_train_df)\n",
    "\n",
    "    y_test_df = pd.DataFrame({'duration': y_test[settings.duration_col], 'event': y_test[settings.event_col]}, index=X_test.index)\n",
    "    y_test_struct = Surv.from_dataframe('event', 'duration', y_test_df)\n",
    "\n",
    "    auc_results = {}\n",
    "\n",
    "    for model_name, model in model_dict.items():\n",
    "        if hasattr(model, \"model\") and hasattr(model.model, \"predict\"):\n",
    "            preds = model.model.predict(X_test.values.astype(\"float32\"))\n",
    "        else:\n",
    "            preds = model.predict(X_test)\n",
    "\n",
    "        if preds.ndim == 1:\n",
    "            risk_scores = preds\n",
    "        elif preds.shape[1] == 1:\n",
    "            risk_scores = preds.ravel()\n",
    "        else:\n",
    "            T = preds.shape[1]\n",
    "            desired_T = len(time_points)\n",
    "            if T == desired_T:\n",
    "                risk_scores = preds\n",
    "            elif T % desired_T == 0:\n",
    "                factor = T // desired_T\n",
    "                risk_scores = preds[:, ::factor]\n",
    "\n",
    "        auc_values, mean_auc = cumulative_dynamic_auc(y_train_struct, y_test_struct, risk_scores, time_points)\n",
    "        auc_results[model_name] = (auc_values, mean_auc)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    years = [t / 365.0 for t in time_points]\n",
    "    \n",
    "    cmap = plt.cm.get_cmap(\"tab20\", len(auc_results))\n",
    "\n",
    "    for i, (model_name, (auc_vals, mean_auc)) in enumerate(auc_results.items()):\n",
    "        plt.plot(years, auc_vals, marker='o', label=f\"{model_name} (Mean AUC={mean_auc:.3f})\", color=cmap(i))\n",
    "\n",
    "    plt.xlabel(\"Time (years)\")\n",
    "    plt.ylabel(\"Time-Dependent AUC\")\n",
    "    plt.title(settings.outcome)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return auc_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c22cabc-bdda-471c-9e2b-0daea7cc18cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_to_evaluate = {\n",
    "    \"DeepSurv\": trained_models[\"DeepSurv\"],\n",
    "    \"DeepSurv_attention\": trained_models[\"DeepSurv_attention\"],\n",
    "    \n",
    "    \"LogisticHazardModel\": trained_models[\"LogisticHazardModel\"],\n",
    "    \"LogisticHazardModel_attention\": trained_models[\"LogisticHazardModel_attention\"],\n",
    "    \n",
    "    \"DeepHitModel\": trained_models[\"DeepHitModel\"],\n",
    "    \"DeepHitModel_attention\": trained_models[\"DeepHitModel_attention\"],\n",
    "    \n",
    "    \"PCHazardModel\": trained_models[\"PCHazardModel\"],\n",
    "    \"PCHazardModel_attention\": trained_models[\"PCHazardModel_attention\"],\n",
    "    \n",
    "    \"MTLRModel\": trained_models[\"MTLRModel\"],\n",
    "    \"MTLRModel_attention\": trained_models[\"MTLRModel_attention\"],\n",
    "    \n",
    "    \"GradientBoosting\": trained_models[\"GradientBoosting\"],   \n",
    "    \"RandomSurvivalForest\": trained_models[\"RandomSurvivalForest\"],    \n",
    "}\n",
    "\n",
    "calculate_time_dependent_auc_for_models(\n",
    "    models_to_evaluate, X_train, y_train, X_test, y_test, \n",
    "    time_points=settings.time_points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d73024-50f0-4755-a20b-e8b10a8f3f97",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4ea75e-0e2a-4a1b-8d16-7b3c16f2919c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_short_names = {\n",
    "        \"ageAtMetastasisDetection\": \"Age (metastasis)\",\n",
    "        \"albumine\": \"Albumin\",\n",
    "        \"alkalinePhosphatase\": \"Alk. phosphatase\",\n",
    "        \"anorectalVergeDistanceCategory\": \"Tumor–ARV distance\",\n",
    "        \"asaClassificationPreSurgeryOrEndoscopy\": \"ASA class\",\n",
    "        \"carcinoEmbryonicAntigen\": \"CEA\",\n",
    "        \"cci\": \"CCI (score)\",\n",
    "        \"cciHasAids\": \"CCI: AIDS\",\n",
    "        \"cciHasCerebrovascularDisease\": \"CCI: Cerebrovascular disease\",\n",
    "        \"cciHasCollagenosis\": \"CCI: Collagenosis\",\n",
    "        \"cciHasCongestiveHeartFailure\": \"CCI: Heart failure\",\n",
    "        \"cciHasCopd\": \"CCI: COPD\",\n",
    "        \"cciHasDementia\": \"CCI: Dementia\",\n",
    "        \"cciHasDiabetesMellitus\": \"CCI: Diabetes\",\n",
    "        \"cciHasDiabetesMellitusWithEndOrganDamage\": \"CCI: Diabetes w/ EOD\",\n",
    "        \"cciHasHemiplegiaOrParaplegia\": \"CCI: Hemiplegia\",\n",
    "        \"cciHasLiverDisease\": \"CCI: Liver disease\",\n",
    "        \"cciHasMildLiverDisease\": \"CCI: Mild liver disease\",\n",
    "        \"cciHasMyocardialInfarct\": \"CCI: MI\",\n",
    "        \"cciHasOtherMalignancy\": \"CCI: Other malignancy\",\n",
    "        \"cciHasOtherMetastaticSolidTumor\": \"CCI: Other metastasis\",\n",
    "        \"cciHasPeripheralVascularDisease\": \"CCI: PVD\",\n",
    "        \"cciHasRenalDisease\": \"CCI: Renal disease\",\n",
    "        \"cciHasUlcerDisease\": \"CCI: Ulcer disease\",\n",
    "        \"cciNumberOfCategories\": \"CCI: # categories\",\n",
    "        \"distanceToMesorectalFasciaMm\": \"MRF distance (mm)\",\n",
    "        \"hasBrafMutation\": \"BRAF mut.\",\n",
    "        \"hasBrafV600EMutation\": \"BRAF V600E\",\n",
    "        \"hasDoublePrimaryTumor\": \"Double primary\",\n",
    "        \"hasHadPriorTumor\": \"Prior tumor\",\n",
    "        \"hasKrasG12CMutation\": \"KRAS G12C\",\n",
    "        \"hasMsi\": \"MSI\",\n",
    "        \"hasRasMutation\": \"RAS mut.\",\n",
    "        \"investigatedLymphNodesNumber\": \"# nodes (investigated)\",\n",
    "        \"lactateDehydrogenase\": \"LDH\",\n",
    "        \"leukocytesAbsolute\": \"Leukocytes\",\n",
    "        \"maximumSizeOfLiverMetastasisMm\": \"Max liver met (mm)\",\n",
    "        \"mesorectalFasciaIsClear\": \"MRF clear\",\n",
    "        \"neutrophilsAbsolute\": \"Neutrophils\",\n",
    "        \"numberOfLiverMetastases\": \"# liver mets\",\n",
    "        \"positiveLymphNodesNumber\": \"# positive nodes\",\n",
    "        \"presentedWithIleus\": \"Ileus at presentation\",\n",
    "        \"presentedWithPerforation\": \"Perforation\",\n",
    "        \"sex\": \"Sex\",\n",
    "        \"sidedness\": \"Tumor sidedness\",\n",
    "        \"stageCTNM\": \"cTNM\",\n",
    "        \"stagePTNM\": \"pTNM\",\n",
    "        \"stageTNM\": \"TNM\",\n",
    "        \"tumorDifferentiationGrade\": \"Grade\",\n",
    "        \"tumorIncidenceYear\": \"Incidence year\",\n",
    "        \"whoStatusPreTreatmentStart\": \"WHO status\",\n",
    "        \"observedOsFromMetastasisDetectionDays\": \"OS (days)\",\n",
    "\n",
    "        # Systemic treatment flags\n",
    "        \"systemicTreatmentPlan_5-FU\": \"5-FU\",\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": \"Oxaliplatin\",\n",
    "        \"systemicTreatmentPlan_irinotecan\": \"Irinotecan\",\n",
    "        \"systemicTreatmentPlan_bevacizumab\": \"Bevacizumab\",\n",
    "        \"systemicTreatmentPlan_panitumab\": \"Panitumumab\",\n",
    "        \"systemicTreatmentPlan_pembrolizumab\": \"Pembrolizumab\",\n",
    "        \"systemicTreatmentPlan_nivolumab\": \"Nivolumab\",\n",
    "\n",
    "        # Metastasis locations\n",
    "        \"metastasisLocationGroupsPriorToSystemicTreatment_BRAIN\": \"Met: Brain\",\n",
    "        \"metastasisLocationGroupsPriorToSystemicTreatment_BRONCHUS_AND_LUNG\": \"Met: Lung\",\n",
    "        \"metastasisLocationGroupsPriorToSystemicTreatment_LIVER_AND_INTRAHEPATIC_BILE_DUCTS\": \"Met: Liver\",\n",
    "        \"metastasisLocationGroupsPriorToSystemicTreatment_LYMPH_NODES\": \"Met: LN\",\n",
    "        \"metastasisLocationGroupsPriorToSystemicTreatment_OTHER\": \"Met: Other\",\n",
    "        \"metastasisLocationGroupsPriorToSystemicTreatment_PERITONEUM\": \"Met: Peritoneum\",\n",
    "\n",
    "        # Tumor types\n",
    "        \"consolidatedTumorType_CRC_ADENOCARCINOMA\": \"CRC: Adeno\",\n",
    "        \"consolidatedTumorType_CRC_MUCINOUS\": \"CRC: Mucinous\",\n",
    "        \"consolidatedTumorType_CRC_OTHER\": \"CRC: Other\",\n",
    "        \"consolidatedTumorType_CRC_SIGNET_RING_CELL\": \"CRC: Signet ring\",\n",
    "\n",
    "        # Extra mural invasion\n",
    "        \"extraMuralInvasionCategory_ABOVE_FIVE_MM\": \"EMI >5mm\",\n",
    "        \"extraMuralInvasionCategory_LESS_THAN_FIVE_MM\": \"EMI <5mm\",\n",
    "        \"extraMuralInvasionCategory_NA\": \"EMI: NA\",\n",
    "\n",
    "        # Basis of diagnosis\n",
    "        \"tumorBasisOfDiagnosis_CLINICAL_AND_DIAGNOSTIC_INVESTIGATION\": \"Dx: Clinical + diag\",\n",
    "        \"tumorBasisOfDiagnosis_CLINICAL_ONLY_INVESTIGATION\": \"Dx: Clinical only\",\n",
    "        \"tumorBasisOfDiagnosis_CYTOLOGICAL_CONFIRMATION\": \"Dx: Cytology\",\n",
    "        \"tumorBasisOfDiagnosis_HISTOLOGICAL_CONFIRMATION\": \"Dx: Histology\",\n",
    "        \"tumorBasisOfDiagnosis_HISTOLOGICAL_CONFIRMATION_METASTASES\": \"Dx: Histology (met)\",\n",
    "        \"tumorBasisOfDiagnosis_SPEC_BIOCHEMICAL_IMMUNOLOGICAL_LAB_INVESTIGATION\": \"Dx: Biochem/immuno\",\n",
    "\n",
    "        # Tumor location\n",
    "        \"tumorLocation_APPENDIX\": \"Tumor: Appendix\",\n",
    "        \"tumorLocation_ASCENDING_COLON\": \"Tumor: Asc. colon\",\n",
    "        \"tumorLocation_COECUM\": \"Tumor: Cecum\",\n",
    "        \"tumorLocation_COLON_NOS\": \"Tumor: Colon NOS\",\n",
    "        \"tumorLocation_COLON_OVERLAPPING\": \"Tumor: Overlapping\",\n",
    "        \"tumorLocation_DESCENDING_COLON\": \"Tumor: Desc. colon\",\n",
    "        \"tumorLocation_FLEXURA_HEPATICA\": \"Tumor: Hepatic flexure\",\n",
    "        \"tumorLocation_FLEXURA_LIENALIS\": \"Tumor: Splenic flexure\",\n",
    "        \"tumorLocation_OVARY\": \"Tumor: Ovary\",\n",
    "        \"tumorLocation_RECTOSIGMOID\": \"Tumor: Rectosigmoid\",\n",
    "        \"tumorLocation_RECTUM\": \"Tumor: Rectum\",\n",
    "        \"tumorLocation_SIGMOID_COLON\": \"Tumor: Sigmoid\",\n",
    "        \"tumorLocation_TRANSVERSE_COLON\": \"Tumor: Transverse\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35b869e-865b-457a-aa0f-454913834c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_effective_input(model, X_tensor: torch.Tensor) -> np.ndarray:\n",
    "    attn_layer = model.model.net.attention\n",
    "\n",
    "    x = X_tensor.clone()\n",
    "    x_gated = attn_layer._apply_gate(x)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        weights = attn_layer.attn(x_gated).cpu().numpy()[0]  \n",
    "\n",
    "    x_gated_np = x_gated.cpu().numpy()[0]\n",
    "\n",
    "    x_effective = x_gated_np * weights\n",
    "\n",
    "    return x_effective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d359b6-c147-468e-8150-77b696e41d02",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature Importance\n",
    "\n",
    "Feature importance analysis helps us identify which features most strongly influence survival predictions across various models. In this section SHAP (SHapley Additive exPlanations) is used for all models to ensure uniformity and interpretability. SHAP values provide a consistent and locally accurate measure of feature importance for individual predictions.\n",
    "\n",
    "How SHAP is used:\n",
    "- For classical models like CoxPH and Aalen Additive, SHAP values are calculated based on risk scores or cumulative hazard coefficients. Custom prediction functions are used when necessary (e.g., for Aalen Additive) to align feature importance with model-specific outputs.\n",
    "- For tree-based models like Random Survival Forest (RSF) and Gradient Boosting Survival Model (GBM), SHAP values replace traditional feature importance metrics to ensure consistency.\n",
    "- For neural network-based models like DeepSurv and DeepHit, SHAP values are derived using the model's prediction function.\n",
    "\n",
    "#### Visualization\n",
    "SHAP provides the following insights:\n",
    "- Summary Plot - Bar: Displays the average magnitude of SHAP values for each feature, indicating the overall importance of features in the model.\n",
    "- Summary Plot - Dot: Highlights the distribution of SHAP values for each feature, showing their impact across different samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d1b49-c34a-4854-9e95-eb3b829158a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nn_predict(X, model, X_train):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X, columns=X_train.columns)\n",
    "    X_tensor = X.values.astype('float32')\n",
    "    return model.model.predict(X_tensor)\n",
    "\n",
    "def custom_aalen_predict(X, model):\n",
    "    \"\"\"\n",
    "    Custom predict function for AalenAdditiveModel.\n",
    "    Aligns cumulative hazard coefficients with input features.\n",
    "    \"\"\"\n",
    "    cumulative_coefs = model.model.cumulative_hazards_\n",
    "    X = X[model.selected_features].copy()\n",
    "\n",
    "    # Interpolate coefficients at the latest time point\n",
    "    latest_coefs = cumulative_coefs.iloc[-1].values\n",
    "    \n",
    "    if len(latest_coefs) > X.shape[1]:\n",
    "        X = X.copy()\n",
    "        X.insert(0, \"Intercept\", 1.0)  \n",
    "\n",
    "    X_array = X.values\n",
    "    risk_scores = np.einsum('ij,j->i', X_array, latest_coefs)\n",
    "    return risk_scores\n",
    "\n",
    "def shap_interpret_model(model_name, model, X_train, feature_short_names, max_features=20, shap_sample=200):\n",
    "\n",
    "    X_sample = X_train.sample(min(shap_sample, len(X_train)), random_state=42)\n",
    "    \n",
    "    X_display = X_sample.rename(columns=feature_short_names)\n",
    "    display_names = list(X_display.columns)\n",
    "    \n",
    "    predict_functions = {\n",
    "        'AalenAdditive': lambda X: custom_aalen_predict(X, model),\n",
    "        'default': model.predict\n",
    "    }\n",
    "\n",
    "    if model_name == 'AalenAdditive':\n",
    "        prediction_fn = predict_functions['AalenAdditive']\n",
    "    else:\n",
    "        try:\n",
    "            model.predict(X_sample.head(1))\n",
    "            prediction_fn = predict_functions['default']\n",
    "        except:\n",
    "            prediction_fn = lambda x: nn_predict(x, model, X_train)\n",
    "\n",
    "    explainer = shap.Explainer(prediction_fn, X_sample, feature_names = display_names)\n",
    "    shap_values = explainer(X_sample)\n",
    "\n",
    "    print(f\"SHAP Summary for {model_name}:\")\n",
    "\n",
    "    if len(shap_values.values.shape) == 3: #If time dimension present\n",
    "        aggregated_shap = shap_values.values.mean(axis=1)\n",
    "        shap.summary_plot(aggregated_shap, features=X_display, plot_type=\"bar\", max_display=max_features)\n",
    "        shap.summary_plot(aggregated_shap, features=X_display, max_display=max_features)\n",
    "    else:\n",
    "        shap.summary_plot(shap_values, features=X_display, plot_type=\"bar\", max_display=max_features)\n",
    "        shap.summary_plot(shap_values, features=X_display, max_display=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1cd51e-df04-4d6c-9260-9b64a1bd3897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model_name, model_instance in models_to_evaluate.items():\n",
    "    print(f\"\\n--- Interpreting {model_name} ---\")\n",
    "    shap_interpret_model(model_name, model_instance, X_train, feature_short_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6d471-ca36-45a7-bf46-c4b57cbb2db3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a1291-e893-40f2-b3ea-49b1e88738b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_effective_feature_contributions(model, preprocessor, settings, ncr_id, max_display=20):\n",
    "    features = [\"ncrId\"] + [f for f in lookup_manager.features if f != \"ncrId\"]\n",
    "    df_all, _, _ = preprocessor.preprocess_data(features)\n",
    "    df_all = df_all.loc[:, ~df_all.columns.duplicated()].copy()\n",
    "\n",
    "    patient_df = df_all[df_all[\"ncrId\"] == ncr_id]\n",
    "    if patient_df.empty:\n",
    "        raise ValueError(f\"No patient found with ncrId={ncr_id}\")\n",
    "\n",
    "    X_input = patient_df.drop(columns=[\"ncrId\", settings.event_col, settings.duration_col])\n",
    "    feature_names = X_input.columns.tolist()\n",
    "    X_tensor = torch.tensor(X_input.values, dtype=torch.float32)\n",
    "\n",
    "    x_effective = compute_effective_input(model, X_tensor)\n",
    "\n",
    "    df_plot = pd.DataFrame({\n",
    "        \"Feature\": [feature_short_names.get(f, f) for f in feature_names],\n",
    "        \"Effective Contribution\": x_effective\n",
    "    })\n",
    "\n",
    "    df_plot = df_plot.loc[df_plot[\"Effective Contribution\"].abs() > 0]\n",
    "    df_plot = df_plot.sort_values(\"Effective Contribution\", key=abs, ascending=False).head(max_display)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df_plot, x=\"Effective Contribution\", y=\"Feature\", palette=\"viridis\")\n",
    "    plt.title(f\"Effective Input Contribution to MLP – Patient {ncr_id}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42ea3a3-f37c-4dc2-90dd-348602980f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_effective_feature_contributions(\n",
    "    model=trained_models[\"DeepSurv_attention\"],\n",
    "    preprocessor=preprocessor,\n",
    "    settings=settings,\n",
    "    ncr_id=#NcrID,\n",
    "    max_display=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8251ee4-bd28-4497-ae9a-971c9f5d2be7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17bc71-3d6e-4d81-a662-f18cfd6c3b41",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Comparison of Treatments\n",
    "In this section the predicted survival probabilities can be visualized for a single patient under different treatment scenarios. By simulating the patient receiving each available treatment, we can compare how the model predicts their survival trajectory across treatments.\n",
    "\n",
    "This analysis provides insights into the model's predictions for different treatment options, helping to identify potentially better treatment choices for the patient based on the predicted survival probabilities over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890b768-501b-4177-ad18-dddc46a65daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_treatment_combinations = {\n",
    "    \"No Treatment\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 0,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 0,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 0,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"systemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 0,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 0,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0, \n",
    "        \"systemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + oxaliplatin\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 1,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 0,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"systemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + oxaliplatin + bevacizumab\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 1,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 0,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 1,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"systemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + irinotecan\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 0,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 1,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"systemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + irinotecan + bevacizumab\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 0,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 1,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 1,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"systemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + irinotecan + panitumumab\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 0,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 1,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 1,\n",
    "        \"systemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + oxaliplatin + irinotecan\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 1,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 1,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"systemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + oxaliplatin + irinotecan + bevacizumab\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 1,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 1,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 1,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"systemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"PEMBROLIZUMAB\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 0,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 0,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 0,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"systemicTreatmentPlan_pembrolizumab\": 1,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7de122-7805-4a5a-aac8-a8df125da2ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Median Survival Time Calculation\n",
    "\n",
    " Rather than relying on the mean survival time (which can be skewed by tail behavior), we focus on the median survival time, defined as the time point t at which the survival function S(t) first drops below 0.5. This metric is often more robust in practical settings, as it is less sensitive to subtle differences in the survival curve’s tail.\n",
    "\n",
    "The median survival time is obtained by scanning the survival curve from time zero until finding the earliest point where S(t)≤0.5. If the survival probability never dips below 0.5 within the observed follow-up, the median is considered to be at (or beyond) the maximum time point in our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533477d-7dde-4aa2-bfaa-35d4c9412367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_survival_stats(time_grid: np.ndarray, surv_probs: np.ndarray):\n",
    "    \"\"\"\n",
    "    Given a survival curve sampled on `time_grid`, returns:\n",
    "      - median_months: time where S(t) ≤ 0.5, in months\n",
    "      - mean_months: area under S(t) curve (restricted mean survival), in months\n",
    "    \"\"\"\n",
    "    below = np.where(surv_probs <= 0.5)[0]\n",
    "    if below.size:\n",
    "        median_days = time_grid[below[0]]\n",
    "    else:\n",
    "        median_days = time_grid[-1]\n",
    "\n",
    "    auc_days = np.trapz(surv_probs, time_grid)\n",
    "\n",
    "    return median_days, auc_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ee1c2f-c1c3-4f52-95e8-5480a4bdb868",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Patient specific prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652935a3-e604-4dcf-91ed-6ddb3a6fc747",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "from PIL import Image\n",
    "import io\n",
    "import pymysql\n",
    "\n",
    "def compute_risk_at_horizon(model, X, horizon_days=360):\n",
    "    survival_functions = model.predict_survival_function(X)\n",
    "    return np.array([\n",
    "        1.0 - np.interp(horizon_days, sf.x, sf.y)\n",
    "        for sf in survival_functions\n",
    "    ])\n",
    "\n",
    "def create_shap_image(shap_values, max_display=15):\n",
    "    shap_values.feature_names = [\n",
    "        feature_short_names.get(name, name)\n",
    "        for name in shap_values.feature_names\n",
    "    ]\n",
    "    fig, ax = plt.subplots(figsize=(16, 5.5))\n",
    "    shap.plots.bar(shap_values, max_display=max_display, show=False)\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_clip_on(False)\n",
    "        label.set_horizontalalignment(\"right\")\n",
    "    plt.subplots_adjust(left=0.28)\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", dpi=600)\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    return Image.open(buf)\n",
    "\n",
    "def apply_treatment(df, mapping, treatment_cols, msi_flag):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[treatment_cols] = 0\n",
    "    for col, val in mapping.items():\n",
    "        if col in df_copy:\n",
    "            df_copy[col] = val\n",
    "    if \"hasMsi\" in df_copy:\n",
    "        df_copy[\"hasMsi\"] = msi_flag\n",
    "        \n",
    "    df_copy[\"hasTreatment\"] = (\n",
    "        df_copy[treatment_cols].sum(axis=1) > 0\n",
    "    ).astype(int)\n",
    "    return df_copy\n",
    "\n",
    "def plot_survival_and_shap_grid(\n",
    "    model, preprocessor, settings, patient_id: int = None, patient_row: dict = None,\n",
    "    treatment_map: dict = None, treatment_prefix=\"systemicTreatmentPlan\",\n",
    "    horizons=(12,), background_size=150, max_shap_display=15, display_stats=('median', 'auc')\n",
    "):\n",
    "    \n",
    "    raw_df = preprocessor.load_data()\n",
    "    \n",
    "    if patient_row is not None:\n",
    "        raw_df = pd.concat([raw_df, pd.DataFrame([patient_row])], ignore_index=True)\n",
    "        target_id = patient_row['ncrId']\n",
    "    else:\n",
    "        target_id = patient_id\n",
    "\n",
    "    features = [\"ncrId\"] + lookup_manager.features\n",
    "    df_all, updated_features, _ = preprocessor.preprocess_data(features, df=raw_df)\n",
    "    \n",
    "    patient_df = df_all[df_all[\"ncrId\"] == target_id]\n",
    "    if patient_df.empty:\n",
    "        raise ValueError(f\"Could not find ncrId={target_id} after preprocessing\")\n",
    "\n",
    "    X_base = patient_df[updated_features].drop(columns=[\"ncrId\"])\n",
    "    flag = lambda col: int(\n",
    "        X_base.get(col, pd.Series([0])).iloc[0]\n",
    "    )\n",
    "    \n",
    "    msi_label = \"MSI\" if flag(\"hasMsi\") else \"MSS\"\n",
    "\n",
    "    if patient_row is None:\n",
    "        with pymysql.connect(\n",
    "            read_default_file=preprocessor.db_config_path,\n",
    "            read_default_group=\"RAnalysis\",\n",
    "            db=preprocessor.db_name\n",
    "        ) as conn:\n",
    "            raw = pd.read_sql(f\"SELECT * FROM {settings.view_name}\", conn)\n",
    "        raw_patient = raw.loc[raw[\"ncrId\"] == target_id].iloc[0]\n",
    "    else:\n",
    "        raw_patient = patient_row\n",
    "\n",
    "    treatment_cols = [c for c in X_base if c.startswith(treatment_prefix)]\n",
    "    survival_fs = model.predict_survival_function(X_base)\n",
    "    time_start = max(sf.x[0] for sf in survival_fs)\n",
    "    time_end = min(sf.x[-1] for sf in survival_fs)\n",
    "    time_grid = np.linspace(time_start, time_end, 100)\n",
    "    cmap = plt.cm.tab20(np.linspace(0, 1, len(treatment_map)))\n",
    "    risks = {}\n",
    "\n",
    "    fig = plt.figure(figsize=(28, 20))\n",
    "    gs_master = gridspec.GridSpec(2, 2, height_ratios=[2.0, 4.5], width_ratios=[1.3, 1.1], figure=fig)\n",
    "    \n",
    "    ax_curve = fig.add_subplot(gs_master[0, 0])\n",
    "    for i, (label, mapping) in enumerate(treatment_map.items()):\n",
    "        X_mod = apply_treatment(X_base, mapping, treatment_cols, flag(\"hasMsi\"))\n",
    "        surv_fn, = model.predict_survival_function(X_mod)\n",
    "        surv_prob = surv_fn(time_grid)\n",
    "        \n",
    "        median_days, auc_days = compute_survival_stats(time_grid, surv_prob)\n",
    "        median_mo, auc_mo = median_days/30.44 , auc_days/30.44\n",
    "        \n",
    "        ax_curve.step(time_grid / 30.44, surv_prob, where=\"post\", color=cmap[i], label=f\"{label}  (median ≈ {median_mo:.0f} mo, auc = {auc_mo:.0f})\")\n",
    "        risks[label] = compute_risk_at_horizon(model, X_mod, 12 * 30)\n",
    "        \n",
    "    actual_time = patient_df[settings.duration_col].iloc[0] / 30.44\n",
    "    event_flag = int(patient_df[settings.event_col].iloc[0])\n",
    "    \n",
    "    ax_curve.axvline(actual_time, color=\"red\" if event_flag else \"blue\", linestyle=\"--\", label=\"Event\" if event_flag else \"Censor\")\n",
    "    ax_curve.set_title(f\"Patient {target_id} – survival curves\")\n",
    "    ax_curve.set_xlabel(\"Time (months)\")\n",
    "    ax_curve.set_ylabel(\"Survival probability\")\n",
    "    ax_curve.legend(ncol=2, fontsize=8)\n",
    "    ax_curve.grid(True)\n",
    "\n",
    "    ax_info = fig.add_subplot(gs_master[0, 1])\n",
    "    ax_info.axis(\"off\")\n",
    "    info_lines = [\n",
    "        f\"Patient {target_id}\",\n",
    "        f\"Age at metastasis detection: {raw_patient.get('ageAtMetastasisDetection','NA')}\",\n",
    "        f\"WHO status: {raw_patient.get('whoStatusPreTreatmentStart','NA')}\",\n",
    "        f\"MSI status: {msi_label}\",\n",
    "        f\"BRAF mutation: {'Yes' if flag('hasBrafMutation') else 'No'}\",\n",
    "        f\"BRAF V600E: {'Yes' if flag('hasBrafV600EMutation') else 'No'}\",\n",
    "        f\"KRAS G12C: {'Yes' if flag('hasKrasG12CMutation') else 'No'}\",\n",
    "        f\"RAS mutation: {'Yes' if flag('hasRasMutation') else 'No'}\",\n",
    "    ]\n",
    "    ax_info.text(0, 1, \"\\n\".join(info_lines), va=\"top\", ha=\"left\", fontsize=11)\n",
    "\n",
    "    is_io = lambda label: any(t in label.lower() for t in (\"pembrolizumab\", \"nivolumab\"))\n",
    "    is_chemo = lambda label: not is_io(label) and \"no treatment\" not in label.lower()\n",
    "    no_tx = next((l for l in risks if \"No Treatment\" in l),list(risks)[0])\n",
    "\n",
    "    best_io = min((l for l in risks if is_io(l)), key=risks.get)\n",
    "    best_chemo = min((l for l in risks if is_chemo(l)), key=risks.get)\n",
    "    worst = max((l for l in risks if l != no_tx), key=risks.get)\n",
    "    showcase = [no_tx, best_io, best_chemo, worst]\n",
    "\n",
    "    X_bg = df_all.drop(columns=[\"ncrId\", settings.event_col, settings.duration_col]).sample(min(background_size, len(df_all)), random_state=42)\n",
    "\n",
    "    gs_shap = gridspec.GridSpecFromSubplotSpec(len(horizons), len(showcase), subplot_spec=gs_master[1, :], hspace=0.005, wspace=0.005)\n",
    "    \n",
    "    for r, H in enumerate(horizons):\n",
    "        for c, lbl in enumerate(showcase):\n",
    "            X_mod = apply_treatment(X_base, treatment_map[lbl], treatment_cols, flag(\"hasMsi\"))\n",
    "            \n",
    "            explainer = shap.Explainer(\n",
    "                lambda x: compute_risk_at_horizon(model, x, H * 30),\n",
    "                X_bg,\n",
    "                feature_names=X_bg.columns\n",
    "            )\n",
    "            sv = explainer(X_mod)[0]\n",
    "            \n",
    "            if hasattr(model.model.net, \"attention\"):                \n",
    "                X_tensor = torch.tensor(X_mod.values, dtype=torch.float32)\n",
    "                x_effective = compute_effective_input(model, X_tensor)\n",
    "                mask = (x_effective != 0).astype(float)\n",
    "                sv.values = sv.values * mask\n",
    "             \n",
    "            sv_exp = shap.Explanation(\n",
    "                sv.values,\n",
    "                base_values=sv.base_values,\n",
    "                data=sv.data,\n",
    "                feature_names=X_bg.columns.tolist()\n",
    "            )\n",
    "            img = create_shap_image(sv_exp, max_display=max_shap_display)\n",
    "\n",
    "            ax = fig.add_subplot(gs_shap[r, c])\n",
    "            ax.imshow(img)\n",
    "            ax.axis(\"off\")\n",
    "            \n",
    "            if r == 0:\n",
    "                ax.set_title(lbl, fontsize=12)\n",
    "            if c == 0:\n",
    "                ax.annotate(\n",
    "                    f\"{H} mo\",\n",
    "                    xy=(-0.1, 0.5),\n",
    "                    xycoords=\"axes fraction\",\n",
    "                    rotation=90,\n",
    "                    va=\"center\",\n",
    "                    ha=\"right\",\n",
    "                    fontsize=11\n",
    "                )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53499f-a8eb-4822-8de5-4f18e1f02327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor(settings.db_config_path, settings.db_name)\n",
    "\n",
    "plot_survival_and_shap_grid(\n",
    "    model=trained_models[\"DeepSurv_attention\"],\n",
    "    preprocessor=preprocessor,\n",
    "    settings=settings,\n",
    "    treatment_map=valid_treatment_combinations,\n",
    "    patient_id=950861304    \n",
    ")\n",
    "\n",
    "# also possible to give a new patient row:\n",
    "# patient = {'variable1': 0, ... 'lastvariable': 1}\n",
    "# plot_survival_and_shap_grid(\n",
    "#     model=trained_models[\"DeepSurv_attention\"],\n",
    "#     preprocessor=preprocessor,\n",
    "#     settings=settings,\n",
    "#     treatment_map=valid_treatment_combinations,\n",
    "#     patient_row=patient\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac2abd-edb8-42b6-ba6c-5501e3fff062",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predicted Median Survival per Treatment\n",
    "This section compares the predicted median survival times across different systemic treatments for the full patient cohort.\n",
    "\n",
    "**Violin plots** are used to capture both the distribution and variability of median/auc survival times under each treatment scenario.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce19703-d7ee-4f43-bfd4-e5c2a7156cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_violin_data_real_treatment_with_observed(preprocessor, model, treatment_map, settings, msi_only=False):\n",
    "    df_all, _, _ = preprocessor.preprocess_data([f for f in lookup_manager.features if f != \"ncrId\"])\n",
    "    df_all = df_all.loc[:, ~df_all.columns.duplicated()].copy()\n",
    "\n",
    "    if msi_only:\n",
    "        if \"hasMsi\" not in df_all.columns:\n",
    "            raise ValueError(\"MSI feature (hasMsi) not found in dataset.\")\n",
    "        df_all = df_all[df_all[\"hasMsi\"] == 1]\n",
    "        if df_all.empty:\n",
    "            raise ValueError(\"No MSI patients found!\")\n",
    "\n",
    "    model_input_cols = df_all.drop(columns=[settings.event_col, settings.duration_col, \"ncrId\"], errors=\"ignore\").columns.tolist()\n",
    "    treatment_cols = [c for c in model_input_cols if c.startswith(\"systemicTreatmentPlan\")]\n",
    "    time_grid = np.linspace(0, 2000, 100)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for treatment_name, treatment_flags in treatment_map.items():\n",
    "        mask = np.ones(len(df_all), dtype=bool)\n",
    "        for drug_flag, expected_val in treatment_flags.items():\n",
    "            if drug_flag in df_all.columns:\n",
    "                mask &= (df_all[drug_flag] == expected_val)\n",
    "\n",
    "        selected_patients = df_all[mask]\n",
    "\n",
    "        if selected_patients.empty:\n",
    "            print(f\"Skipping {treatment_name}: no patients found.\")\n",
    "            continue\n",
    "\n",
    "        for _, row in selected_patients.iterrows():\n",
    "            row_input = row[model_input_cols]\n",
    "            row_df = pd.DataFrame([row_input])\n",
    "\n",
    "            try:\n",
    "                surv_fn, = model.predict_survival_function(row_df)\n",
    "                surv_prob = surv_fn(time_grid)\n",
    "                median_days_predicted, auc_days_predicted = compute_survival_stats(time_grid, surv_prob)\n",
    "                \n",
    "                # median_predicted = compute_median_survival(model, row_df, time_grid)\n",
    "                days_observed = row[settings.duration_col]\n",
    "                results.append({\n",
    "                    \"treatment\": treatment_name,\n",
    "                    \"predicted_median_survival\": median_days_predicted,\n",
    "                    \"predicted_auc_survival\": auc_days_predicted,\n",
    "                    \"observed_survival\": days_observed\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping patient in {treatment_name} due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def plot_predicted_and_observed_violin(df_violin, type_days = 'median'):\n",
    "    plt.figure(figsize=(18, 7))\n",
    "\n",
    "    if type_days == 'median':\n",
    "        data = df_violin.melt(id_vars=\"treatment\", \n",
    "                                value_vars=[\"predicted_median_survival\", \"observed_survival\"], \n",
    "                                var_name=\"Type\", value_name=\"Survival\")\n",
    "    else: \n",
    "        data = df_violin.melt(id_vars=\"treatment\", \n",
    "                                value_vars=[\"predicted_auc_survival\", \"observed_survival\"], \n",
    "                                var_name=\"Type\", value_name=\"Survival\")\n",
    "   \n",
    "    sns.violinplot(\n",
    "        data=data,\n",
    "        x=\"treatment\",\n",
    "        y=\"Survival\",\n",
    "        hue=\"Type\",\n",
    "        split=True,\n",
    "        inner=\"quartile\"\n",
    "    )\n",
    "\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Survival Time (days)\")\n",
    "    plt.title(\"Predicted vs Observed Survival per Treatment\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.legend(title=\"Type\", loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce8925-ee07-471b-94f4-0a7683b9794b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_violin = generate_violin_data_real_treatment_with_observed(\n",
    "    preprocessor,\n",
    "    trained_models[\"DeepSurv_attention\"],\n",
    "    valid_treatment_combinations,\n",
    "    settings,\n",
    "    msi_only=True\n",
    ")\n",
    "\n",
    "plot_predicted_and_observed_violin(df_violin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d276a-8cfb-44d1-b28d-cd8d7f2e26af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_predicted_and_observed_violin(df_violin, \n",
    "    type_days = 'auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18265fe9-3fe1-4d67-9f7a-9ecd28f36ed1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Treatment-Specific Time-Dependent AUCs\n",
    "To further evaluate model discrimination, we compute time-dependent AUCs for survival prediction within each treatment subgroup.\n",
    "- AUCs are calculated at 1, 2, 3, 4, and 5 years post-treatment.\n",
    "- Treatment groups with fewer than 30 patients were excluded to ensure statistical reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d237c4-477c-4249-b6e4-20b643fe6d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "\n",
    "def compute_time_dependent_auc_real_treatment(\n",
    "    model, preprocessor, settings, treatment_map, times_in_days\n",
    "):\n",
    "    df_all, _, _ = preprocessor.preprocess_data(\n",
    "        [f for f in lookup_manager.features if f != \"ncrId\"]\n",
    "    )\n",
    "    df_all = df_all.loc[:, ~df_all.columns.duplicated()].copy()\n",
    "\n",
    "    drop_cols = [settings.event_col, settings.duration_col, \"ncrId\"]\n",
    "    input_cols = [c for c in df_all.columns if c not in drop_cols]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, flags in treatment_map.items():\n",
    "        mask = np.ones(len(df_all), dtype=bool)\n",
    "        for df, val in flags.items():\n",
    "            if df in df_all:\n",
    "                mask &= (df_all[df] == val)\n",
    "        sel = df_all[mask]\n",
    "        n = len(sel)\n",
    "        if n < 30:\n",
    "            print(f\"Skipping {name}: only {n} patients\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Computing AUCs for {name} on {n} patients…\")\n",
    "\n",
    "        y_df = sel[[settings.event_col, settings.duration_col]]\n",
    "        y_struct = Surv.from_dataframe(\n",
    "            settings.event_col, settings.duration_col, y_df\n",
    "        )\n",
    "\n",
    "        min_t = y_df[settings.duration_col].min()\n",
    "        max_t = y_df[settings.duration_col].max()\n",
    "        times = [t for t in times_in_days if min_t <= t <= max_t]\n",
    "        if not times:\n",
    "            print(f\"  no valid times in [{min_t:.0f},{max_t:.0f}]\")\n",
    "            continue\n",
    "\n",
    "        X = sel[input_cols]\n",
    "        surv_fns = model.predict_survival_function(X)\n",
    "\n",
    "        surv_mat = np.vstack([\n",
    "            np.interp(times, fn.x, fn.y) for fn in surv_fns\n",
    "        ])  \n",
    "        \n",
    "        risk_mat = 1 - surv_mat\n",
    "        aucs, _ = cumulative_dynamic_auc(y_struct, y_struct, risk_mat, np.array(times))\n",
    "        \n",
    "        col_names = [f\"AUC_{int(t/365)}yr\" for t in times]\n",
    "        results[name] = dict(zip(col_names, aucs))\n",
    "\n",
    "    return pd.DataFrame(results).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713868c-69e5-448e-ac14-c83cf0b3ea41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auc_per_treatment = compute_time_dependent_auc_real_treatment(\n",
    "    trained_models[\"DeepSurv_attention\"],\n",
    "    preprocessor,\n",
    "    settings,\n",
    "    valid_treatment_combinations,\n",
    "    times_in_days=[365, 730, 1095, 1460, 1825]  # 1,2,3,4,5 years\n",
    ")\n",
    "\n",
    "print(auc_per_treatment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db8510c-93be-4546-b562-f6b611ebe8f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predicted vs Observed\n",
    "\n",
    "To check that our model does **more than spit out the same prognosis for every patient**, we plot the **predicted median survival (in days)** against the **actually observed survival time** for each individual.\n",
    "\n",
    "> **Why not predict the exact number of days?**  \n",
    "> Predicting a precise survival day is extremely difficult—many clinical and biological factors that affect outcome are not (or cannot be) captured in the registry.  \n",
    "> That is exactly why we focus on *survival probabilities* (or the median of a full survival curve) instead of a single “day‑of‑death” estimate.  \n",
    "> Consequently, comparing the model’s *median* to the *exact* observed day is not a perfectly fair yard‑stick—but it is still a useful sanity check.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2643bac9-b1c3-41a7-bcc6-10dcc9ca04ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def plot_predicted_vs_observed_hexbin(\n",
    "    model,\n",
    "    preprocessor,\n",
    "    settings,\n",
    "    *,\n",
    "    max_observed_days: int,\n",
    "    metric: str = \"median\",\n",
    "    figsize=(6,6),\n",
    "    gridsize: int = 60,\n",
    "    cmap: str = \"Oranges\",\n",
    "    bins: str = \"log\",\n",
    "    show_fit: bool = False, \n",
    "    print_errors: bool = True\n",
    "):\n",
    "    \n",
    "    feats = [\"ncrId\"] + [f for f in lookup_manager.features if f != \"ncrId\"]\n",
    "    df_all, _, _ = preprocessor.preprocess_data(feats)\n",
    "    df_all = df_all.loc[:, ~df_all.columns.duplicated()]\n",
    "\n",
    "    X = df_all.drop(columns=[\"ncrId\", settings.event_col, settings.duration_col])\n",
    "    times_obs = df_all[settings.duration_col].values\n",
    "\n",
    "    sfs = model.predict_survival_function(X)\n",
    "    metrics_pred = []\n",
    "    for sf in sfs:\n",
    "        time_grid = sf.x\n",
    "        surv_probs = sf.y\n",
    "        median_days, auc_days = compute_survival_stats(time_grid, surv_probs)\n",
    "        if metric == \"median\":\n",
    "            metrics_pred.append(median_days)\n",
    "        elif metric == \"auc\":\n",
    "            metrics_pred.append(auc_days)\n",
    "        else:\n",
    "            raise ValueError(\"metric must be 'median' or 'auc'\")\n",
    "            \n",
    "    metrics_pred = np.array(metrics_pred)\n",
    "\n",
    "    mask = times_obs <= max_observed_days\n",
    "    tobs = times_obs[mask]\n",
    "    tpred = metrics_pred[mask]\n",
    "    \n",
    "    if print_errors:\n",
    "        mae  = mean_absolute_error(tobs, tpred)\n",
    "        rmse = np.sqrt(mean_squared_error(tobs, tpred))\n",
    "        print(f\"{metric.upper()} prediction error (days):\")\n",
    "        print(f\"  MAE  = {mae:.1f}\")\n",
    "        print(f\"  RMSE = {rmse:.1f}\")\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=110)\n",
    "    ax.plot([0, max_observed_days], [0, max_observed_days],\n",
    "            ls=\":\", color=\"black\")\n",
    "    hb = ax.hexbin(\n",
    "        tobs, tpred,\n",
    "        gridsize=gridsize,\n",
    "        cmap=cmap,\n",
    "        bins=bins\n",
    "    )\n",
    "    fig.colorbar(hb, ax=ax, label=f\"{bins} count\")\n",
    "\n",
    "    if show_fit:\n",
    "        valid = ~np.isnan(tpred)\n",
    "        if valid.sum() > 1:\n",
    "            coeffs = np.polyfit(tobs[valid], tpred[valid], 1)\n",
    "            xfit = np.linspace(0, max_observed_days, 100)\n",
    "            ax.plot(xfit, np.polyval(coeffs, xfit),\n",
    "                    ls=\"--\", color=\"tab:orange\")\n",
    "\n",
    "    ax.set_xlabel(\"Observed survival (days)\")\n",
    "    ax.set_ylabel(\"Predicted median (days)\")\n",
    "    ax.set_title(f\"Pred vs Obs (hexbin, ≤ {max_observed_days}d, metric={metric})\")\n",
    "    ax.set_xlim(0, max_observed_days)\n",
    "    ax.set_ylim(0, 1200)\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.grid(True, ls=\":\", lw=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb5b142-619c-408d-82aa-4af1e6eb8a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_predicted_vs_observed_hexbin(\n",
    "    model              = trained_models[\"DeepSurv_attention\"],\n",
    "    preprocessor       = preprocessor,\n",
    "    settings           = settings,\n",
    "    max_observed_days  = 365,   \n",
    "    metric             = \"median\",\n",
    "    gridsize           = 80,         \n",
    "    bins               = \"log\",      \n",
    "    show_fit           = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d81d0-ed08-4de5-bb95-eddad717c521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_predicted_vs_observed_hexbin(\n",
    "    model              = trained_models[\"DeepHitModel_attention\"],\n",
    "    preprocessor       = preprocessor,\n",
    "    settings           = settings,\n",
    "    max_observed_days  = 365,         \n",
    "    metric             = \"auc\",\n",
    "    gridsize           = 80,         \n",
    "    bins               = \"log\",      \n",
    "    show_fit           = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722c7f4e-5b65-4ef0-8bc3-a6329215c8ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model prediction: No Treatment\n",
    "In this section, we aim to understand how well our model identifies patients for whom \"no treatment\" might not be worse than receiving treatment. We do this by comparing model predictions to actual observed outcomes.\n",
    "\n",
    "Clinical intuition—and data—tell us that untreated patients generally have worse outcomes. Yet our model occasionally predicts that no treatment could be among the better options. We want to:\n",
    "\n",
    "- Verify how often the model makes this prediction.\n",
    "- Compare it to actual outcomes using patient survival.\n",
    "- Understand for which patients the model is right (or wrong).\n",
    "\n",
    "We bidirectionally match treated and untreated patients. For each patient (treated or untreated), match to nearest neighbor in opposite group and compare observed survival (OS). Each match is only counted once — no double-counting.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9a940-25e5-469d-ac41-9cdee7f4f72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Circle\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def count_no_treatment_rankings(\n",
    "    model, preprocessor, settings, treatment_map, horizon_days=365\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compute per-patient ranking of 'No Treatment' against other treatments.\"\"\"\n",
    "    df_raw = preprocessor.load_data()\n",
    "    features = [\"ncrId\"] + lookup_manager.features\n",
    "    df_all, updated_features, _ = preprocessor.preprocess_data(features, df=df_raw)\n",
    "    treatment_cols = [c for c in updated_features if c.startswith(\"systemicTreatmentPlan\")]\n",
    "\n",
    "    records = []\n",
    "    for pid in df_all[\"ncrId\"].unique():\n",
    "        row = df_all[df_all[\"ncrId\"] == pid]\n",
    "        X_base = row[updated_features].drop(columns=[\"ncrId\"])\n",
    "        msi_flag = int(X_base.get(\"hasMsi\", pd.Series([0])).iloc[0])\n",
    "        risk_scores = {\n",
    "            label: compute_risk_at_horizon(model, \n",
    "                   apply_treatment(X_base, mapping, treatment_cols, msi_flag), horizon_days)[0]\n",
    "            for label, mapping in treatment_map.items()\n",
    "        }\n",
    "        no_tx = risk_scores.get(\"No Treatment\")\n",
    "        if no_tx is not None:\n",
    "            worse_count = sum(1 for l, r in risk_scores.items() if l != \"No Treatment\" and r > no_tx)\n",
    "            records.append({\n",
    "                \"ncrId\": pid,\n",
    "                \"treatments_worse\": worse_count\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "def compare_matched_os_bidirectional(preprocessor, settings, lookup_manager, n_neighbors=5):\n",
    "   \n",
    "    raw = preprocessor.load_data()\n",
    "    features = [\"ncrId\"] + lookup_manager.features\n",
    "    df_all, updated_features, _ = preprocessor.preprocess_data(features, df=raw)\n",
    "    \n",
    "    treated = df_all[df_all[\"hasTreatment\"] == 1].copy()\n",
    "    untreated = df_all[df_all[\"hasTreatment\"] == 0].copy()\n",
    "\n",
    "    feature_cols = [\n",
    "        col for col in updated_features\n",
    "        if pd.api.types.is_numeric_dtype(df_all[col])\n",
    "        and col not in [settings.duration_col, settings.event_col, \"hasTreatment\"]\n",
    "    ]\n",
    "\n",
    "    nn_untreated = NearestNeighbors(n_neighbors=n_neighbors).fit(untreated[feature_cols])\n",
    "    nn_treated = NearestNeighbors(n_neighbors=n_neighbors).fit(treated[feature_cols])\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    distances, indices = nn_untreated.kneighbors(treated[feature_cols])\n",
    "    for i, tr in treated.reset_index(drop=True).iterrows():\n",
    "        ut_idx = indices[i][0]\n",
    "        ut = untreated.iloc[ut_idx]\n",
    "        if tr[\"ncrId\"] < ut[\"ncrId\"]: \n",
    "            matches.append({\n",
    "                \"ncrId_patient\": tr[\"ncrId\"],\n",
    "                \"os_patient\": tr[settings.duration_col],\n",
    "                \"ncrId_match\": ut[\"ncrId\"],\n",
    "                \"os_match\": ut[settings.duration_col],\n",
    "                \"patient_treated\": True\n",
    "            })\n",
    "\n",
    "    distances, indices = nn_treated.kneighbors(untreated[feature_cols])\n",
    "    for i, ut in untreated.reset_index(drop=True).iterrows():\n",
    "        tr_idx = indices[i][0]\n",
    "        tr = treated.iloc[tr_idx]\n",
    "        if ut[\"ncrId\"] < tr[\"ncrId\"]:  # prevent duplicate pairs\n",
    "            matches.append({\n",
    "                \"ncrId_patient\": ut[\"ncrId\"],\n",
    "                \"os_patient\": ut[settings.duration_col],\n",
    "                \"ncrId_match\": tr[\"ncrId\"],\n",
    "                \"os_match\": tr[settings.duration_col],\n",
    "                \"patient_treated\": False\n",
    "            })\n",
    "\n",
    "    df_matches = pd.DataFrame(matches)\n",
    "    df_matches[\"patient_not_worse\"] = df_matches[\"os_patient\"] > df_matches[\"os_match\"]\n",
    "    \n",
    "    not_worse_ids = set(df_matches.loc[df_matches[\"patient_not_worse\"], \"ncrId_patient\"])\n",
    "\n",
    "    return df_matches, not_worse_ids\n",
    "\n",
    "def compute_overlap_statistics_bidirectional(\n",
    "    model, preprocessor, settings, lookup_manager, treatment_map, n_neighbors=1, horizon_days=365\n",
    "):\n",
    "    df_pred = count_no_treatment_rankings(\n",
    "        model, preprocessor, settings, treatment_map, horizon_days\n",
    "    )\n",
    "    df_all, *_ = preprocessor.preprocess_data([\"ncrId\"] + lookup_manager.features)\n",
    "    pred_set = set(df_pred.loc[df_pred[\"treatments_worse\"] > 0, \"ncrId\"])\n",
    "    pred_count = len(pred_set)\n",
    "    pred_total = df_all.shape[0]\n",
    "\n",
    "    df_matches, actual_set = compare_matched_os_bidirectional(\n",
    "        preprocessor, settings, lookup_manager, n_neighbors\n",
    "    )\n",
    "    actual_count = len(actual_set)\n",
    "    actual_total = df_all.shape[0]\n",
    "\n",
    "    overlap = actual_set & pred_set\n",
    "    overlap_count = len(overlap)\n",
    "\n",
    "    return {\n",
    "        \"actual\":    {\"total\": actual_total,    \"count\": actual_count},\n",
    "        \"predicted\": {\"total\": pred_total,      \"count\": pred_count},\n",
    "        \"overlap\":   {\"count\": overlap_count}\n",
    "    }\n",
    "\n",
    "def plot_area_venn(stats):\n",
    "    actual = stats[\"actual\"][\"count\"]\n",
    "    predicted = stats[\"predicted\"][\"count\"]\n",
    "    overlap = stats[\"overlap\"][\"count\"]\n",
    "    actual_only = actual - overlap\n",
    "    predicted_only = predicted - overlap\n",
    "\n",
    "    r1 = np.sqrt(actual / np.pi)\n",
    "    r2 = np.sqrt(predicted / np.pi)\n",
    "\n",
    "    def intersection_area(r0, r1, d):\n",
    "        if d >= r0 + r1: return 0\n",
    "        if d <= abs(r1 - r0): return np.pi * min(r0, r1)**2\n",
    "        r0sq, r1sq, dsq = r0*r0, r1*r1, d*d\n",
    "        alpha = np.arccos((dsq + r0sq - r1sq) / (2*d*r0))\n",
    "        beta  = np.arccos((dsq + r1sq - r0sq) / (2*d*r1))\n",
    "        return (r0sq*alpha + r1sq*beta\n",
    "                - 0.5*np.sqrt((-d+r0+r1)*(d+r0-r1)*(d-r0+r1)*(d+r0+r1)))\n",
    "\n",
    "    lo, hi = abs(r1 - r2), r1 + r2\n",
    "    for _ in range(50):\n",
    "        mid = (lo + hi) / 2\n",
    "        if intersection_area(r1, r2, mid) < overlap:\n",
    "            hi = mid\n",
    "        else:\n",
    "            lo = mid\n",
    "    d = (lo + hi) / 2\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    ax.add_patch(Circle((0,0),   r1, color='skyblue', alpha=0.5))\n",
    "    ax.add_patch(Circle((d,0),   r2, color='salmon',  alpha=0.5))\n",
    "    ax.text(-r1*0.3, 0, str(actual_only), ha='center', va='center', fontsize=12)\n",
    "    ax.text(d+r2*0.3,0, str(predicted_only), ha='center', va='center', fontsize=12)\n",
    "    ax.text(d/2,      0, str(overlap),      ha='center', va='center', fontsize=12, color='white')\n",
    "    ax.text(0,   r1+2, f\"Actual Not Worse\\n(n={actual})\", ha='center', va='bottom', fontsize=13)\n",
    "    ax.text(d,   r2+2, f\"Predicted Not Worse\\n(n={predicted})\", ha='center', va='bottom', fontsize=13)\n",
    "    ax.set_xlim(-r1*1.2, d+r2*1.2)\n",
    "    ax.set_ylim(-max(r1,r2)*1.2, max(r1,r2)*1.2 + 2.5)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44504ae-bac1-4f55-9df1-90f9be6c2dad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats = compute_overlap_statistics_bidirectional(\n",
    "    trained_models['DeepSurv_attention'],\n",
    "    preprocessor, settings, lookup_manager, valid_treatment_combinations,\n",
    "    n_neighbors=1, horizon_days=365\n",
    ")\n",
    "\n",
    "print(f\"Actual fraction not worse:    {stats['actual']['count']}/{stats['actual']['total']} \"\n",
    "      f\"= {stats['actual']['count']/stats['actual']['total']:.1%}\")\n",
    "print(f\"Predicted fraction not worse: {stats['predicted']['count']}/{stats['predicted']['total']} \"\n",
    "      f\"= {stats['predicted']['count']/stats['predicted']['total']:.1%}\")\n",
    "\n",
    "plot_area_venn(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75e6028-2ee9-40d2-967a-3ed0a55d772b",
   "metadata": {},
   "source": [
    "#### Feature differences in untreated patients who survive longer\n",
    "In this section, we explore why some untreated patients survive longer than expected—both according to the model and in real-world observations.\n",
    "To do so, we analyze which patient features are associated with better survival outcomes without systemic treatment. Specifically, we look at:\n",
    "\n",
    "- Patients the model predicts will do better without treatment.\n",
    "- Patients who actually did better than their matched treated counterparts.\n",
    "\n",
    "We compare these \"not worse\" patients to other untreated patients who did fare worse, using two strategies:\n",
    "\n",
    "1. **Standardized Mean Differences (SMD)**:\n",
    "    This helps us understand which features differ the most between untreated patients who do better and those who do not. We compute SMDs both for *model-predicted* and *actually observed* \"not worse\" patients (via matched survival comparison)\n",
    "\n",
    "2. **Paired Feature Differences vs. Matched Treated Patients**:\n",
    "    For untreated patients who survived longer than their matched treated peers, we look at average differences in feature values compared to those treated patients. This gives insight into what makes some untreated patients truly exceptional.\n",
    "\n",
    "The goal is to uncover whether certain biological, clinical, or demographic characteristics help explain why some patients might not need systemic therapy—and whether the model is learning these patterns or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b0c85-8448-4ae7-b287-fe1814fdf341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_untreated_feature_differences(\n",
    "    model,\n",
    "    preprocessor,\n",
    "    settings,\n",
    "    lookup_manager,\n",
    "    treatment_map,\n",
    "    n_neighbors: int = 5,\n",
    "    horizon_days: int = 365\n",
    "):\n",
    "    df_pred = count_no_treatment_rankings(model, preprocessor, settings, treatment_map, horizon_days)\n",
    "    pred_not_worse = set(df_pred.loc[df_pred[\"treatments_worse\"] > 0, \"ncrId\"])\n",
    "\n",
    "    df_matches, actual_not_worse = compare_matched_os_bidirectional(\n",
    "        preprocessor, settings, lookup_manager, n_neighbors\n",
    "    )\n",
    "\n",
    "    features = [\"ncrId\"] + lookup_manager.features\n",
    "    df_all, updated_features, _ = preprocessor.preprocess_data(features)\n",
    "    unt = df_all[df_all[\"hasTreatment\"] == 0].copy()\n",
    "    unt[\"actual_not_worse\"] = unt[\"ncrId\"].isin(actual_not_worse)\n",
    "    unt[\"pred_not_worse\"]   = unt[\"ncrId\"].isin(pred_not_worse)\n",
    "\n",
    "    num_feats = [\n",
    "        col for col in updated_features\n",
    "        if pd.api.types.is_numeric_dtype(df_all[col])\n",
    "        and col not in [settings.duration_col, settings.event_col, \"hasTreatment\", 'ncrId']\n",
    "    ]\n",
    "\n",
    "    def smd(a, b):\n",
    "        m1, m2 = a.mean(), b.mean()\n",
    "        s1, s2 = a.std(ddof=1), b.std(ddof=1)\n",
    "        pooled = np.sqrt((s1*s1 + s2*s2) / 2)\n",
    "        return (m1 - m2) / pooled\n",
    "\n",
    "    grp_true  = unt.loc[unt[\"actual_not_worse\"], num_feats]\n",
    "    grp_false = unt.loc[~unt[\"actual_not_worse\"], num_feats]\n",
    "    smd_actual = {f: smd(grp_true[f], grp_false[f]) for f in num_feats}\n",
    "    df_smd_actual = (\n",
    "        pd.DataFrame.from_dict(smd_actual, orient=\"index\", columns=[\"SMD\"])\n",
    "          .assign(absSMD=lambda df: df[\"SMD\"].abs())\n",
    "          .sort_values(\"absSMD\", ascending=False)\n",
    "    )\n",
    "\n",
    "    grp_true  = unt.loc[unt[\"pred_not_worse\"], num_feats]\n",
    "    grp_false = unt.loc[~unt[\"pred_not_worse\"], num_feats]\n",
    "    smd_pred = {f: smd(grp_true[f], grp_false[f]) for f in num_feats}\n",
    "    df_smd_pred = (\n",
    "        pd.DataFrame.from_dict(smd_pred, orient=\"index\", columns=[\"SMD\"])\n",
    "          .assign(absSMD=lambda df: df[\"SMD\"].abs())\n",
    "          .sort_values(\"absSMD\", ascending=False)\n",
    "    )\n",
    "\n",
    "    pairs = df_matches.query(\"patient_treated == False and patient_not_worse\")\n",
    "    left = pairs[[\"ncrId_patient\", \"ncrId_match\"]].rename(columns={\"ncrId_patient\": \"ncrId\"})\n",
    "    df_pair = (\n",
    "        left\n",
    "        .merge(df_all[[\"ncrId\"] + num_feats], on=\"ncrId\")\n",
    "        .merge(\n",
    "            df_all[[\"ncrId\"] + num_feats].set_index(\"ncrId\"),\n",
    "            left_on=\"ncrId_match\", right_index=True,\n",
    "            suffixes=(\"_unt\", \"_tr\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    delta = {\n",
    "        f: (df_pair[f+\"_unt\"] - df_pair[f+\"_tr\"]).mean()\n",
    "        for f in num_feats\n",
    "    }\n",
    "    df_delta = (\n",
    "        pd.DataFrame.from_dict(delta, orient=\"index\", columns=[\"Mean_Untreated−Treated\"])\n",
    "          .assign(absDiff=lambda df: df[\"Mean_Untreated−Treated\"].abs())\n",
    "          .sort_values(\"absDiff\", ascending=False)\n",
    "    )\n",
    "\n",
    "    return df_smd_actual, df_smd_pred, df_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3dd29-22c1-414a-85dd-c86e88243627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_smd_actual, df_smd_pred, df_delta = analyze_untreated_feature_differences(\n",
    "    trained_models[\"DeepSurv_attention\"],\n",
    "    preprocessor, settings, lookup_manager,\n",
    "    valid_treatment_combinations,\n",
    "    n_neighbors=5\n",
    ")\n",
    "\n",
    "print(\"Actual SMDs:\")\n",
    "display(df_smd_actual.head(10))\n",
    "\n",
    "print(\"Predicted SMDs:\")\n",
    "display(df_smd_pred.head(10))\n",
    "\n",
    "print(\"Mean Pairwise Deltas:\")\n",
    "display(df_delta.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd4d254-e015-4259-bdce-d6c090a73fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_smds(df_smd, title, number_of_features = 10):\n",
    "\n",
    "    df_smd.index = [feature_short_names.get(f, f) for f in df_smd.index]\n",
    "\n",
    "    df_top = df_smd.head(number_of_features).sort_values(\"SMD\")\n",
    "    colors = ['salmon' if v < 0 else 'skyblue' for v in df_top[\"SMD\"]]\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.barh(df_top.index, df_top[\"SMD\"], color=colors)\n",
    "    plt.axvline(0, color='black', linewidth=0.8)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Standardized Mean Difference\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_smds(df_smd_actual, \"Top features distinguishing actual not-worse untreated patients\")\n",
    "plot_smds(df_smd_pred,   \"Top features driving model predictions for not-worse untreated patients\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b71f1ee-ae1f-41d9-8e16-5c139142856b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Classification-Based Evaluation of Survival Models\n",
    "\n",
    "Survival models typically predict a **survival curve** over time. However, in many clinical situations, we may want a simpler answer to the question:\n",
    "\n",
    "> *\"Will this patient survive at least 1 year?\"*\n",
    "\n",
    "To evaluate this, we reframe survival prediction as a **binary classification task**:\n",
    "\n",
    "- Patients who survive beyond a defined time horizon (e.g. 365 days) are labeled **positive**.\n",
    "- Patients who die **before** that horizon are labeled **negative**.\n",
    "- Patients censored **before** the horizon are **excluded** from evaluation (since their true outcome is unknown).\n",
    "\n",
    "We use the model's survival probability at the chosen horizon as a **pseudo-probability** of surviving:\n",
    "- If the model predicts a survival probability > *certain threshold* at 365 days → predict *survives*.\n",
    "- Otherwise → predict *does not survive*.\n",
    "\n",
    "For each model, we compute classic classification metrics: **Accuracy**, **Precision**, **Recall**, **F1-score**, **ROC AUC**\n",
    "\n",
    "These metrics provide an intuitive understanding of how well the model distinguishes between short-term and long-term survivors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9356f523-6fd0-4b5f-8363-2c5f1fd7a212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score,\n",
    "    recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "def evaluate_survival_as_classifier(\n",
    "    models: dict,\n",
    "    preprocessor,\n",
    "    settings,\n",
    "    horizon_days: int = 365,\n",
    "    threshold: float = 0.5\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    feats = [\"ncrId\"] + [f for f in lookup_manager.features if f != \"ncrId\"]\n",
    "    df_all, _, _ = preprocessor.preprocess_data(feats)\n",
    "    df_all = df_all.loc[:, ~df_all.columns.duplicated()].copy()\n",
    "\n",
    "    durations = df_all[settings.duration_col].values\n",
    "    events    = df_all[settings.event_col].astype(bool).values\n",
    "\n",
    "    mask_known = ~((durations <= horizon_days) & (~events))\n",
    "    durations = durations[mask_known]\n",
    "    events    = events[mask_known]\n",
    "    \n",
    "    y_true = durations > horizon_days\n",
    "\n",
    "    X = df_all.drop(columns=[\"ncrId\", settings.duration_col, settings.event_col])\n",
    "    X = X.iloc[mask_known]\n",
    "\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        surv_funcs = model.predict_survival_function(X)\n",
    "        probs = np.array([fn(horizon_days) for fn in surv_funcs])\n",
    "\n",
    "        y_pred = probs > threshold\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, probs)\n",
    "        except ValueError:\n",
    "            auc = np.nan\n",
    "\n",
    "        results[name] = {\n",
    "            \"accuracy\":  acc,\n",
    "            \"precision\": prec,\n",
    "            \"recall\":    rec,\n",
    "            \"f1\":        f1,\n",
    "            \"roc_auc\":   auc,\n",
    "            \"n_samples\": len(y_true)\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9719524-9e3f-43b8-9a29-3bda7517b291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year_survival_df = evaluate_survival_as_classifier(\n",
    "    trained_models,\n",
    "    preprocessor,\n",
    "    settings,\n",
    "    horizon_days=365,\n",
    "    threshold=0.45\n",
    ")\n",
    "print(\"1-year performance:\\n\", year_survival_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a795e2d-bc8c-4067-bf9c-9e15af4cabb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparison of Models\n",
    "Next, we focus on the patient's actual treatment choice and compare the predictions from the best-performing models. By evaluating the survival curves generated by both models for the chosen treatment, we assess their agreement and gain a deeper understanding of the patient-specific predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0730cdb-7e53-4a41-b729-41989c352953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_different_models_survival_curves(\n",
    "    trained_models=models_to_evaluate,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    patient_index=70\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prediction_env)",
   "language": "python",
   "name": "prediction_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
