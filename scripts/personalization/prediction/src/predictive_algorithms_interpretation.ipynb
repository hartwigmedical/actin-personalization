{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ded855-2c7d-4b66-941f-08baefeff998",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "This notebook demonstrates the interpretation and evaluation of the models (as trained in `predictive_algorithms_training.ipynb`):\n",
    "- Performance Evaluation: Comparing models based on metrics such as concordance index (C-Index), integrated Brier score (IBS), calibration error (CE), and time-dependent AUC.\n",
    "- Visualization: Generating survival curves and feature importance plots to interpret model predictions and uncover key insights.\n",
    "\n",
    "In the file `utils/settings.py` all the experiment settings can be set (e.g. OS or PFS, grouped treatments or not), then the experiment can be run in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d8fe66-6bd6-42e4-98f4-c8c1ea8068a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22badec3-1d43-48b9-bceb-30bfef7d3ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/data/repos/actin-personalization/scripts/personalization/prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327398cd-8fde-4fa0-950d-e6c9d8f8c932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import dill\n",
    "import torch\n",
    "\n",
    "from src.models import *\n",
    "from src.data.data_processing import DataSplitter, DataPreprocessor\n",
    "from src.data.lookups import lookup_manager\n",
    "from src.utils.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96061676-ee3f-4100-936f-06041205a5d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from src.predictive_algorithms_training import get_data, plot_different_models_survival_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f88038-4db9-48a9-bdb7-218d5d3c4f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df, X_train, X_test, y_train, y_test, encoded_columns = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9982662e-0f4c-4148-80fe-989a61af6bf8",
   "metadata": {},
   "source": [
    "### Metric comparison: OS vs. PFS\n",
    "\n",
    "The trained models are evaluated using the following metrics:\n",
    "\n",
    "- **C-Index**: The Concordance Index measures how well the predicted survival times align with the actual outcomes. It is a measure of discrimination, indicating the model's ability to correctly rank the survival times of patients. A higher value indicates better predictive accuracy.\n",
    "\n",
    "- **Integrated Brier Score (IBS)**: This metric evaluates the accuracy of the survival probability predictions over time. It combines the squared differences between predicted and actual survival probabilities, weighted by the survival distribution. Lower values indicate better predictive performance.\n",
    "\n",
    "- **Calibration Error (CE)**: Calibration error assesses how well the predicted survival probabilities match the observed probabilities. It indicates whether the model is systematically overestimating or underestimating survival probabilities. Lower values signify better calibration.\n",
    "\n",
    "- **Area Under the Curve (AUC)**: For survival models, AUC is typically computed over a time-dependent ROC curve, reflecting the model's discrimination ability at different time points. Higher AUC values indicate better overall performance.\n",
    "\n",
    "This section visualizes the comparison of model performance metrics (C-Index, IBS, CE, AUC) for OS and PFS. The bar plots highlight the strengths and weaknesses of each model in the two prediction tasks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b352418-ebec-4b4d-83e1-3ce48bf2c6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model_outcomes():\n",
    "    csv_file = os.path.join(settings.save_path, f\"{settings.outcome}_model_outcomes.csv\")\n",
    "    \n",
    "    if os.path.exists(csv_file):\n",
    "        results_df = pd.read_csv(csv_file)\n",
    "        print(f\"Loaded model outcomes from {csv_file}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No saved outcomes found for {settings.outcome} in {settings.save_path}\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b21db4a-eb3a-4af5-827e-337e7e497171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_outcomes = load_model_outcomes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c5be4-028e-48a0-9904-1cf99436cf60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_holdout_metrics(df):\n",
    "    if df['holdout'].apply(lambda x: isinstance(x, str)).any():\n",
    "        df['holdout'] = df['holdout'].apply(ast.literal_eval)\n",
    "    \n",
    "    holdout_metrics = df['holdout'].apply(pd.Series)\n",
    "    holdout_metrics['Model'] = df['Model']\n",
    "    \n",
    "    return holdout_metrics\n",
    "\n",
    "\n",
    "def plot_all_metrics(df, holdout=True):\n",
    "    metrics = ['c_index', 'ibs', 'ce', 'auc']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for ax, metric in zip(axes, metrics):\n",
    "        sns.barplot(x='Model', y=metric, data=df, ax=ax, palette='Set1')\n",
    "        title = f\"{metric.upper()} Comparison\"\n",
    "        \n",
    "        ax.set_title(title)\n",
    "        ax.set(xlabel='Model', ylabel=metric.upper())\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        if metric in ['c_index', 'auc']:\n",
    "            ax.set_ylim(0, 1)\n",
    "        \n",
    "        # Set bar colors based on the metric values for some visual weighting\n",
    "        min_val, max_val = df[metric].min(), df[metric].max()\n",
    "        cmap = sns.light_palette(\"#79C\", as_cmap=True)\n",
    "        for patch in ax.patches:\n",
    "            height = patch.get_height()\n",
    "            normalized = (height - min_val) / (max_val - min_val) if max_val > min_val else 0.5\n",
    "            patch.set_facecolor(cmap(0.4 + 0.8 * normalized))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ab86d-6573-4d83-8d36-8d6fbe4a89f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_all_metrics(model_outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3ea02a-4c7b-4bf4-8205-f6189e6be4a3",
   "metadata": {},
   "source": [
    "### Import Trained Models\n",
    "The pretrained models are stored in the Google Cloud Storage bucket: `gs://actin-personalization-models-v1/trained_models/`. \n",
    "\n",
    "To download the saved models from the bucket to the trained_models map, run the following command in your terminal:\n",
    "\n",
    "`gsutil -m cp -r gs://actin-personalization-models-v1/trained_models/./trained_models/`\n",
    "\n",
    "Make sure the trained_models folder is inside the models folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9f06e2-50cd-4e66-95c7-8b9a87e68edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_trained_model(model_name, model_class, model_kwargs={}):\n",
    "    model_file_prefix = os.path.join(settings.save_path, f\"{settings.outcome}_{model_name}\")\n",
    "    nn_file = model_file_prefix + \".pt\"\n",
    "    sk_file = model_file_prefix + \".pkl\"\n",
    "        \n",
    "    if model_name in ['CoxPH', 'RandomSurvivalForest', 'GradientBoosting', 'AalenAdditive']:\n",
    "        with open(sk_file, \"rb\") as f:\n",
    "            model = dill.load(f)\n",
    "        print(f\"Model {model_name} loaded from {sk_file}\")\n",
    "        return model\n",
    "    else:\n",
    "        model = model_class(**model_kwargs)\n",
    "    \n",
    "        state = torch.load(nn_file, map_location=torch.device('cpu'))\n",
    "        model.model.net.load_state_dict(state['net_state'])\n",
    "        \n",
    "        if 'baseline_hazards' in state and state['baseline_hazards'] is not None:\n",
    "            model.model.baseline_hazards_ = state['baseline_hazards']\n",
    "            model.model.baseline_cumulative_hazards_ = state['baseline_cumulative_hazards']\n",
    "            \n",
    "            print(f\"Baseline hazards loaded for {model_name}.\")\n",
    "        model.model.net.eval()     \n",
    "        print(f\"Model {model_name} loaded from {nn_file}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "def load_all_trained_models():\n",
    "    loaded_models = {}\n",
    "    config_mgr = ExperimentConfig(settings.json_config_file)\n",
    "    loaded_configs = config_mgr.load_model_configs()\n",
    "\n",
    "    for model_name, (model_class, model_kwargs) in loaded_configs.items():\n",
    "        print(model_name, model_class)\n",
    "        try:\n",
    "            loaded_model = load_trained_model(\n",
    "                model_name=model_name, \n",
    "                model_class=model_class, \n",
    "                model_kwargs=model_kwargs\n",
    "            )\n",
    "            loaded_models[model_name] = loaded_model\n",
    "        except:\n",
    "            print(f'Could not load: {model_name}')\n",
    "            continue\n",
    "    return loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09cb005-8968-45ae-ae28-5ba2fbf8abc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_models = load_all_trained_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d0bc5-3d6c-4293-912a-cdd6b5ae8393",
   "metadata": {},
   "source": [
    "### Time-Dependent ROC-AUC\n",
    "\n",
    "This section visualizes the ROC curves and computes the AUC for survival models at specific time intervals for both OS and PFS. By evaluating the models' discriminative performance over time, we identify which models perform best at different prediction horizons.\n",
    "\n",
    "Time interval:\n",
    "- **Overall Survival (OS)**: For OS, the follow-up times in the dataset extend up to 5 years, allowing us to evaluate model performance over this longer horizon. As survival outcomes often have a broader timespan, a 5-year evaluation provides a comprehensive view of the model's ability to predict long-term survival.\n",
    "\n",
    "- **Progression-Free Survival (PFS)**: In contrast, PFS events typically occur sooner than OS events. Instead, we limit the PFS analysis to 3 years, which encompasses the majority of observed progression events while maintaining meaningful statistical power.\n",
    "\n",
    "The ROC curves for the best-performing models (Gradient Boosting, CoxPH, DeepSurv, and RSF) are plotted for each time interval, showcasing how well the models distinguish patients at risk across the respective timeframes for OS and PFS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169551f6-ef77-4553-bb99-5dc742b2cc18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "\n",
    "def calculate_time_dependent_auc_for_models(model_dict, X_train, y_train, X_test, y_test, time_points):\n",
    "  \n",
    "    y_train_df = pd.DataFrame({'duration': y_train[settings.duration_col], 'event': y_train[settings.event_col]}, index=X_train.index)\n",
    "    y_train_struct = Surv.from_dataframe('event', 'duration', y_train_df)\n",
    "\n",
    "    y_test_df = pd.DataFrame({'duration': y_test[settings.duration_col], 'event': y_test[settings.event_col]}, index=X_test.index)\n",
    "    y_test_struct = Surv.from_dataframe('event', 'duration', y_test_df)\n",
    "\n",
    "    auc_results = {}\n",
    "\n",
    "    for model_name, model in model_dict.items():\n",
    "        if hasattr(model, \"model\") and hasattr(model.model, \"predict\"):\n",
    "            preds = model.model.predict(X_test.values.astype(\"float32\"))\n",
    "        else:\n",
    "            preds = model.predict(X_test)\n",
    "\n",
    "        if preds.ndim == 1:\n",
    "            risk_scores = preds\n",
    "        elif preds.shape[1] == 1:\n",
    "            risk_scores = preds.ravel()\n",
    "        else:\n",
    "            T = preds.shape[1]\n",
    "            desired_T = len(time_points)\n",
    "            if T == desired_T:\n",
    "                risk_scores = preds\n",
    "            elif T % desired_T == 0:\n",
    "                factor = T // desired_T\n",
    "                risk_scores = preds[:, ::factor]\n",
    "\n",
    "        auc_values, mean_auc = cumulative_dynamic_auc(y_train_struct, y_test_struct, risk_scores, time_points)\n",
    "        auc_results[model_name] = (auc_values, mean_auc)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    years = [t / 365.0 for t in time_points]\n",
    "\n",
    "    for model_name, (auc_vals, mean_auc) in auc_results.items():\n",
    "        plt.plot(years, auc_vals, marker='o', label=f\"{model_name} (Mean AUC={mean_auc:.3f})\")\n",
    "\n",
    "    plt.xlabel(\"Time (years)\")\n",
    "    plt.ylabel(\"Time-Dependent AUC\")\n",
    "    plt.title(settings.outcome)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return auc_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c22cabc-bdda-471c-9e2b-0daea7cc18cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_to_evaluate = {\n",
    "    \"DeepSurv\": trained_models[\"DeepSurv\"],\n",
    "    \"DeepSurv_attention\": trained_models[\"DeepSurv_attention\"],\n",
    "    \n",
    "    \"LogisticHazardModel\": trained_models[\"LogisticHazardModel\"],\n",
    "    \"LogisticHazardModel_attention\": trained_models[\"LogisticHazardModel_attention\"],\n",
    "    \n",
    "    \"DeepHitModel\": trained_models[\"DeepHitModel\"],\n",
    "    \"DeepHitModel_attention\": trained_models[\"DeepHitModel_attention\"],\n",
    "    \n",
    "    \"PCHazardModel\": trained_models[\"PCHazardModel\"],\n",
    "    \"PCHazardModel_attention\": trained_models[\"PCHazardModel_attention\"],\n",
    "    \n",
    "    \"MTLRModel\": trained_models[\"MTLRModel\"],\n",
    "    \"MTLRModel_attention\": trained_models[\"MTLRModel_attention\"],\n",
    "    \n",
    "    # \"CoxPH\": trained_models[\"CoxPH\"],\n",
    "    \"GradientBoosting\": trained_models[\"GradientBoosting\"],   \n",
    "    \"RandomSurvivalForest\": trained_models[\"RandomSurvivalForest\"],    \n",
    "}\n",
    "\n",
    "calculate_time_dependent_auc_for_models(\n",
    "    models_to_evaluate, X_train, y_train, X_test, y_test, \n",
    "    time_points=settings.time_points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d73024-50f0-4755-a20b-e8b10a8f3f97",
   "metadata": {},
   "source": [
    "## Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d359b6-c147-468e-8150-77b696e41d02",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature Importance\n",
    "\n",
    "Feature importance analysis helps us identify which features most strongly influence survival predictions across various models. In this section SHAP (SHapley Additive exPlanations) is used for all models to ensure uniformity and interpretability. SHAP values provide a consistent and locally accurate measure of feature importance for individual predictions.\n",
    "\n",
    "How SHAP is used:\n",
    "- For classical models like CoxPH and Aalen Additive, SHAP values are calculated based on risk scores or cumulative hazard coefficients. Custom prediction functions are used when necessary (e.g., for Aalen Additive) to align feature importance with model-specific outputs.\n",
    "- For tree-based models like Random Survival Forest (RSF) and Gradient Boosting Survival Model (GBM), SHAP values replace traditional feature importance metrics to ensure consistency.\n",
    "- For neural network-based models like DeepSurv and DeepHit, SHAP values are derived using the model's prediction function.\n",
    "\n",
    "#### Visualization\n",
    "SHAP provides the following insights:\n",
    "- Summary Plot - Bar: Displays the average magnitude of SHAP values for each feature, indicating the overall importance of features in the model.\n",
    "- Summary Plot - Dot: Highlights the distribution of SHAP values for each feature, showing their impact across different samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d1b49-c34a-4854-9e95-eb3b829158a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "def nn_predict(X, model, X_train):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X, columns=X_train.columns)\n",
    "    X_tensor = X.values.astype('float32')\n",
    "    return model.model.predict(X_tensor)\n",
    "\n",
    "def custom_aalen_predict(X, model):\n",
    "    \"\"\"\n",
    "    Custom predict function for AalenAdditiveModel.\n",
    "    Aligns cumulative hazard coefficients with input features.\n",
    "    \"\"\"\n",
    "    cumulative_coefs = model.model.cumulative_hazards_\n",
    "    X = X[model.selected_features].copy()\n",
    "\n",
    "    # Interpolate coefficients at the latest time point\n",
    "    latest_coefs = cumulative_coefs.iloc[-1].values\n",
    "    \n",
    "    if len(latest_coefs) > X.shape[1]:\n",
    "        X = X.copy()\n",
    "        X.insert(0, \"Intercept\", 1.0)  \n",
    "\n",
    "    X_array = X.values\n",
    "    risk_scores = np.einsum('ij,j->i', X_array, latest_coefs)\n",
    "    return risk_scores\n",
    "\n",
    "def shap_interpret_model(model_name, model, X_train, max_features=20, shap_sample=200):\n",
    "\n",
    "    X_sample = X_train.sample(min(shap_sample, len(X_train)), random_state=42)\n",
    "\n",
    "    predict_functions = {\n",
    "        'AalenAdditive': lambda X: custom_aalen_predict(X, model),\n",
    "        'default': model.predict\n",
    "    }\n",
    "\n",
    "    if model_name == 'AalenAdditive':\n",
    "        prediction_fn = predict_functions['AalenAdditive']\n",
    "    else:\n",
    "        try:\n",
    "            model.predict(X_sample.head(1))\n",
    "            prediction_fn = predict_functions['default']\n",
    "        except:\n",
    "            prediction_fn = lambda x: nn_predict(x, model, X_train)\n",
    "\n",
    "    explainer = shap.Explainer(prediction_fn, X_sample)\n",
    "    shap_values = explainer(X_sample)\n",
    "\n",
    "    print(f\"SHAP Summary for {model_name}:\")\n",
    "\n",
    "    if len(shap_values.values.shape) == 3: #If time dimension present\n",
    "        aggregated_shap = shap_values.values.mean(axis=1)\n",
    "        shap.summary_plot(aggregated_shap, features=X_sample, plot_type=\"bar\", max_display=max_features)\n",
    "        shap.summary_plot(aggregated_shap, features=X_sample, max_display=max_features)\n",
    "    else:\n",
    "        shap.summary_plot(shap_values, features=X_sample, plot_type=\"bar\", max_display=max_features)\n",
    "        shap.summary_plot(shap_values, features=X_sample, max_display=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1cd51e-df04-4d6c-9260-9b64a1bd3897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model_name, model_instance in models_to_evaluate.items():\n",
    "    print(f\"\\n--- Interpreting {model_name} ---\")\n",
    "    shap_interpret_model(model_name, model_instance, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8251ee4-bd28-4497-ae9a-971c9f5d2be7",
   "metadata": {},
   "source": [
    "## Model Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7de122-7805-4a5a-aac8-a8df125da2ac",
   "metadata": {},
   "source": [
    "### Median Survival Time Calculation\n",
    "\n",
    " Rather than relying on the mean survival time (which can be skewed by tail behavior), we focus on the median survival time, defined as the time point t at which the survival function S(t) first drops below 0.5. This metric is often more robust in practical settings, as it is less sensitive to subtle differences in the survival curve’s tail.\n",
    "\n",
    "The median survival time is obtained by scanning the survival curve from time zero until finding the earliest point where S(t)≤0.5. If the survival probability never dips below 0.5 within the observed follow-up, the median is considered to be at (or beyond) the maximum time point in our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98479b4-0b8e-44b4-89d8-7fa9c3161a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_median_and_quartiles_survival_time(times, surv_probs):\n",
    "    times = np.asarray(times, dtype=float)\n",
    "    surv_probs = np.asarray(surv_probs, dtype=float)\n",
    "\n",
    "    def find_time_for_percentile(percentile):\n",
    "        for i in range(1, len(times)):\n",
    "            if surv_probs[i] <= percentile:\n",
    "                x0, x1 = times[i - 1], times[i]\n",
    "                y0, y1 = surv_probs[i - 1], surv_probs[i]\n",
    "                frac = (percentile - y0) / (y1 - y0)\n",
    "                return x0 + frac * (x1 - x0)\n",
    "        return times[-1]\n",
    "\n",
    "    median_time = find_time_for_percentile(0.5)\n",
    "    q1_time = find_time_for_percentile(0.75)  # Q1: 75% survival probability\n",
    "    q3_time = find_time_for_percentile(0.25)  # Q3: 25% survival probability\n",
    "\n",
    "    return median_time, q1_time, q3_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17bc71-3d6e-4d81-a662-f18cfd6c3b41",
   "metadata": {},
   "source": [
    "#### Comparison of Treatments\n",
    "In this section the predicted survival probabilities can be visualized for a single patient under different treatment scenarios. By simulating the patient receiving each available treatment, we can compare how the model predicts their survival trajectory across treatments.\n",
    "\n",
    "This analysis provides insights into the model's predictions for different treatment options, helping to identify potentially better treatment choices for the patient based on the predicted survival probabilities over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f72ef-1094-40e2-b2fc-e31204ef2955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import pymysql\n",
    "\n",
    "def get_raw_patient_row(db_config_path: str, db_name: str, ncrId: int):\n",
    "    conn = pymysql.connect(read_default_file=db_config_path, read_default_group='RAnalysis', db=db_name)\n",
    "    raw_df = pd.read_sql(f\"SELECT * FROM {settings.view_name}\", conn)\n",
    "    conn.close()\n",
    "    raw_df = raw_df[raw_df[\"ncrId\"] == ncrId]\n",
    "    \n",
    "    return raw_df.iloc[0] if not raw_df.empty else None\n",
    "\n",
    "def plot_survival_curves_for_ncrId_different_treatments(valid_treatment_combinations, model, ncrId, features, treatment_col_prefix=\"systemicTreatmentPlan\", plot_title=\"Survival Curves\", test_all_msi=True):\n",
    "    features_with_id = features.copy()\n",
    "    if \"ncrId\" not in features_with_id:\n",
    "        features_with_id.insert(0, \"ncrId\")\n",
    "        \n",
    "    preproc = DataPreprocessor(settings.db_config_path, settings.db_name)\n",
    "    df, updated_feats, encoded_cols = preproc.preprocess_data(features_with_id)\n",
    "    df_patient = df[df[\"ncrId\"] == ncrId]\n",
    "    \n",
    "    if df_patient.empty:\n",
    "        print(f\"No patient found with ncrId {ncrId}\")\n",
    "        return\n",
    "    \n",
    "    patient_row = df_patient.iloc[0]\n",
    "    raw_patient = get_raw_patient_row(preproc.db_config_path, preproc.db_name, ncrId)\n",
    "    print(f\"\\n🧬 Patient {ncrId} characteristics:\")\n",
    "    print(f\"  - Age at metastasis detection: {raw_patient.get('ageAtMetastasisDetection', 'NA')}\")\n",
    "    print(f\"  - WHO status: {raw_patient.get('whoStatusPreTreatmentStart', 'NA')}\")\n",
    "    print(f\"  - MSI status: {'MSI' if patient_row.get('hasMsi', 0)==1 else 'MSS or NA'}\")\n",
    "    print(f\"  - BRAF mutation: {'Yes' if patient_row.get('hasBrafMutation', 0)==1 else 'No'}\")\n",
    "    print(f\"  - BRAF V600E: {'Yes' if patient_row.get('hasBrafV600EMutation', 0)==1 else 'No'}\")\n",
    "    print(f\"  - KRAS G12C: {'Yes' if patient_row.get('hasKrasG12CMutation', 0)==1 else 'No'}\")\n",
    "    print(f\"  - RAS mutation: {'Yes' if patient_row.get('hasRasMutation', 0)==1 else 'No'}\")\n",
    "    \n",
    "    X_base = df_patient.drop(columns=[\"ncrId\", settings.event_col, settings.duration_col]).copy()\n",
    "    \n",
    "    if settings.experiment_type.lower() == 'treatment_drug':\n",
    "        treatment_opts = list(valid_treatment_combinations.items())\n",
    "        drug_cols = {col for combo in valid_treatment_combinations.values() for col in combo.keys()}\n",
    "    else:\n",
    "        treat_cols = [col for col in X_base.columns if col.startswith(treatment_col_prefix)]\n",
    "        \n",
    "        if not treat_cols:\n",
    "            print(f\"No treatment columns found with prefix '{treatment_col_prefix}'\")\n",
    "            return\n",
    "        \n",
    "        actual_received = [col[len(treatment_col_prefix)+1:] for col in treat_cols if patient_row.get(col, 0)==1]\n",
    "        print(f\"  - Actual received treatment: {', '.join(actual_received) if actual_received else 'No Treatment'}\\n\")\n",
    "        treatment_opts = [(\"No Treatment\", {tc: 0 for tc in treat_cols})]\n",
    "        \n",
    "        for tc in treat_cols:\n",
    "            opt = {t: 0 for t in treat_cols}\n",
    "            opt[tc] = 1\n",
    "            label = tc[len(treatment_col_prefix)+1:]\n",
    "            treatment_opts.append((label, opt))\n",
    "            \n",
    "        drug_cols = set(treat_cols)\n",
    "\n",
    "    if settings.experiment_type.lower() == 'treatment_drug':\n",
    "        time_grid = np.arange(1, settings.max_time, 30)\n",
    "    else:\n",
    "        time_grid = np.linspace(\n",
    "            max(fn.x[0] for fn in model.predict_survival_function(X_base.copy())),\n",
    "            min(fn.x[-1] for fn in model.predict_survival_function(X_base.copy())),\n",
    "            100\n",
    "        )\n",
    "        \n",
    "    months = [6, 12, 18, 24, 30, 36]\n",
    "    time_pts = np.array(months) * 30\n",
    "    plt.figure(figsize=(12,8))\n",
    "    cmap = plt.cm.tab20(np.linspace(0,1,len(treatment_opts)))\n",
    "    msi_opts = [(\"MSI\", 1), (\"MSS\", 0)] if test_all_msi else [(\"MSI\", 1)]\n",
    "    \n",
    "    for i, (base_label, opt) in enumerate(treatment_opts):\n",
    "        for msi_label, msi_val in msi_opts:\n",
    "            X_mod = X_base.copy()\n",
    "            for col in drug_cols:\n",
    "                if col in X_mod.columns:\n",
    "                    X_mod[col] = 0\n",
    "            for col, val in opt.items():\n",
    "                if col in X_mod.columns:\n",
    "                    X_mod[col] = val\n",
    "                    \n",
    "            if 'hasMsi' in X_mod.columns:\n",
    "                X_mod['hasMsi'] = msi_val\n",
    "            try:\n",
    "                surv_funcs = model.predict_survival_function(X_mod)\n",
    "                if not surv_funcs:\n",
    "                    print(f\"No survival function for {base_label} [{msi_label}]\")\n",
    "                    continue\n",
    "                    \n",
    "                surv_func = surv_funcs[0]\n",
    "                surv_probs = surv_func(time_grid)\n",
    "                \n",
    "                med, _, _ = get_median_and_quartiles_survival_time(time_grid, surv_probs)\n",
    "                label = f\"{base_label} ({msi_label}, median={int(med)})\"\n",
    "                idx = i * len(msi_opts) + (0 if msi_val==1 else 1)\n",
    "                \n",
    "                plt.step(time_grid/30.44, surv_probs, where=\"post\", color=cmap[idx % len(cmap)], label=label)              \n",
    "               \n",
    "            except Exception as e:\n",
    "                print(f\"Error plotting survival curve for {base_label} [{msi_label}]: {e}\")\n",
    "                \n",
    "    actual_time = df_patient[settings.duration_col].iloc[0]\n",
    "    event_flag = df_patient[settings.event_col].iloc[0]\n",
    "    marker_color = \"red\" if event_flag else \"blue\"\n",
    "    marker_label = \"Event Time\" if event_flag else \"Censoring Time\"\n",
    "    plt.axvline(x=actual_time/30.44, color=marker_color, linestyle=\"--\", label=marker_label)\n",
    "    plt.title(f\"{plot_title} for ncrId: {ncrId}\")\n",
    "    plt.xlabel(\"Time (months)\")\n",
    "    plt.ylabel(\"Survival Probability\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890b768-501b-4177-ad18-dddc46a65daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_treatment_combinations = {\n",
    "    \"No Treatment\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 0,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 0,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 0,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"sytemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 0,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 0,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0, \n",
    "        \"sytemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + oxaliplatin\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 1,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 0,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"sytemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + oxaliplatin + bevacizumab\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 1,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 0,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 1,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"sytemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + irinotecan\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 0,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 1,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"sytemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + irinotecan + bevacizumab\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 0,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 1,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 1,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"sytemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + irinotecan + panitumumab\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 0,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 1,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 1,\n",
    "        \"sytemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + oxaliplatin + irinotecan\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 1,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 1,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"sytemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"5-FU + oxaliplatin + irinotecan + bevacizumab\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 1,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 1,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 1,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 1,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"sytemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"PEMBROLIZUMAB\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 0,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 0,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 0,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"sytemicTreatmentPlan_pembrolizumab\": 1,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 0\n",
    "    },\n",
    "    \"NIVOLUMAB\": {\n",
    "        \"systemicTreatmentPlan_5-FU\": 0,\n",
    "        \"systemicTreatmentPlan_oxaliplatin\": 0,\n",
    "        \"systemicTreatmentPlan_irinotecan\": 0,\n",
    "        \"systemicTreatmentPlan_bevacizumab\": 0,\n",
    "        \"systemicTreatmentPlan_panitumab\": 0,\n",
    "        \"sytemicTreatmentPlan_pembrolizumab\": 0,\n",
    "        \"systemicTreatmentPlan_nivolumab\": 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf59c2e6-89f5-48b2-b102-5a8dec47dc30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_survival_curves_for_ncrId_different_treatments(\n",
    "    valid_treatment_combinations,\n",
    "    model=trained_models['DeepSurv'],\n",
    "    ncrId=159624204,\n",
    "    features=lookup_manager.features,\n",
    "    plot_title=f\"{settings.outcome}: Survival Curves\", \n",
    "    test_all_msi=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa275a68-72d7-4927-8e88-92ffe9e8e171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_survival_curves_for_ncrId_different_treatments(\n",
    "    valid_treatment_combinations,\n",
    "    model=trained_models['DeepSurv_attention'],\n",
    "    ncrId=159624204,\n",
    "    features=lookup_manager.features,\n",
    "    plot_title=f\"{settings.outcome}: Survival Curves\", \n",
    "    test_all_msi=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9adaee-3de8-4dc3-8ce6-cbd4c238286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "def get_patient_features(df, ncrId, drop_cols):\n",
    "    \"\"\"\n",
    "    Pulls out the preprocessed feature row for one patient.\n",
    "    \"\"\"\n",
    "    df_pat = df[df[\"ncrId\"] == ncrId]\n",
    "    if df_pat.empty:\n",
    "        raise ValueError(f\"No patient with ncrId={ncrId}\")\n",
    "    # drop ID and any non‑feature columns\n",
    "    return df_pat.drop(columns=drop_cols)\n",
    "\n",
    "def make_predict_fn(model_name, model, X_train, time_point=None):\n",
    "    \"\"\"\n",
    "    Returns a function f(X_df) -> 1D numpy array of predictions.\n",
    "    For survival models, you might want risk scores (Aalen/Cox)\n",
    "    or survival probability at a fixed time_point.\n",
    "    \"\"\"\n",
    "    if model_name == \"AalenAdditive\":\n",
    "        def f(X_df):\n",
    "            # use your custom Aalen risk‐score wrapper\n",
    "            return custom_aalen_predict(X_df, model)\n",
    "        return f\n",
    "\n",
    "    # for tree‐ or linear‐based Cox, risk score is just model.predict\n",
    "    if hasattr(model, \"predict\"):\n",
    "        return lambda X_df: model.predict(X_df)\n",
    "\n",
    "    # for a Keras/TensorFlow net\n",
    "    def nn_f(X_df):\n",
    "        # cast to tensor and call the network\n",
    "        return nn_predict(X_df, model, X_train)\n",
    "    return nn_f\n",
    "\n",
    "def explain_one_patient(ncrId, model_name, model, X_train, df, drop_cols, max_display=10, time_point=None):\n",
    "    \"\"\"\n",
    "    Computes and plots SHAP values for a single patient.\n",
    "    \"\"\"\n",
    "    # 1) grab the row\n",
    "    X_pat = get_patient_features(df, ncrId, drop_cols)\n",
    "\n",
    "    # 2) build predict fn that returns a single number per row\n",
    "    predict_fn = make_predict_fn(model_name, model, X_train, time_point)\n",
    "\n",
    "    # 3) sample a background set (you already do this in shap_interpret_model)\n",
    "    bg = X_train.sample(min(200, len(X_train)), random_state=42)\n",
    "\n",
    "    # 4) init Explainer\n",
    "    explainer = shap.Explainer(predict_fn, bg)\n",
    "\n",
    "    # 5) compute shap values for just this one row\n",
    "    shap_vals = explainer(X_pat)\n",
    "\n",
    "    # 6) visualize\n",
    "    # waterfall is great for a single instance:\n",
    "    shap.plots.waterfall(shap_vals[0], max_display=max_display)\n",
    "    # or even a force plot:\n",
    "    # shap.plots.force(shap_vals[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654937cd-e467-4511-a1d0-580b57201e60",
   "metadata": {},
   "source": [
    "#### Comparison of Models\n",
    "Next, we focus on the patient's actual treatment choice and compare the predictions from the best-performing models. By evaluating the survival curves generated by both models for the chosen treatment, we assess their agreement and gain a deeper understanding of the patient-specific predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0730cdb-7e53-4a41-b729-41989c352953",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_different_models_survival_curves(\n",
    "    trained_models=models_to_evaluate,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    patient_index=78\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_env)",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
