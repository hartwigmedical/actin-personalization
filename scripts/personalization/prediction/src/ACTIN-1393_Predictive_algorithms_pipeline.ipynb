{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d61ed0d-783d-45f7-99a2-f3c87dbccfc2",
   "metadata": {},
   "source": [
    "# Predictive Algorithms\n",
    "\n",
    "This notebook demonstrates the development and evaluation of predictive algorithms for survival analysis. The aim is to train, evaluate, and optimize various survival models to predict overall survival (OS) and progression-free survival (PFS) for patients, using both classical and deep learning techniques. It includes data preprocessing, model training, hyperparameter optimization, and visualization of survival curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00789d13-178f-42bd-81a8-947b666139f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b78c7cb-fe63-46a0-9873-be7edde348b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.models import *\n",
    "from src.data.data_processing import DataSplitter, DataPreprocessor\n",
    "from src.data.lookups import LookupManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f5b2e-bc29-4325-8a49-63bac2552dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_config_path = '/home/jupyter/.my.cnf'\n",
    "db_name = 'actin_personalization'\n",
    "query = \"SELECT * FROM knownPalliativeTreatments\"\n",
    "\n",
    "preprocessor = DataPreprocessor(db_config_path, db_name)\n",
    "\n",
    "lookup_manager = LookupManager()\n",
    "features = lookup_manager.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d87935-155b-40c6-8edc-d7c8326d2ef5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In this section, we set up the data pipeline for survival analysis. The `DataSplitter` and `DataPreprocessor` classes are used to load, preprocess, and split the data into training and testing sets. This ensures the survival data is structured appropriately for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a8049d-485b-4da4-913f-510906547b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(query, event_col, duration_col, features):\n",
    "    splitter = DataSplitter(test_size=0.1, random_state=42)\n",
    "    \n",
    "    df, features, encoded_columns = preprocessor.preprocess_data(query, duration_col, event_col, features)\n",
    "                          \n",
    "    y = Surv.from_dataframe(event=event_col, time=duration_col, data=df)\n",
    "    X_train, X_test, y_train, y_test = splitter.split(df[features], df, 'systemicTreatmentPlan', encoded_columns)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, encoded_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504d62f-a330-402b-b58e-a3b3f74a9658",
   "metadata": {},
   "source": [
    "## Train and Evaluate Models\n",
    "\n",
    "This section defines the function `train_evaluate_models`, which trains various survival models using predefined configurations. The trained models are evaluated using the following metrics:\n",
    "\n",
    "- **C-Index**: The Concordance Index measures how well the predicted survival times align with the actual outcomes. It is a measure of discrimination, indicating the model's ability to correctly rank the survival times of patients. A higher value indicates better predictive accuracy.\n",
    "\n",
    "- **Integrated Brier Score (IBS)**: This metric evaluates the accuracy of the survival probability predictions over time. It combines the squared differences between predicted and actual survival probabilities, weighted by the survival distribution. Lower values indicate better predictive performance.\n",
    "\n",
    "- **Calibration Error (CE)**: Calibration error assesses how well the predicted survival probabilities match the observed probabilities. It indicates whether the model is systematically overestimating or underestimating survival probabilities. Lower values signify better calibration.\n",
    "\n",
    "- **Area Under the Curve (AUC)**: For survival models, AUC is typically computed over a time-dependent ROC curve, reflecting the model's discrimination ability at different time points. Higher AUC values indicate better overall performance.\n",
    "\n",
    "Together, these metrics provide a comprehensive evaluation of the models' predictive performance, capturing different aspects of accuracy, discrimination, and calibration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71536d40-de44-4f55-9e44-c1f1e3cc5fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_survival_curves_for_patient(trained_models, X_test, y_test, patient_index, event_col, duration_col, plot_title):\n",
    "    \"\"\"\n",
    "    Plot survival curves for a specific patient using trained models.\n",
    "    \"\"\"\n",
    "    X_patient = X_test.iloc[[patient_index]]\n",
    "    actual_duration_days = y_test[duration_col].iloc[patient_index]\n",
    "    actual_event = y_test[event_col].iloc[patient_index]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for model_name, model in trained_models.items():\n",
    "        try:\n",
    "            surv_funcs = model.predict_survival_function(X_patient)\n",
    "\n",
    "            times = np.linspace( max(fn.x[0] for fn in surv_funcs), min(fn.x[-1] for fn in surv_funcs), 100)\n",
    "            surv_probs = np.row_stack([fn(times) for fn in surv_funcs])\n",
    "            \n",
    "            plt.step(times / 30.44, surv_probs[0], where=\"post\", label=model_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting survival curves for model {model_name}: {e}\")\n",
    "\n",
    "    marker_color = 'red' if actual_event else 'blue'\n",
    "    marker_label = \"Event Time\" if actual_event else \"Censoring Time\"\n",
    "    plt.axvline(x=actual_duration_days / 30.44, color=marker_color, linestyle='--', label=marker_label)\n",
    "\n",
    "    plt.title(f\"Predicted {plot_title} Curves\")\n",
    "    plt.xlabel(\"Time (months)\")\n",
    "    plt.ylabel(\"Survival Probability\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9317cc-59e1-430f-8e93-d3e10257d308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sksurv.util import Surv\n",
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import torch\n",
    "\n",
    "def train_evaluate_models(query, event_col, duration_col, features, configs, title, patient_index = 78, save_models=True):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, encoded_columns = get_data(query, event_col, duration_col, features)\n",
    "    \n",
    "    models = {}        \n",
    "    for model_name, (model_class, model_kwargs) in configs.items():\n",
    "        if issubclass(model_class, NNSurvivalModel):\n",
    "            model_kwargs['input_size'] = X_train.shape[1]\n",
    "        models[model_name] = model_class(**model_kwargs)\n",
    "    \n",
    "    trainer = ModelTrainer(models=models, n_splits=5, random_state=42)\n",
    "\n",
    "    results, trained_models = trainer.train_and_evaluate(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        treatment_col='systemicTreatmentPlan',\n",
    "        encoded_columns=encoded_columns,\n",
    "        event_col= event_col,\n",
    "        duration_col= duration_col, \n",
    "        title = title\n",
    "    )\n",
    "    \n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    results_df.reset_index(inplace=True)\n",
    "    results_df.rename(columns={'index': 'Model'}, inplace=True)\n",
    "    \n",
    "    if save_models:\n",
    "        save_path = \"src/models/trained_models\"\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        csv_file = os.path.join(save_path, f\"{title}_model_outcomes.csv\")\n",
    "        results_df.to_csv(csv_file, index=False)\n",
    "        print(f\"Model outcomes saved to {csv_file}\")\n",
    "    \n",
    "    plot_survival_curves_for_patient(trained_models, X_test, y_test, patient_index, event_col, duration_col, title)\n",
    "    \n",
    "    return results_df, trained_models\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32032079-2e45-443b-ad67-1721f39c2c4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Best Model Configurations\n",
    "\n",
    "The best configurations for OS and PFS models were determined using hyperparameter optimization, as defined below in this notebook. These configurations are used to instantiate the models for training and evaluation. The best configurations for the OS and PFS models are stored in `models/model_configurations`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35973037-bcc6-4556-a0b7-93c5a2e02c67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_model_outcomes, os_trained_models =  train_evaluate_models(query, event_col='hadSurvivalEvent', duration_col='observedOsFromTreatmentStartDays', features=features, configs=os_configs, title=\"OS\", save_models=True)\n",
    "os_model_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab611cb-e5de-4c00-abae-9fbf35c6ceb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pfs_model_outcomes, pfs_trained_models = train_evaluate_models(query, event_col='hadProgressionEvent', duration_col='observedPfsDays', features=features, configs=pfs_configs, title=\"PFS\")\n",
    "pfs_model_outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f3ce52-cd89-4fb4-89fa-fc8def4cf880",
   "metadata": {},
   "source": [
    "### Metric comparison: OS vs. PFS\n",
    "\n",
    "This section visualizes the comparison of model performance metrics (C-Index, IBS, CE, AUC) for OS and PFS. The bar plots highlight the strengths and weaknesses of each model in the two prediction tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e27ec-61fa-47db-9b2b-54dd89f5bdf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model_outcomes(title, save_path=\"src/models/trained_models\"):\n",
    "    csv_file = os.path.join(save_path, f\"{title}_model_outcomes.csv\")\n",
    "    \n",
    "    if os.path.exists(csv_file):\n",
    "        results_df = pd.read_csv(csv_file)\n",
    "        print(f\"Loaded model outcomes from {csv_file}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No saved outcomes found for {title} in {save_path}\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2a7c0-6b93-4d75-b5c3-87b83c41e138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_model_outcomes = load_model_outcomes(\"OS\")\n",
    "pfs_model_outcomes = load_model_outcomes(\"PFS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b6bc68-84e8-4386-9a1f-cc8e1d409e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_model_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc5e8c4-3b63-4569-840a-0d33231b7779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pfs_model_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c109ba-8bd2-47a1-8ade-3b63cbcb14b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "\n",
    "def extract_holdout_metrics(df):\n",
    "    if df['holdout'].apply(lambda x: isinstance(x, str)).any():\n",
    "        df['holdout'] = df['holdout'].apply(ast.literal_eval)\n",
    "    \n",
    "    holdout_metrics = df['holdout'].apply(pd.Series)\n",
    "    holdout_metrics['Model'] = df['Model']\n",
    "    \n",
    "    return holdout_metrics\n",
    "\n",
    "def plot_all_metrics(pfs_df, os_df, holdout=True):\n",
    "       \n",
    "    if holdout:\n",
    "        pfs_df = extract_holdout_metrics(pfs_df)\n",
    "        os_df = extract_holdout_metrics(os_df)\n",
    "    \n",
    "    pfs_df['Type'] = 'PFS'\n",
    "    os_df['Type'] = 'OS'\n",
    "\n",
    "    combined_df = pd.concat([pfs_df, os_df], ignore_index=True)\n",
    "\n",
    "    metrics = ['c_index', 'ibs', 'ce', 'auc']\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i]\n",
    "        sns.barplot(\n",
    "            x='Model',\n",
    "            y=metric,\n",
    "            hue='Type',\n",
    "            data=combined_df,\n",
    "            ax=ax,\n",
    "            palette='Set1'\n",
    "        )\n",
    "        ax.set_title(f'{metric.upper()} Comparison: OS vs. PFS')\n",
    "        ax.set_xlabel('Model')\n",
    "        ax.set_ylabel(metric.upper())\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "        ax.legend(title='Type', loc='best')\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f799e6a-4946-4187-b087-dde792f84752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_all_metrics(pfs_model_outcomes, os_model_outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7296eed4-6c66-4e95-9db4-27d2a913a7cb",
   "metadata": {},
   "source": [
    "## Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872752ce-54d4-45bb-a775-418a0159daee",
   "metadata": {},
   "source": [
    "Import the saved models if they were trained previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bad84d-bd4b-4d9d-a663-cb281dcacc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import joblib\n",
    "import dill\n",
    "from src.models.survival_models import NNSurvivalModel\n",
    "\n",
    "def load_trained_model(model_name, title, model_class, model_kwargs={}, save_path=\"src/models/trained_models\"):\n",
    "    model_file_prefix = os.path.join(save_path, f\"{title}_{model_name}\")\n",
    "    nn_file = model_file_prefix + \".pt\"\n",
    "    sk_file = model_file_prefix + \".pkl\"\n",
    "    \n",
    "    if issubclass(model_class, NNSurvivalModel):\n",
    "        if 'input_size' not in model_kwargs:\n",
    "            model_kwargs['input_size'] = 100\n",
    "        model = model_class(**model_kwargs)\n",
    "    \n",
    "        model.model.net.load_state_dict(torch.load(nn_file, map_location=torch.device('cpu')))\n",
    "        model.model.net.eval()\n",
    "        print(f\"Model {model_name} loaded from {nn_file}\")\n",
    "        return model\n",
    "    else:\n",
    "        with open(sk_file, \"rb\") as f:\n",
    "            model = dill.load(f)\n",
    "        print(f\"Model {model_name} loaded from {sk_file}\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e627c-9d7f-4707-acc8-08298d790452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_all_trained_models(model_specs, title, save_path=\"src/models/trained_models\"):\n",
    "    loaded_models = {}\n",
    "    for model_name, (model_class, model_kwargs) in model_specs.items():\n",
    "        loaded_model = load_trained_model(\n",
    "            model_name=model_name, \n",
    "            title=title, \n",
    "            model_class=model_class, \n",
    "            model_kwargs=model_kwargs, \n",
    "            save_path=save_path\n",
    "        )\n",
    "        loaded_models[model_name] = loaded_model\n",
    "    return loaded_models\n",
    "\n",
    "os_trained_models = load_all_trained_models(os_configs, title=\"OS\", save_path=\"src/models/trained_models\")\n",
    "pfs_trained_models = load_all_trained_models(pfs_configs, title=\"PFS\", save_path=\"src/models/trained_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c720f46-894f-4c4a-a22a-8e6997afb1c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature Importance\n",
    "\n",
    "Once the Random Survival Forest (RSF) and Gradient Boosting Survival Model (GBM) have been trained, we can extract feature importance scores. These importance scores help us identify which features most strongly influence survival predictions. High importance scores mean the feature plays a significant role in splitting the data and improving the model’s predictive power.\n",
    "\n",
    "For complex, non-linear models such as DeepSurv, DeepHit, and other neural network-based models, we will use SHAP. SHAP values provide a consistent and locally accurate measure of feature importance for individual predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443da54-c635-4f62-8c24-d0c44b19e5bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Still busy with implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cbb53f-7bfa-4c9f-bf05-3f0582e543b8",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "To ensure optimal model performance and interpretability, we apply feature selection methods tailored to the model type:\n",
    "- **CoxPH**: Identify significant linear predictors using hazard ratios and p-values.\n",
    "- **Tree-Based Models (RSF, GradientBoosting)**: Use feature importance scores to retain only the most influential variables.\n",
    "- **Neural Models (DeepSurv, DeepHit, PCHazard, MTLR)**: Apply regularization techniques (e.g., Elastic Net) to encourage sparse solutions and reduce unnecessary complexity.\n",
    "\n",
    "By combining these approaches, we refine the input space to only include variables that provide meaningful predictive value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e2b097-d37e-4bda-be06-752b7fef9ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Still needs to be implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cfc2de-8126-4ccc-ae60-b846528673a4",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "\n",
    "Hyperparameter optimization is performed for each model using a defined grid of parameters. The `random_parameter_search` function samples configurations to identify the optimal parameters for each model (can be found in `models/hyperparameter_optimization`). This ensures that models achieve their best performance for the given data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c208e0c-00eb-47dd-a74b-bf3e021cb4da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(query, event_col, duration_col, features, metric_comparison):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, encoded_columns = get_data(query, event_col, duration_col, features)\n",
    "          \n",
    "    models = {\n",
    "        'DeepSurv': DeepSurv(input_size=X_train.shape[1]),\n",
    "        'LogisticHazardModel': LogisticHazardModel(input_size=X_train.shape[1]),\n",
    "        'DeepHitModel': DeepHitModel(input_size=X_train.shape[1]), \n",
    "        'PCHazardModel': PCHazardModel(input_size=X_train.shape[1]), \n",
    "        'MTLRModel': MTLRModel(input_size=X_train.shape[1]),\n",
    "        'AalenAdditive': AalenAdditiveModel(),\n",
    "        'CoxPH': CoxPHModel(),\n",
    "        'RandomSurvivalForest': RandomSurvivalForestModel(),\n",
    "        'GradientBoosting': GradientBoostingSurvivalModel(),\n",
    "    }\n",
    "    \n",
    "    best_models, all_results = hyperparameter_search(\n",
    "        X_train, y_train, X_test, y_test,\n",
    "        treatment_col='systemicTreatmentPlan', encoded_columns=encoded_columns,\n",
    "        event_col=event_col, duration_col=duration_col,\n",
    "        base_models=models, param_grids=param_grids, metric_comparison=metric_comparison\n",
    "    )\n",
    "       \n",
    "    return best_models, all_results         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf478771-030d-41ed-a26e-f91ac670995f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_best_models, os_results = optimize_hyperparameters(query, event_col = 'hadSurvivalEvent', duration_col = 'observedOsFromTreatmentStartDays', features = features, metric_comparison='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b83205-fa98-4c80-abeb-32d149528523",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfs_best_models, pfs_results = optimize_hyperparameters(query, event_col = 'hadProgressionEvent', duration_col = 'observedPfsDays', features=features, metric_comparison='auc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prediction_env)",
   "language": "python",
   "name": "prediction_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
