{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d61ed0d-783d-45f7-99a2-f3c87dbccfc2",
   "metadata": {},
   "source": [
    "# Predictive Algorithms for Survival Analysis\n",
    "\n",
    "This notebook demonstrates the pipeline for developing and evaluating predictive algorithms in survival analysis. The primary objective is to model and predict **overall survival (OS)** and **progression-free survival (PFS)** for patients. Using both classical statistical methods and state-of-the-art deep learning techniques, the notebook covers the entire process, including:\n",
    "- Data Preprocessing: Preparing survival datasets for analysis, ensuring compatibility with various model types.\n",
    "- Model Training: Building survival models tailored to predict survival outcomes and handle censored data.\n",
    "- Hyperparameter Optimization: Fine-tuning models for optimal performance.\n",
    "- Performance Evaluation: Comparing models based on metrics such as concordance index (C-Index), integrated Brier score (IBS), calibration error (CE), and time-dependent AUC.\n",
    "- Visualization: Generating survival curves and feature importance plots to interpret model predictions and uncover key insights.\n",
    "\n",
    "This workflow provides a framework to explore survival modeling techniques and tailor them to specific datasets and objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00789d13-178f-42bd-81a8-947b666139f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b78c7cb-fe63-46a0-9873-be7edde348b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.models import *\n",
    "from src.data.data_processing import DataSplitter, DataPreprocessor\n",
    "from src.data.lookups import LookupManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f5b2e-bc29-4325-8a49-63bac2552dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_config_path = '/home/jupyter/.my.cnf'\n",
    "db_name = 'actin_personalization'\n",
    "query = \"SELECT * FROM knownPalliativeTreatments\"\n",
    "\n",
    "preprocessor = DataPreprocessor(db_config_path, db_name)\n",
    "\n",
    "lookup_manager = LookupManager()\n",
    "features = lookup_manager.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d87935-155b-40c6-8edc-d7c8326d2ef5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In this section, we set up the data pipeline for survival analysis. The `DataSplitter` and `DataPreprocessor` classes are used to load, preprocess, and split the data into training and testing sets. This ensures the survival data is structured appropriately for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a8049d-485b-4da4-913f-510906547b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sksurv.util import Surv\n",
    "\n",
    "def get_data(query, event_col, duration_col, features):\n",
    "    splitter = DataSplitter(test_size=0.1, random_state=42)\n",
    "    \n",
    "    df, features, encoded_columns = preprocessor.preprocess_data(query, duration_col, event_col, features)\n",
    "                          \n",
    "    y = Surv.from_dataframe(event=event_col, time=duration_col, data=df)\n",
    "    X_train, X_test, y_train, y_test = splitter.split(df[features], df, event_col, encoded_columns)\n",
    "    \n",
    "    return df, X_train, X_test, y_train, y_test, encoded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfbf72a-d031-43fe-ae55-812bb0cbef2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_df, os_X_train, os_X_test, os_y_train, os_y_test, os_encoded_columns = get_data(\n",
    "    query, 'hadSurvivalEvent', 'observedOsFromTreatmentStartDays', features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93219473-6d01-4c4b-a626-e7cca02008fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pfs_df, pfs_X_train, pfs_X_test, pfs_y_train, pfs_y_test, pfs_encoded_columns = get_data(\n",
    "    query, 'hadProgressionEvent', 'observedPfsDays', features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504d62f-a330-402b-b58e-a3b3f74a9658",
   "metadata": {},
   "source": [
    "## Train and Evaluate Models\n",
    "\n",
    "This section defines the function `train_evaluate_models`, which trains various survival models using predefined configurations. The trained models are evaluated using the following metrics:\n",
    "\n",
    "- **C-Index**: The Concordance Index measures how well the predicted survival times align with the actual outcomes. It is a measure of discrimination, indicating the model's ability to correctly rank the survival times of patients. A higher value indicates better predictive accuracy.\n",
    "\n",
    "- **Integrated Brier Score (IBS)**: This metric evaluates the accuracy of the survival probability predictions over time. It combines the squared differences between predicted and actual survival probabilities, weighted by the survival distribution. Lower values indicate better predictive performance.\n",
    "\n",
    "- **Calibration Error (CE)**: Calibration error assesses how well the predicted survival probabilities match the observed probabilities. It indicates whether the model is systematically overestimating or underestimating survival probabilities. Lower values signify better calibration.\n",
    "\n",
    "- **Area Under the Curve (AUC)**: For survival models, AUC is typically computed over a time-dependent ROC curve, reflecting the model's discrimination ability at different time points. Higher AUC values indicate better overall performance.\n",
    "\n",
    "Together, these metrics provide a comprehensive evaluation of the models' predictive performance, capturing different aspects of accuracy, discrimination, and calibration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71536d40-de44-4f55-9e44-c1f1e3cc5fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_survival_curves_for_patient(trained_models, X_test, y_test, patient_index, event_col, duration_col, plot_title, actual_line = True):\n",
    "    \"\"\"\n",
    "    Plot survival curves for a specific patient using trained models.\n",
    "    \"\"\"\n",
    "    X_patient = X_test.iloc[[patient_index]]\n",
    "    actual_duration_days = y_test[duration_col].iloc[patient_index]\n",
    "    actual_event = y_test[event_col].iloc[patient_index]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for model_name, model in trained_models.items():\n",
    "        try:\n",
    "            surv_funcs = model.predict_survival_function(X_patient)\n",
    "\n",
    "            times = np.linspace( max(fn.x[0] for fn in surv_funcs), min(fn.x[-1] for fn in surv_funcs), 100)\n",
    "            surv_probs = np.row_stack([fn(times) for fn in surv_funcs])\n",
    "            \n",
    "            plt.step(times / 30.44, surv_probs[0], where=\"post\", label=model_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting survival curves for model {model_name}: {e}\")\n",
    "\n",
    "    if actual_line:\n",
    "        marker_color = 'red' if actual_event else 'blue'\n",
    "        marker_label = \"Event Time\" if actual_event else \"Censoring Time\"\n",
    "        \n",
    "        plt.axvline(x=actual_duration_days / 30.44, color=marker_color, linestyle='--', label=marker_label)\n",
    "\n",
    "    plt.title(f\"Predicted {plot_title} Curves\")\n",
    "    plt.xlabel(\"Time (months)\")\n",
    "    plt.ylabel(\"Survival Probability\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9317cc-59e1-430f-8e93-d3e10257d308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def train_evaluate_models(query, event_col, duration_col, features, configs, title, patient_index = 78, save_models=False):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, encoded_columns = get_data(query, event_col, duration_col, features)\n",
    "    \n",
    "    models = {}        \n",
    "    for model_name, (model_class, model_kwargs) in configs.items():\n",
    "        if issubclass(model_class, NNSurvivalModel):\n",
    "            model_kwargs['input_size'] = X_train.shape[1]\n",
    "        models[model_name] = model_class(**model_kwargs)\n",
    "    \n",
    "    trainer = ModelTrainer(models=models, n_splits=5, random_state=42)\n",
    "\n",
    "    results, trained_models = trainer.train_and_evaluate(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        encoded_columns=encoded_columns,\n",
    "        event_col= event_col,\n",
    "        duration_col= duration_col, \n",
    "        title = title, \n",
    "        save_models = save_models\n",
    "    )\n",
    "    \n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "    results_df.reset_index(inplace=True)\n",
    "    results_df.rename(columns={'index': 'Model'}, inplace=True)\n",
    "    \n",
    "    if save_models:\n",
    "        save_path = \"src/models/trained_models\"\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        csv_file = os.path.join(save_path, f\"{title}_model_outcomes.csv\")\n",
    "        if os.path.exists(csv_file):\n",
    "            existing_df = pd.read_csv(csv_file)\n",
    "            merged_df = pd.concat([existing_df, results_df]).drop_duplicates(\n",
    "                subset=['Model'], keep='last'\n",
    "            )\n",
    "            merged_df.to_csv(csv_file, index=False)\n",
    "            print(f\"Updated model outcomes saved to {csv_file}\")\n",
    "        else:\n",
    "            results_df.to_csv(csv_file, index=False)\n",
    "            print(f\"Model outcomes saved to {csv_file}\")\n",
    "    \n",
    "    plot_survival_curves_for_patient(trained_models, X_test, y_test, patient_index, event_col, duration_col, title)\n",
    "    \n",
    "    return results_df, trained_models\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32032079-2e45-443b-ad67-1721f39c2c4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Best Model Configurations\n",
    "\n",
    "The best configurations for OS and PFS models were determined using hyperparameter optimization, as defined below in this notebook. These configurations are used to instantiate the models for training and evaluation. The best configurations for the OS and PFS models are stored in `models/model_configurations`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35973037-bcc6-4556-a0b7-93c5a2e02c67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_model_outcomes, os_trained_models =  train_evaluate_models(query, event_col='hadSurvivalEvent', duration_col='observedOsFromTreatmentStartDays', features=features, configs=os_configs, title=\"OS\", save_models=True)\n",
    "os_model_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab611cb-e5de-4c00-abae-9fbf35c6ceb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pfs_model_outcomes, pfs_trained_models = train_evaluate_models(query, event_col='hadProgressionEvent', duration_col='observedPfsDays', features=features, configs=pfs_configs, title=\"PFS\", save_models=True)\n",
    "pfs_model_outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349b5de-8790-4b51-9882-8f4ce982de3a",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f3ce52-cd89-4fb4-89fa-fc8def4cf880",
   "metadata": {},
   "source": [
    "### Metric comparison: OS vs. PFS\n",
    "\n",
    "This section visualizes the comparison of model performance metrics (C-Index, IBS, CE, AUC) for OS and PFS. The bar plots highlight the strengths and weaknesses of each model in the two prediction tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e27ec-61fa-47db-9b2b-54dd89f5bdf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_model_outcomes(title, save_path=\"src/models/trained_models\"):\n",
    "    csv_file = os.path.join(save_path, f\"{title}_model_outcomes.csv\")\n",
    "    \n",
    "    if os.path.exists(csv_file):\n",
    "        results_df = pd.read_csv(csv_file)\n",
    "        print(f\"Loaded model outcomes from {csv_file}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"No saved outcomes found for {title} in {save_path}\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2a7c0-6b93-4d75-b5c3-87b83c41e138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_model_outcomes = load_model_outcomes(\"OS\")\n",
    "pfs_model_outcomes = load_model_outcomes(\"PFS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b6bc68-84e8-4386-9a1f-cc8e1d409e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_model_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc5e8c4-3b63-4569-840a-0d33231b7779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pfs_model_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c109ba-8bd2-47a1-8ade-3b63cbcb14b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "\n",
    "def extract_holdout_metrics(df):\n",
    "    if df['holdout'].apply(lambda x: isinstance(x, str)).any():\n",
    "        df['holdout'] = df['holdout'].apply(ast.literal_eval)\n",
    "    \n",
    "    holdout_metrics = df['holdout'].apply(pd.Series)\n",
    "    holdout_metrics['Model'] = df['Model']\n",
    "    \n",
    "    return holdout_metrics\n",
    "\n",
    "def plot_all_metrics(pfs_df, os_df, holdout=True):\n",
    "       \n",
    "    if holdout:\n",
    "        pfs_df = extract_holdout_metrics(pfs_df)\n",
    "        os_df = extract_holdout_metrics(os_df)\n",
    "    \n",
    "    pfs_df['Type'] = 'PFS'\n",
    "    os_df['Type'] = 'OS'\n",
    "\n",
    "    combined_df = pd.concat([pfs_df, os_df], ignore_index=True)\n",
    "\n",
    "    metrics = ['c_index', 'ibs', 'ce', 'auc']\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i]\n",
    "        sns.barplot(\n",
    "            x='Model',\n",
    "            y=metric,\n",
    "            hue='Type',\n",
    "            data=combined_df,\n",
    "            ax=ax,\n",
    "            palette='Set1'\n",
    "        )\n",
    "        ax.set_title(f'{metric.upper()} Comparison: OS vs. PFS')\n",
    "        ax.set_xlabel('Model')\n",
    "        ax.set_ylabel(metric.upper())\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "        ax.legend(title='Type', loc='best')\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f799e6a-4946-4187-b087-dde792f84752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_all_metrics(pfs_model_outcomes, os_model_outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872752ce-54d4-45bb-a775-418a0159daee",
   "metadata": {},
   "source": [
    "### Import Trained Models\n",
    "The pretrained models are stored in the Google Cloud Storage bucket: `gs://actin-personalization-models-v1/trained_models/`. \n",
    "\n",
    "To download the saved models from the bucket to the trained_models map, run the following command in your terminal:\n",
    "\n",
    "`gsutil -m cp -r gs://actin-personalization-models-v1/trained_models/./trained_models/`\n",
    "\n",
    "Make sure the trained_models folder is inside the models folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bad84d-bd4b-4d9d-a663-cb281dcacc04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "from src.models.survival_models import NNSurvivalModel\n",
    "\n",
    "def load_trained_model(model_name, title, model_class, model_kwargs={}, save_path=\"src/models/trained_models\"):\n",
    "    model_file_prefix = os.path.join(save_path, f\"{title}_{model_name}\")\n",
    "    nn_file = model_file_prefix + \".pt\"\n",
    "    sk_file = model_file_prefix + \".pkl\"\n",
    "    \n",
    "    if model_name in ['AalenAdditive', 'CoxPH', 'RandomSurvivalForest', 'GradientBoosting']:\n",
    "        with open(sk_file, \"rb\") as f:\n",
    "            model = dill.load(f)\n",
    "        print(f\"Model {model_name} loaded from {sk_file}\")\n",
    "        return model\n",
    "    else:\n",
    "        if 'input_size' not in model_kwargs:\n",
    "            model_kwargs['input_size'] = 100\n",
    "        model = model_class(**model_kwargs)\n",
    "    \n",
    "        model.model.net.load_state_dict(torch.load(nn_file, map_location=torch.device('cpu')))\n",
    "        model.model.net.eval()\n",
    "        print(f\"Model {model_name} loaded from {nn_file}\")\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e627c-9d7f-4707-acc8-08298d790452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_all_trained_models(model_specs, title, save_path=\"src/models/trained_models\"):\n",
    "    loaded_models = {}\n",
    "    for model_name, (model_class, model_kwargs) in model_specs.items():\n",
    "        loaded_model = load_trained_model(\n",
    "            model_name=model_name, \n",
    "            title=title, \n",
    "            model_class=model_class, \n",
    "            model_kwargs=model_kwargs, \n",
    "            save_path=save_path\n",
    "        )\n",
    "        loaded_models[model_name] = loaded_model\n",
    "    return loaded_models\n",
    "\n",
    "os_trained_models = load_all_trained_models(os_configs, title=\"OS\", save_path=\"src/models/trained_models\")\n",
    "pfs_trained_models = load_all_trained_models(pfs_configs, title=\"PFS\", save_path=\"src/models/trained_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337edebf-e6a2-4abe-84ae-13b879563003",
   "metadata": {},
   "source": [
    "### Time-Dependent ROC-AUC\n",
    "\n",
    "This section visualizes the ROC curves and computes the AUC for survival models at specific time intervals for both OS and PFS. By evaluating the models' discriminative performance over time, we identify which models perform best at different prediction horizons.\n",
    "\n",
    "Time interval:\n",
    "- **Overall Survival (OS)**: For OS, the follow-up times in the dataset extend up to 5 years, allowing us to evaluate model performance over this longer horizon. As survival outcomes often have a broader timespan, a 5-year evaluation provides a comprehensive view of the model's ability to predict long-term survival.\n",
    "\n",
    "- **Progression-Free Survival (PFS)**: In contrast, PFS events typically occur sooner than OS events. The maximum PFS duration in the dataset is less than 5 years for most patients, with very few outliers exceeding 4 years. Using a 5-year horizon for PFS would skew the evaluation by focusing on a small subset of patients, potentially leading to unreliable results. Instead, we limit the PFS analysis to 3 years, which encompasses the majority of observed progression events while maintaining meaningful statistical power.\n",
    "\n",
    "The ROC curves for the best-performing models (Gradient Boosting, CoxPH, DeepSurv, and RSF) are plotted for each time interval, showcasing how well the models distinguish patients at risk across the respective timeframes for OS and PFS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cccb8e-0024-41f8-9321-f41d48b7ce93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "\n",
    "def calculate_time_dependent_auc_for_models(model_dict, X_train, y_train, X_test, y_test, duration_col, event_col, time_points, title=\"Time-Dependent AUC\"):\n",
    "    \n",
    "    y_train_df = pd.DataFrame({'duration': y_train[duration_col], 'event': y_train[event_col]}, index=X_train.index)\n",
    "    y_train_structured = Surv.from_dataframe('event', 'duration', y_train_df)\n",
    "\n",
    "    y_test_df = pd.DataFrame({'duration': y_test[duration_col], 'event': y_test[event_col]}, index=X_test.index)\n",
    "    y_test_structured = Surv.from_dataframe('event', 'duration', y_test_df)\n",
    "\n",
    "    auc_results = {}\n",
    "\n",
    "    for model_name, model in model_dict.items():\n",
    "        model_class = type(model)\n",
    "        if issubclass(model_class, NNSurvivalModel):\n",
    "            risk_scores = model.model.predict(X_test.values.astype('float32'), is_dataloader=False).ravel()\n",
    "        else:\n",
    "            risk_scores = model.predict(X_test).ravel()\n",
    "\n",
    "        auc_values, mean_auc = cumulative_dynamic_auc(y_train_structured, y_test_structured, risk_scores, time_points)\n",
    "        auc_results[model_name] = (auc_values, mean_auc)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    years = [t / 365 for t in time_points]\n",
    "    for model_name, (auc_values, mean_auc) in auc_results.items():\n",
    "        plt.plot(years, auc_values, label=f\"{model_name} (Mean AUC={mean_auc:.3f})\", marker='o')\n",
    "\n",
    "    plt.xlabel(\"Time (years)\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return auc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7639369-8b42-442d-ab01-c60138daca29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_models_to_plot = {\n",
    "    \"GradientBoosting\": os_trained_models[\"GradientBoosting\"],\n",
    "    \"CoxPH\": os_trained_models[\"CoxPH\"],\n",
    "    \"DeepSurv\": os_trained_models[\"DeepSurv\"],\n",
    "    \"RandomSurvivalForest\": os_trained_models[\"RandomSurvivalForest\"]\n",
    "}\n",
    "\n",
    "os_time_points = [int(round(i * 365 / 4)) for i in range(1, 21)] # Every 3 months (up to 5 years)\n",
    "\n",
    "calculate_time_dependent_auc_for_models(\n",
    "    os_models_to_plot, os_X_train, os_y_train, os_X_test, os_y_test, \n",
    "    duration_col=\"observedOsFromTreatmentStartDays\", \n",
    "    event_col=\"hadSurvivalEvent\", \n",
    "    time_points=os_time_points, \n",
    "    title=\"OS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32710eb4-c3b2-4c6d-bffa-78785613f60f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pfs_models_to_plot = {\n",
    "    \"GradientBoosting\": pfs_trained_models[\"GradientBoosting\"],\n",
    "    \"CoxPH\": pfs_trained_models[\"CoxPH\"],\n",
    "    \"DeepSurv\": pfs_trained_models[\"DeepSurv\"],\n",
    "    \"RandomSurvivalForest\": pfs_trained_models[\"RandomSurvivalForest\"]\n",
    "}\n",
    "\n",
    "pfs_time_points = [int(round(i * 365 / 4)) for i in range(1, 13)] # Every 3 months (up to 3 years)\n",
    "\n",
    "calculate_time_dependent_auc_for_models(\n",
    "    pfs_models_to_plot, pfs_X_train, pfs_y_train, pfs_X_test, pfs_y_test, \n",
    "    duration_col=\"observedPfsDays\", \n",
    "    event_col=\"hadProgressionEvent\", \n",
    "    time_points=pfs_time_points, \n",
    "    title=\"PFS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1891e14b-ef35-496d-8030-e08d08095e9a",
   "metadata": {},
   "source": [
    "### Performance per Treatment\n",
    "To assess model performance across treatment groups, we evaluate metrics for each treatment. For every treatment column, the dataset is filtered to include only the relevant patients. The model generates survival or risk predictions for these patients, and metrics are calculated based on their outcomes.\n",
    "\n",
    "**Note on inflated metrics:**\n",
    "Since we evaluate the model on the full dataset, including data it was trained on, the performance metrics might be inflated compared to an evaluation on unseen test data. This occurs because the model has already seen and learned from some of these patients during training.\n",
    "\n",
    "**Why this is still useful**\n",
    "Despite the potential inflation, this approach remains valuable for exploring the modelâ€™s predictions across different treatment groups. It allows us to identify patterns, strengths, or weaknesses in how the model handles specific treatments, which can guide further refinements or highlight treatment groups requiring more robust predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1808b046-4a86-4bdd-9eb1-bf27f07f0253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def binarize_scaled_treatment_cols(X: pd.DataFrame, col_prefix=\"systemicTreatmentPlan\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Given an X DataFrame where certain columns named like\n",
    "    'systemicTreatmentPlan_*' have been scaled but originally were binary (0/1),\n",
    "    map them back to 0/1.\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    treatment_cols = [c for c in X.columns if col_prefix in c]\n",
    "    \n",
    "    for col in treatment_cols:\n",
    "        unique_vals = sorted(X[col].unique())\n",
    "        if len(unique_vals) == 2:\n",
    "            low_val, high_val = unique_vals\n",
    "            X[col] = X[col].apply(\n",
    "                lambda x: 1 if abs(x - high_val) < 1e-8 else 0\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Warning: {col} has {len(unique_vals)} distinct values, cannot binarize cleanly.\")\n",
    "    \n",
    "    return X\n",
    "\n",
    "def evaluate_model_by_treatment(\n",
    "    model, df, duration_col, event_col, model_name, col_prefix='systemicTreatmentPlan'\n",
    "):\n",
    "    trainer = ModelTrainer(models={}, n_splits=5, random_state=42)\n",
    "\n",
    "    treatment_cols = [col for col in df.columns if col_prefix in col]\n",
    "    results_list = []\n",
    "\n",
    "    y_df = pd.DataFrame({\n",
    "        \"duration\": df[duration_col],\n",
    "        \"event\": df[event_col].astype(bool)\n",
    "    }, index=df.index)\n",
    "    y_struct = Surv.from_dataframe(\"event\", \"duration\", y_df)\n",
    "\n",
    "    for t_col in treatment_cols:\n",
    "        X_sub = df[df[t_col] == 1].drop(columns=[event_col, duration_col])\n",
    "        y_sub = y_df.loc[X_sub.index]\n",
    "        \n",
    "        y_sub_struct = Surv.from_dataframe(\"event\", \"duration\", y_sub)\n",
    "\n",
    "        metrics = trainer._evaluate_model(\n",
    "            model=model,\n",
    "            X_val=X_sub,\n",
    "            y_train_structured=y_struct, \n",
    "            y_val_structured=y_sub_struct,\n",
    "            model_name=model_name\n",
    "        )\n",
    "\n",
    "        results_list.append({\n",
    "            \"treatment_column\": t_col,\n",
    "            \"patient_count\": len(X_sub),\n",
    "            **metrics\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c57650-b563-4089-9feb-71b03bf8f314",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_models_to_evaluate = {\n",
    "    \"GradientBoosting\": os_trained_models[\"GradientBoosting\"],\n",
    "    \"RandomSurvivalForest\": os_trained_models[\"RandomSurvivalForest\"]\n",
    "}\n",
    "\n",
    "os_df = binarize_scaled_treatment_cols(os_df)\n",
    "\n",
    "for model_name, model_instance in os_models_to_evaluate.items():\n",
    "    results_df = evaluate_model_by_treatment(\n",
    "        model=model_instance,\n",
    "        df=os_df,\n",
    "        duration_col='observedOsFromTreatmentStartDays',\n",
    "        event_col='hadSurvivalEvent',\n",
    "        model_name=model_name\n",
    "    )\n",
    "    print(f\"Metrics per treatment for {model_name}:\\n\", results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca3978-ed07-4c1b-9c0e-dccc7e834dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pfs_models_to_evaluate = {\n",
    "    \"GradientBoosting\": pfs_trained_models[\"GradientBoosting\"],\n",
    "    \"RandomSurvivalForest\": pfs_trained_models[\"RandomSurvivalForest\"]\n",
    "}\n",
    "\n",
    "pfs_df = binarize_scaled_treatment_cols(pfs_df)\n",
    "\n",
    "for model_name, model_instance in pfs_models_to_evaluate.items():\n",
    "    results_df = evaluate_model_by_treatment(\n",
    "        model=model_instance,\n",
    "        df=pfs_df,\n",
    "        duration_col='observedPfsDays',\n",
    "        event_col='hadProgressionEvent',\n",
    "        model_name=model_name\n",
    "    )\n",
    "    print(f\"Metrics per treatment for {model_name}:\\n\", results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad4b5b0-2b9e-4668-b0f4-3a637ec18c59",
   "metadata": {},
   "source": [
    "## Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c720f46-894f-4c4a-a22a-8e6997afb1c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature Importance\n",
    "\n",
    "Feature importance analysis helps us identify which features most strongly influence survival predictions across various models. In this section SHAP (SHapley Additive exPlanations) is used for all models to ensure uniformity and interpretability. SHAP values provide a consistent and locally accurate measure of feature importance for individual predictions.\n",
    "\n",
    "How SHAP is used:\n",
    "- For classical models like CoxPH and Aalen Additive, SHAP values are calculated based on risk scores or cumulative hazard coefficients. Custom prediction functions are used when necessary (e.g., for Aalen Additive) to align feature importance with model-specific outputs.\n",
    "- For tree-based models like Random Survival Forest (RSF) and Gradient Boosting Survival Model (GBM), SHAP values replace traditional feature importance metrics to ensure consistency.\n",
    "- For neural network-based models like DeepSurv and DeepHit, SHAP values are derived using the model's prediction function.\n",
    "\n",
    "#### Visualization\n",
    "SHAP provides the following insights:\n",
    "- Summary Plot - Bar: Displays the average magnitude of SHAP values for each feature, indicating the overall importance of features in the model.\n",
    "- Summary Plot - Dot: Highlights the distribution of SHAP values for each feature, showing their impact across different samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443da54-c635-4f62-8c24-d0c44b19e5bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "def nn_predict(X, model, X_train):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X, columns=X_train.columns)\n",
    "    X_tensor = X.values.astype('float32')\n",
    "    return model.model.predict(X_tensor)\n",
    "\n",
    "def custom_aalen_predict(X, model):\n",
    "    \"\"\"\n",
    "    Custom predict function for AalenAdditiveModel.\n",
    "    Aligns cumulative hazard coefficients with input features.\n",
    "    \"\"\"\n",
    "    cumulative_coefs = model.model.cumulative_hazards_\n",
    "    X = X[model.selected_features].copy()\n",
    "\n",
    "    # Interpolate coefficients at the latest time point\n",
    "    latest_coefs = cumulative_coefs.iloc[-1].values\n",
    "    \n",
    "    if len(latest_coefs) > X.shape[1]:\n",
    "        X = X.copy()\n",
    "        X.insert(0, \"Intercept\", 1.0)  \n",
    "\n",
    "    X_array = X.values\n",
    "    risk_scores = np.einsum('ij,j->i', X_array, latest_coefs)\n",
    "    return risk_scores\n",
    "\n",
    "def shap_interpret_model(model_name, model, X_train, max_features=20, shap_sample=200):\n",
    "\n",
    "    X_sample = X_train.sample(min(shap_sample, len(X_train)), random_state=42)\n",
    "\n",
    "    predict_functions = {\n",
    "        'AalenAdditive': lambda X: custom_aalen_predict(X, model),\n",
    "        'default': model.predict\n",
    "    }\n",
    "\n",
    "    if model_name == 'AalenAdditive':\n",
    "        prediction_fn = predict_functions['AalenAdditive']\n",
    "    else:\n",
    "        try:\n",
    "            model.predict(X_sample.head(1))\n",
    "            prediction_fn = predict_functions['default']\n",
    "        except:\n",
    "            prediction_fn = lambda x: nn_predict(x, model, X_train)\n",
    "\n",
    "    explainer = shap.Explainer(prediction_fn, X_sample)\n",
    "    shap_values = explainer(X_sample)\n",
    "\n",
    "    print(f\"SHAP Summary for {model_name}:\")\n",
    "\n",
    "    if len(shap_values.values.shape) == 3: #If time dimension present\n",
    "        aggregated_shap = shap_values.values.mean(axis=1)\n",
    "        shap.summary_plot(aggregated_shap, features=X_sample, plot_type=\"bar\", max_display=max_features)\n",
    "        shap.summary_plot(aggregated_shap, features=X_sample, max_display=max_features)\n",
    "    else:\n",
    "        shap.summary_plot(shap_values, features=X_sample, plot_type=\"bar\", max_display=max_features)\n",
    "        shap.summary_plot(shap_values, features=X_sample, max_display=max_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc39cc-ef1f-4c13-9ea2-cb530ed03666",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_instance in os_trained_models.items():\n",
    "    print(f\"\\n--- Interpreting {model_name} ---\")\n",
    "    shap_interpret_model(model_name, model_instance, os_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318bafc-6b24-4c76-a79e-9821dc254b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_instance in pfs_trained_models.items():\n",
    "    print(f\"\\n--- Interpreting {model_name} ---\")\n",
    "    shap_interpret_model(model_name, model_instance, pfs_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e861f-eb6d-4e14-9a66-e041a032eeb6",
   "metadata": {},
   "source": [
    "### Model Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa24f9-32ef-4a06-a01b-8685750e5314",
   "metadata": {},
   "source": [
    "#### Comparison of Treatments\n",
    "In this section the predicted survival probabilities are visualized for a single patient under different treatment scenarios. By simulating the patient receiving each available treatment, we can compare how the model predicts their survival trajectory across treatments.\n",
    "\n",
    "This analysis provides insights into the model's predictions for different treatment options, helping to identify potentially better treatment choices for the patient based on the predicted survival probabilities over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f358949-9dc1-4363-ac98-c771ddba4287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_survival_curves_for_all_treatments(model, X_test, y_test, patient_index, event_col, duration_col, col_prefix='systemicTreatmentPlan', plot_title='Survival Curves by Treatment'):\n",
    "\n",
    "    X_patient_original = X_test.iloc[[patient_index]].copy()\n",
    "    actual_duration = y_test.loc[X_patient_original.index, duration_col].values[0]\n",
    "    actual_event = y_test.loc[X_patient_original.index, event_col].values[0]\n",
    "    \n",
    "    treatment_cols = [col for col in X_test.columns if col_prefix in col]\n",
    "    \n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(treatment_cols)))\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    times = np.arange(1, 1826, 30)\n",
    "\n",
    "    for i, t_col in enumerate(treatment_cols):\n",
    "        X_patient = X_patient_original.copy()\n",
    "\n",
    "        for col in treatment_cols:\n",
    "            X_patient[col] = 0\n",
    "            \n",
    "        X_patient[t_col] = 1\n",
    "\n",
    "        surv_funcs = model.predict_survival_function(X_patient) \n",
    "            \n",
    "        plt.step(times, surv_funcs[0](times), where=\"post\", label=t_col[len(col_prefix) + 1:], color=colors[i])\n",
    "\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(\"Time (days)\")\n",
    "    plt.ylabel(\"Survival Probability\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624c3262-7f8d-49e2-b2ec-100c4f1b2dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_best_model = \"RandomSurvivalForest\"\n",
    "plot_survival_curves_for_all_treatments(\n",
    "    model=os_trained_models[os_best_model],\n",
    "    X_test=os_X_test,\n",
    "    y_test=os_y_test,\n",
    "    patient_index=100,\n",
    "    event_col=\"hadSurvivalEvent\",\n",
    "    duration_col=\"observedOsFromTreatmentStartDays\",\n",
    "    col_prefix=\"systemicTreatmentPlan\",\n",
    "    plot_title=f\"OS: One Patient, All Treatments ({os_best_model})\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c19f8-310c-4822-b410-5ce8d0969607",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pfs_best_model = \"GradientBoosting\"\n",
    "plot_survival_curves_for_all_treatments(\n",
    "    model=pfs_trained_models[pfs_best_model],\n",
    "    X_test=pfs_X_test,\n",
    "    y_test=pfs_y_test,\n",
    "    patient_index=100,\n",
    "    event_col=\"hadProgressionEvent\",\n",
    "    duration_col=\"observedPfsDays\",\n",
    "    col_prefix=\"systemicTreatmentPlan\",\n",
    "    plot_title=f\"PFS: One Patient, All Treatments ({pfs_best_model})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9634b15-ade7-43c9-b43f-d2349fb39ed6",
   "metadata": {},
   "source": [
    "#### Comparison of Models\n",
    "Next, we focus on the patient's actual treatment choice and compare the predictions from the two best-performing models. By evaluating the survival curves generated by both models for the chosen treatment, we assess their agreement and gain a deeper understanding of the patient-specific predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09eefb-7704-475d-8845-c536440e5f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_survival_curves_for_patient(\n",
    "    trained_models=os_models_to_evaluate,\n",
    "    X_test=os_X_test,\n",
    "    y_test=os_y_test,\n",
    "    patient_index=101,\n",
    "    event_col=\"hadSurvivalEvent\",\n",
    "    duration_col=\"observedOsFromTreatmentStartDays\",\n",
    "    plot_title=\"OS (GradientBoosting & RSF)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f0a1a-1a87-45f5-8587-7ece380633c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_survival_curves_for_patient(\n",
    "    trained_models=pfs_models_to_evaluate,\n",
    "    X_test=pfs_X_test,\n",
    "    y_test=pfs_y_test,\n",
    "    patient_index=100,\n",
    "    event_col=\"hadProgressionEvent\",\n",
    "    duration_col=\"observedPfsDays\",\n",
    "    plot_title=\"PFS (GradientBoosting & RSF)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cbb53f-7bfa-4c9f-bf05-3f0582e543b8",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Explicit feature selection is applied to CoxPH and Aalen Additive model to improve interpretability and reduce noise:\n",
    "\n",
    "- `CoxPH`: \n",
    "    - Features with high p-values (non-significant) are removed.\n",
    "    - Multicollinearity is addressed by excluding highly correlated predictors.\n",
    "- `Aalen Additive`:\n",
    "    - Features with low cumulative impact (mean absolute coefficients near zero) are excluded.\n",
    "    \n",
    "Other models, such as tree-based or neural survival models, inherently manage feature selection through their architecture or regularization techniques, making explicit feature filtering unnecessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06dae5a-17b2-4640-83a2-0fc9a02073f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select_coxph(model, X_train, threshold=0.01):\n",
    "    \"\"\"\n",
    "    For CoxPH: Remove features with abs(coef) < threshold.\n",
    "    \"\"\"\n",
    "    if hasattr(model.model, 'coef_'):\n",
    "        coefs = model.model.coef_\n",
    "        feature_mask = np.abs(coefs) > threshold\n",
    "        retained = model.selected_features[feature_mask]\n",
    "        if len(retained) == 0:\n",
    "            retained = model.selected_features\n",
    "        return retained\n",
    "    else:\n",
    "        return model.selected_features\n",
    "\n",
    "def feature_select_aalen_additive(model, X_train, threshold=0.001):\n",
    "    \"\"\"\n",
    "    For AalenAdditive: Remove features with mean absolute cumulative coefficient < threshold.\n",
    "    \"\"\"\n",
    "    if not model.model.cumulative_hazards_.empty:\n",
    "        cum_haz = model.model.cumulative_hazards_\n",
    "        mean_abs_coefs = cum_haz.abs().mean()\n",
    "        feature_mask = mean_abs_coefs > threshold\n",
    "        retained = mean_abs_coefs.index[feature_mask]\n",
    "        \n",
    "        return retained\n",
    "    else:\n",
    "        return model.selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18ce2e-be3f-478a-8891-0eb448609bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refit_model_with_selected_features(model_name, original_model, X_train, y_train, X_test, y_test, retained_features, title, duration_col, event_col, save_models=True):\n",
    "    \"\"\"\n",
    "    Refit the given model with the selected features and evaluate it using the ModelTrainer's _evaluate_model method.\n",
    "    \"\"\"\n",
    "    \n",
    "    retained_features = [f for f in retained_features if f != \"Intercept\"]\n",
    "\n",
    "    y_train_df = pd.DataFrame({'duration': y_train[duration_col], 'event': y_train[event_col]}, index=X_train.index)\n",
    "    y_train_structured = Surv.from_dataframe('event', 'duration', y_train_df)\n",
    "\n",
    "    y_test_df = pd.DataFrame({'duration': y_test[duration_col], 'event': y_test[event_col]}, index=y_test.index)\n",
    "    y_test_structured = Surv.from_dataframe('event', 'duration', y_test_df)\n",
    "\n",
    "    # Refit the model with the reduced features\n",
    "    model_class = type(original_model)\n",
    "    model_kwargs = getattr(original_model, 'kwargs', {})\n",
    "    new_model = model_class(**model_kwargs)\n",
    "    new_model.fit(X_train[retained_features], y_train_structured)\n",
    "\n",
    "    trainer = ModelTrainer(models={}, n_splits=5, random_state=42)\n",
    "    holdout_metrics = trainer._evaluate_model(\n",
    "        new_model,\n",
    "        X_test[retained_features],\n",
    "        y_train_structured,\n",
    "        y_test_structured,\n",
    "        y_test_df,\n",
    "        model_name,\n",
    "        event_col\n",
    "    )\n",
    "    print(f\"{model_name} Feature-Selected Hold-Out Results: {holdout_metrics}\")\n",
    "\n",
    "    if save_models:\n",
    "        save_new_model(new_model, model_name, title)\n",
    "\n",
    "    return new_model\n",
    "\n",
    "def save_new_model(model, model_name, title, suffix=\"_feature_selected\", save_path=\"src/models/trained_models\"):\n",
    "    new_model_name = model_name + suffix\n",
    "    model_file = os.path.join(save_path, f\"{title}_{new_model_name}\")\n",
    "    with open(model_file + \".pkl\", \"wb\") as f:\n",
    "        dill.dump(model, f)\n",
    "    print(f\"New model with feature selection saved as {title}_{new_model_name}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902a0c8-8c1b-477c-b57a-1d3fe9c90144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_and_refit(X_train, y_train, X_test, y_test, configs, duration_col, event_col, title):\n",
    "    coxph_model = load_trained_model(\"CoxPH\", title, CoxPHModel, model_kwargs=configs['CoxPH'][1])\n",
    "    aalen_model = load_trained_model(\"AalenAdditive\", title, AalenAdditiveModel, model_kwargs=configs['AalenAdditive'][1])\n",
    "    \n",
    "    coxph_retained = feature_select_coxph(coxph_model, X_train, threshold=0.01)\n",
    "    aalen_retained = feature_select_aalen_additive(aalen_model, X_train, threshold=0.001)\n",
    "\n",
    "    new_coxph_model = refit_model_with_selected_features(\n",
    "        \"CoxPH\", coxph_model, X_train, y_train, X_test, y_test,\n",
    "        coxph_retained, title, duration_col=duration_col, event_col=event_col, save_models=True\n",
    "    )\n",
    "\n",
    "    new_aalen_model = refit_model_with_selected_features(\n",
    "        \"AalenAdditive\", aalen_model, X_train, y_train, X_test, y_test,\n",
    "        aalen_retained, title, duration_col=duration_col, event_col=event_col, save_models=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8bd144-e197-4d2a-82de-da1984d82fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "select_features_and_refit(os_X_train, os_y_train, os_X_test, os_y_test, os_configs, 'observedOsFromTreatmentStartDays', 'hadSurvivalEvent', title='OS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fd531-496e-48e4-90a0-9b0cc0c88a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features_and_refit(pfs_X_train, pfs_y_train, pfs_X_test, pfs_y_test, pfs_configs, 'observedPfsDays', 'hadProgressionEvent', title='PFS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cfc2de-8126-4ccc-ae60-b846528673a4",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "\n",
    "Hyperparameter optimization is performed for each model using a defined grid of parameters. The `random_parameter_search` function samples configurations to identify the optimal parameters for each model (can be found in `models/hyperparameter_optimization`). This ensures that models achieve their best performance for the given data.\n",
    "\n",
    "After optimization the results for both OS and PFS were stored in `models/configs/model_configurations.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c208e0c-00eb-47dd-a74b-bf3e021cb4da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimize_hyperparameters(query, event_col, duration_col, features, metric_comparison):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, encoded_columns = get_data(query, event_col, duration_col, features)\n",
    "          \n",
    "    models = {\n",
    "        'DeepSurv': DeepSurv(input_size=X_train.shape[1]),\n",
    "        'LogisticHazardModel': LogisticHazardModel(input_size=X_train.shape[1]),\n",
    "        'DeepHitModel': DeepHitModel(input_size=X_train.shape[1]), \n",
    "        'PCHazardModel': PCHazardModel(input_size=X_train.shape[1]), \n",
    "        'MTLRModel': MTLRModel(input_size=X_train.shape[1]),\n",
    "        'AalenAdditive': AalenAdditiveModel(),\n",
    "        'CoxPH': CoxPHModel(),\n",
    "        'RandomSurvivalForest': RandomSurvivalForestModel(),\n",
    "        'GradientBoosting': GradientBoostingSurvivalModel(),\n",
    "    }\n",
    "    \n",
    "    best_models, all_results = hyperparameter_search(\n",
    "        X_train, y_train, X_test, y_test,\n",
    "        treatment_col='systemicTreatmentPlan', encoded_columns=encoded_columns,\n",
    "        event_col=event_col, duration_col=duration_col,\n",
    "        base_models=models, param_grids=param_grids, metric_comparison=metric_comparison\n",
    "    )\n",
    "       \n",
    "    return best_models, all_results         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf478771-030d-41ed-a26e-f91ac670995f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_best_models, os_results = optimize_hyperparameters(query, event_col = 'hadSurvivalEvent', duration_col = 'observedOsFromTreatmentStartDays', features = features, metric_comparison='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b83205-fa98-4c80-abeb-32d149528523",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfs_best_models, pfs_results = optimize_hyperparameters(query, event_col = 'hadProgressionEvent', duration_col = 'observedPfsDays', features=features, metric_comparison='auc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prediction_env)",
   "language": "python",
   "name": "prediction_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
