{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5725a415-fbbb-416d-bc89-d7269c2db226",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43006d-0322-4efe-8962-88e75e2776d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986eb0aa-e5c5-4de2-8d5d-dab2e25bd90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import dill\n",
    "import torch\n",
    "import nbimporter\n",
    "import shap\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('/data/repos/actin-personalization/prediction')\n",
    "sys.path.insert(0, os.path.abspath(\"src/main/python\"))\n",
    "\n",
    "from models import *\n",
    "from data.data_processing import DataSplitter, DataPreprocessor\n",
    "from data.lookups import lookup_manager\n",
    "from utils.settings import settings\n",
    "from src.main.python.analysis.predictive_algorithms_training import get_data, plot_different_models_survival_curves\n",
    "\n",
    "preprocessor = DataPreprocessor(settings.db_config_path, settings.db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07546771-ef45-4311-86a8-d40621301b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_preprocessed_data_with_sourceId(preprocessor):\n",
    "    df_raw = preprocessor.load_data()\n",
    "    df_all, updated_features, _ = preprocessor.preprocess_data(\n",
    "        lookup_manager.features, df=df_raw\n",
    "    )\n",
    "    df_all[\"sourceId\"] = df_raw.loc[df_all.index, \"sourceId\"]\n",
    "    #df_all[\"reasonRefrainmentFromTreatment\"] = df_raw.loc[df_all.index, \"reasonRefrainmentFromTreatment\"]\n",
    "    return df_raw, df_all, updated_features\n",
    "\n",
    "df_raw, df_all, updated_features = get_preprocessed_data_with_sourceId(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac3420-95fe-4b04-84fd-dcbe4a8fc7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('src/main/python/data/treatment_combinations.json', 'r') as f:\n",
    "    valid_treatment_combinations = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c20be5-a000-4164-ba46-476f64e4f4be",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preperation propensity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7932793-57aa-4dd2-a3f3-9dec9c8c49da",
   "metadata": {},
   "source": [
    "Exclude non covariate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb3e60-c3fd-4bd9-844d-127a63e62d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = [\n",
    "    'hadSurvivalEvent',\n",
    "    'systemicTreatmentPlan_5-FU',\n",
    "    'systemicTreatmentPlan_oxaliplatin',\n",
    "    'systemicTreatmentPlan_irinotecan',\n",
    "    'systemicTreatmentPlan_bevacizumab',\n",
    "    'systemicTreatmentPlan_panitumumab',\n",
    "    'systemicTreatmentPlan_pembrolizumab',\n",
    "    'systemicTreatmentPlan_nivolumab',\n",
    "    'hasTreatment',\n",
    "    'survivalDaysSinceMetastaticDiagnosis',\n",
    "    'investigatedLymphNodesCountPrimaryDiagnosis',\n",
    "    'hasRasMutation'\n",
    "]\n",
    "\n",
    "df_covariate = df_all.copy()\n",
    "\n",
    "#df_covariate[\"hasInvestigatedLymphNodes\"] = (\n",
    "#    df_covariate[\"investigatedLymphNodesCountPrimaryDiagnosis\"] > 0\n",
    "#)\n",
    "\n",
    "df_covariate = df_covariate.drop(columns=exclude, errors='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34db9860-b845-43ac-a870-ee1ab5e4c611",
   "metadata": {},
   "source": [
    "Create treatment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6abf6a7-a8e8-4ac4-9df9-9b2a19684ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "treatment_prefix = \"systemicTreatmentPlan_\"\n",
    "treatment_cols = [col for col in df_all.columns if col.startswith(treatment_prefix)]\n",
    "\n",
    "def extract_actual_treatment(row):\n",
    "    actual_treatments = [col for col in treatment_cols if row[col] == 1]\n",
    "    if actual_treatments:\n",
    "        return \", \".join([col.replace(treatment_prefix, \"\") for col in actual_treatments])\n",
    "    else:\n",
    "        return \"No Treatment\"\n",
    "\n",
    "df_all[\"actual_treatment\"] = df_all.apply(extract_actual_treatment, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4fb02e-b372-4de2-86b9-ba7f1cf19d1a",
   "metadata": {},
   "source": [
    "# Calculation of propensity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d366ee-6f27-4acd-aab9-2bea7ba9b1d4",
   "metadata": {},
   "source": [
    "Logistic regression based on whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce671df-0803-4b52-90fb-cb3877270cad",
   "metadata": {
    "tags": []
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "treatments = df_all[\"actual_treatment\"].astype(\"category\")\n",
    "covariates = df_covariate.copy()\n",
    "\n",
    "covariates_encoded = pd.get_dummies(covariates, drop_first=True)\n",
    "constant_cols = covariates_encoded.columns[covariates_encoded.std() == 0]\n",
    "if len(constant_cols) > 0:\n",
    "    print(f\"Dropping constant columns (for StandardScaler): {list(constant_cols)}\")\n",
    "    covariates_encoded = covariates_encoded.drop(columns=constant_cols)\n",
    "\n",
    "covariates_encoded = covariates_encoded.reset_index(drop=True)\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        multi_class=\"multinomial\",\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe.fit(covariates_encoded, treatments)\n",
    "\n",
    "propensity_probs = pipe.predict_proba(covariates_encoded)\n",
    "treatment_classes = pipe.named_steps[\"clf\"].classes_\n",
    "\n",
    "for i, label in enumerate(treatment_classes):\n",
    "    df_all[f\"propensity_{label}\"] = propensity_probs[:, i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d5e9fc-67ca-40e3-8c26-e358f44c613a",
   "metadata": {},
   "source": [
    "Logistic regression based on trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35ab78-efa8-4efb-8369-c764cc8992e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "treatments = df_all[\"actual_treatment\"].astype(\"category\")\n",
    "covariates = df_covariate.copy()\n",
    "\n",
    "covariates_encoded = pd.get_dummies(covariates, drop_first=True)\n",
    "constant_cols = covariates_encoded.columns[covariates_encoded.std() == 0]\n",
    "if len(constant_cols) > 0:\n",
    "    print(f\"Dropping constant columns (for StandardScaler): {list(constant_cols)}\")\n",
    "    covariates_encoded = covariates_encoded.drop(columns=constant_cols)\n",
    "\n",
    "covariates_encoded = covariates_encoded.reset_index(drop=True)\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "covariates_train, covariates_test, treatments_train, treatments_test = train_test_split(\n",
    "    covariates_encoded, treatments, test_size=0.2, random_state=42, stratify=treatments\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        multi_class=\"multinomial\",\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe.fit(covariates_train, treatments_train)\n",
    "\n",
    "propensity_probs = pipe.predict_proba(covariates_encoded)\n",
    "treatment_classes = pipe.named_steps[\"clf\"].classes_\n",
    "\n",
    "for i, label in enumerate(treatment_classes):\n",
    "    df_all[f\"propensity_{label}\"] = propensity_probs[:, i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35448326-7102-4358-b8ec-cdbf3d7f18a3",
   "metadata": {},
   "source": [
    "# Random patient generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd8ea55-2b3a-4900-a87c-f46973bc7942",
   "metadata": {
    "tags": []
   },
   "source": [
    "import random\n",
    "valid_ids = set(df_all['sourceId'].unique())\n",
    "\n",
    "def get_valid_random_patient_id():\n",
    "    while True:\n",
    "        random_id = random.choice(range(1, 10000000))\n",
    "        if random_id in valid_ids:\n",
    "            return random_id\n",
    "\n",
    "random_patient_id = get_valid_random_patient_id()\n",
    "print(random_patient_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c0adc-9ef3-474f-b861-d16688d3b166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "threshold_days = 2000 \n",
    "eligible_patients = df_all[\n",
    "    (df_all['hasTreatment'] == 0) &\n",
    "    (df_all['survivalDaysSinceMetastaticDiagnosis'] > threshold_days)\n",
    "]\n",
    "\n",
    "valid_ids = set(eligible_patients['sourceId'].unique())\n",
    "\n",
    "def get_valid_random_patient_id():\n",
    "    if not valid_ids:\n",
    "        raise ValueError(\"No valid patients meet the criteria.\")\n",
    "    return random.choice(list(valid_ids))\n",
    "\n",
    "random_patient_id = get_valid_random_patient_id()\n",
    "print(random_patient_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebef171-117e-48cb-b478-48995468be1c",
   "metadata": {},
   "source": [
    "# Personalized patient propensity score estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8185e4-2c7a-4ddc-9228-56ae948f3d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "patient_id = random_patient_id\n",
    "patient_id = 6774820\n",
    "row = df_all[df_all[\"sourceId\"] == patient_id]\n",
    "treatment_row = df_all[df_all[\"sourceId\"] == patient_id].squeeze()\n",
    "raw_row = df_raw[df_raw[\"sourceId\"] == patient_id].squeeze()\n",
    "\n",
    "model = pipe.named_steps[\"clf\"]\n",
    "scaler = pipe.named_steps[\"scale\"]\n",
    "feature_names = covariates_encoded.columns\n",
    "classes = model.classes_\n",
    "coef_matrix = model.coef_\n",
    "intercepts = model.intercept_\n",
    "\n",
    "propensity_cols = [col for col in df_all.columns if col.startswith(\"propensity_\")]\n",
    "patient_propensity = row[propensity_cols].T\n",
    "patient_propensity.columns = [\"Propensity Score\"]\n",
    "patient_propensity.index = [col.replace(\"propensity_\", \"\") for col in patient_propensity.index]\n",
    "patient_propensity[\"Propensity Score\"] = patient_propensity[\"Propensity Score\"].astype(float).round(2)\n",
    "patient_propensity = patient_propensity[patient_propensity[\"Propensity Score\"] >= 0.05]\n",
    "patient_propensity = patient_propensity.sort_values(by=\"Propensity Score\", ascending=False)\n",
    "\n",
    "patient_cov_std = scaler.transform(row[feature_names])[0]\n",
    "logits = coef_matrix @ patient_cov_std + intercepts\n",
    "probs = np.exp(logits) / np.sum(np.exp(logits))\n",
    "\n",
    "top_two_idx = np.argsort(probs)[-2:][::-1]\n",
    "top_idx, second_idx = top_two_idx\n",
    "top_class = classes[top_idx]\n",
    "second_class = classes[second_idx]\n",
    "\n",
    "top_coef = coef_matrix[top_idx]\n",
    "top_contrib = patient_cov_std * top_coef\n",
    "treatment_counts = Counter(treatments)\n",
    "total = sum(treatment_counts[c] for c in classes if c != top_class)\n",
    "weights = [treatment_counts[c] / total for c in classes if c != top_class]\n",
    "avg_other_contrib = np.average(\n",
    "    [patient_cov_std * coef_matrix[i] for i, c in enumerate(classes) if c != top_class],\n",
    "    axis=0, weights=np.array(weights)\n",
    ")\n",
    "delta_contrib_first = top_contrib - avg_other_contrib\n",
    "actual_values = row[feature_names].values.flatten()\n",
    "\n",
    "df_first = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"value\": np.round(actual_values, 2),\n",
    "    \"top_contribution\": np.round(top_contrib, 2),\n",
    "    \"weighted_avg_other_contribution\": np.round(avg_other_contrib, 2),\n",
    "    \"Δ_contribution\": np.round(delta_contrib_first, 2)\n",
    "})\n",
    "df_first = df_first[df_first[\"Δ_contribution\"] > 0].sort_values(\"Δ_contribution\", ascending=False)\n",
    "\n",
    "second_coef = coef_matrix[second_idx]\n",
    "second_contrib = patient_cov_std * second_coef\n",
    "delta_contrib_second = top_contrib - second_contrib\n",
    "\n",
    "df_second = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"value\": np.round(actual_values, 2),\n",
    "    f\"{top_class} contribution\": np.round(top_contrib, 2),\n",
    "    f\"{second_class} contribution\": np.round(second_contrib, 2),\n",
    "    \"Δ_contribution\": np.round(delta_contrib_second, 2)\n",
    "})\n",
    "df_second[\"abs_Δ_contribution\"] = df_second[\"Δ_contribution\"].abs()\n",
    "df_second = df_second.sort_values(\"abs_Δ_contribution\", ascending=False)\n",
    "\n",
    "def interpret_value(v):\n",
    "    if v == 1.0: return \"positive\"\n",
    "    if v == 0.0: return \"negative\"\n",
    "    if v > 0: return \"relatively high\"\n",
    "    if v < 0: return \"relatively low\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def get_raw_value(encoded_feature):\n",
    "    if encoded_feature in raw_row:\n",
    "        return raw_row[encoded_feature]\n",
    "    prefix = encoded_feature.split('_')[0]\n",
    "    return raw_row.get(prefix, np.nan)\n",
    "\n",
    "def prettify_feature(feat):\n",
    "    if \"_\" in feat and not feat.startswith(\"has\"):\n",
    "        base, category = feat.split(\"_\", 1)\n",
    "        base = re.sub(r'(?<!^)(?=[A-Z])', ' ', base).strip().capitalize()\n",
    "        category = category.replace(\"_\", \" \").lower().capitalize()\n",
    "        return f\"{base}: {category}\"\n",
    "    else:\n",
    "        return re.sub(r'(?<!^)(?=[A-Z])', ' ', feat).strip().capitalize()\n",
    "\n",
    "for df in [df_first, df_second]:\n",
    "    df[\"interpretation\"] = df[\"value\"].apply(interpret_value)\n",
    "    df[\"actual_value\"] = df[\"feature\"].apply(get_raw_value)\n",
    "    df[\"feature_written\"] = df[\"feature\"].apply(prettify_feature)\n",
    "\n",
    "treatment_cols = [col for col in treatment_row.index if col.startswith(\"systemicTreatmentPlan_\")]\n",
    "actual_treatments = [\n",
    "    col.replace(\"systemicTreatmentPlan_\", \"\")\n",
    "    for col in treatment_cols\n",
    "    if str(treatment_row[col]).strip() in {\"1\", \"1.0\", \"True\", \"true\"}\n",
    "]\n",
    "actual_treatment_str = \" + \".join(actual_treatments) if actual_treatments else \"No treatment\"\n",
    "survival_days = treatment_row.get(\"survivalDaysSinceMetastaticDiagnosis\", \"Unknown\")\n",
    "\n",
    "top_score_percent = f\"{patient_propensity.loc[top_class, 'Propensity Score'] * 100:.0f}%\" if top_class in patient_propensity.index else \"N/A\"\n",
    "\n",
    "if second_class in patient_propensity.index:\n",
    "    second_score_percent = f\"{patient_propensity.loc[second_class, 'Propensity Score'] * 100:.0f}%\"\n",
    "    show_second = True\n",
    "else:\n",
    "    second_score_percent = None\n",
    "    show_second = False\n",
    "\n",
    "output = [\n",
    "    f\"**Actual Treatment:** {actual_treatment_str}  \",\n",
    "    f\"**Observed Survival:** {survival_days} days\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "output.append(f\"**{top_class}** ({top_score_percent})\")\n",
    "for _, row_ in df_first[df_first[\"Δ_contribution\"] > 0.1].iterrows():\n",
    "    output.append(f\"- **{row_['feature_written']} →** {row_['interpretation']} ({row_['actual_value']})\")\n",
    "\n",
    "if show_second:\n",
    "    output.append(\"\")\n",
    "    output.append(f\"**{second_class}** ({second_score_percent})\")\n",
    "    for _, row_ in df_second[df_second[\"Δ_contribution\"] < -0.1].iterrows():\n",
    "        output.append(f\"- **{row_['feature_written']} →** {row_['interpretation']} ({row_['actual_value']})\")\n",
    "\n",
    "output.append(\"\")\n",
    "for treatment, score in patient_propensity[\"Propensity Score\"].items():\n",
    "    if treatment not in [top_class, second_class] and score >= 0.05:\n",
    "        output.append(f\"**{treatment}** ({score * 100:.0f}%)\")\n",
    "        output.append(\"\")\n",
    "\n",
    "display(Markdown(\"\\n\".join(output)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19459fc1-044b-4f86-9443-daca00bc7e20",
   "metadata": {},
   "source": [
    "# Accuracy estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3159f09-68b7-4c94-a201-94ac2d042216",
   "metadata": {},
   "source": [
    "Based on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1621a7-901c-43bd-98a8-ae4828e16fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_treatment_string(treat_str):\n",
    "    if not treat_str or treat_str.strip().lower() in {\"none\", \"no treatment\"}:\n",
    "        return set()\n",
    "    parts = re.split(r\"[,+]\", treat_str)\n",
    "    return set(p.strip().lower() for p in parts if p.strip())\n",
    "\n",
    "df_test = df_all.loc[covariates_test.index].reset_index(drop=True)\n",
    "test_set = covariates_test.reset_index(drop=True)\n",
    "\n",
    "treatment_comparisons = []\n",
    "\n",
    "for idx, row in df_test.iterrows():\n",
    "    source_id = row[\"sourceId\"]\n",
    "\n",
    "    treatment_cols = [col for col in row.index if col.startswith(\"systemicTreatmentPlan_\")]\n",
    "    actual_treatments = [\n",
    "        col.replace(\"systemicTreatmentPlan_\", \"\")\n",
    "        for col in treatment_cols\n",
    "        if str(row[col]).strip() in {\"1\", \"1.0\", \"True\", \"true\"}\n",
    "    ]\n",
    "    actual_treatment_str = \" + \".join(actual_treatments) if actual_treatments else \"None\"\n",
    "\n",
    "    X_std = scaler.transform(test_set.iloc[[idx]])[0]\n",
    "    logits = coef_matrix @ X_std + intercepts\n",
    "    probs = np.exp(logits) / np.sum(np.exp(logits))\n",
    "    top_class = classes[np.argmax(probs)]\n",
    "    top_prob = probs[np.argmax(probs)]\n",
    "\n",
    "    predicted_set = normalize_treatment_string(top_class)\n",
    "    actual_set = normalize_treatment_string(actual_treatment_str)\n",
    "    is_correct = predicted_set == actual_set\n",
    "\n",
    "    treatment_comparisons.append({\n",
    "        \"sourceId\": source_id,\n",
    "        \"predicted_treatment\": top_class,\n",
    "        \"predicted_probability\": round(top_prob, 3),\n",
    "        \"actual_treatment\": actual_treatment_str,\n",
    "        \"correct_match\": is_correct\n",
    "    })\n",
    "\n",
    "df_treatment_comparison = pd.DataFrame(treatment_comparisons)\n",
    "\n",
    "accuracy = df_treatment_comparison[\"correct_match\"].mean()\n",
    "print(f\"Correct treatment match accuracy (test set): {accuracy:.2%}\")\n",
    "\n",
    "mismatches = df_treatment_comparison[~df_treatment_comparison[\"correct_match\"]]\n",
    "display(mismatches.head(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9057cc39-c7e0-4934-b4b4-0cab17a8e545",
   "metadata": {},
   "source": [
    "Based on whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4714bd9-7ddb-4872-bb1b-2fd9c49d9266",
   "metadata": {
    "tags": []
   },
   "source": [
    "def normalize_treatment_string(treat_str):\n",
    "    if not treat_str or treat_str.strip().lower() in {\"none\", \"no treatment\"}:\n",
    "        return set()\n",
    "    parts = re.split(r\"[,+]\", treat_str)\n",
    "    return set(p.strip().lower() for p in parts if p.strip())\n",
    "\n",
    "\n",
    "treatment_comparisons = []\n",
    "\n",
    "for idx, row in df_all.iterrows():\n",
    "    source_id = row[\"sourceId\"]\n",
    "\n",
    "    treatment_cols = [col for col in row.index if col.startswith(\"systemicTreatmentPlan_\")]\n",
    "    actual_treatments = [\n",
    "        col.replace(\"systemicTreatmentPlan_\", \"\")\n",
    "        for col in treatment_cols\n",
    "        if str(row[col]).strip() in {\"1\", \"1.0\", \"True\", \"true\"}\n",
    "    ]\n",
    "    actual_treatment_str = \" + \".join(actual_treatments) if actual_treatments else \"None\"\n",
    "\n",
    "    X_std = scaler.transform(row[feature_names].to_frame().T)[0]\n",
    "    logits = coef_matrix @ X_std + intercepts\n",
    "    probs = np.exp(logits) / np.sum(np.exp(logits))\n",
    "    top_class = classes[np.argmax(probs)]\n",
    "    top_prob = probs[np.argmax(probs)]\n",
    "\n",
    "    predicted_set = normalize_treatment_string(top_class)\n",
    "    actual_set = normalize_treatment_string(actual_treatment_str)\n",
    "\n",
    "    is_correct = predicted_set == actual_set\n",
    "\n",
    "    treatment_comparisons.append({\n",
    "        \"sourceId\": source_id,\n",
    "        \"predicted_treatment\": top_class,\n",
    "        \"predicted_probability\": round(top_prob, 3),\n",
    "        \"actual_treatment\": actual_treatment_str,\n",
    "        \"correct_match\": is_correct\n",
    "    })\n",
    "\n",
    "df_treatment_comparison = pd.DataFrame(treatment_comparisons)\n",
    "\n",
    "accuracy = df_treatment_comparison[\"correct_match\"].mean()\n",
    "print(f\"Correct treatment match accuracy: {accuracy:.2%}\")\n",
    "\n",
    "mismatches = df_treatment_comparison[~df_treatment_comparison[\"correct_match\"]]\n",
    "display(mismatches.head(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29db4629-d651-4bc6-abbf-4c3ada34b301",
   "metadata": {},
   "source": [
    "# Propensity overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cff8a1-9231-4dab-9ce3-46bca57ad58a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for label in treatment_classes:\n",
    "    sns.kdeplot(df_all[df_all[\"actual_treatment\"] == label][f\"propensity_{label}\"], label=f\"{label} - treated\")\n",
    "    sns.kdeplot(df_all[df_all[\"actual_treatment\"] != label][f\"propensity_{label}\"], label=f\"{label} - others\")\n",
    "    plt.title(f\"Propensity Overlap for {label}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08f81e-a3e9-4f08-97d0-063083552ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_treatment_comparison['actual_treatment'] = df_treatment_comparison['actual_treatment'].str.replace(\" \\+ \", \", \").str.title()\n",
    "df_treatment_comparison['predicted_treatment'] = df_treatment_comparison['predicted_treatment'].str.title()\n",
    "\n",
    "\n",
    "cross_tab = pd.crosstab(\n",
    "    df_treatment_comparison['predicted_treatment'],\n",
    "    df_treatment_comparison['actual_treatment'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "\n",
    "ax = cross_tab.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "plt.ylabel('Percentage of Actual Treatments')\n",
    "plt.title('Distribution of Actual Treatments per Predicted Treatment')\n",
    "plt.legend(title='Actual Treatment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
