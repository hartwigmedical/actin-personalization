{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5725a415-fbbb-416d-bc89-d7269c2db226",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43006d-0322-4efe-8962-88e75e2776d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986eb0aa-e5c5-4de2-8d5d-dab2e25bd90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import dill\n",
    "import torch\n",
    "import nbimporter\n",
    "import shap\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('/data/repos/actin-personalization/prediction')\n",
    "sys.path.insert(0, os.path.abspath(\"src/main/python\"))\n",
    "\n",
    "from models import *\n",
    "from data.data_processing import DataSplitter, DataPreprocessor\n",
    "from data.lookups import lookup_manager\n",
    "from utils.settings import settings\n",
    "from src.main.python.analysis.predictive_algorithms_training import get_data, plot_different_models_survival_curves\n",
    "\n",
    "preprocessor = DataPreprocessor(settings.db_config_path, settings.db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d197db6a-904f-40d7-bfb8-06e423df9b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df, X_train, X_test, y_train, y_test, encoded_columns = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07546771-ef45-4311-86a8-d40621301b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_preprocessed_data_with_sourceId(preprocessor):\n",
    "    df_raw = preprocessor.load_data()\n",
    "    df_all, updated_features, _ = preprocessor.preprocess_data(\n",
    "        lookup_manager.features, df=df_raw\n",
    "    )\n",
    "    df_all[\"sourceId\"] = df_raw.loc[df_all.index, \"sourceId\"]\n",
    "    #df_all[\"reasonRefrainmentFromTreatment\"] = df_raw.loc[df_all.index, \"reasonRefrainmentFromTreatment\"]\n",
    "    return df_raw, df_all, updated_features\n",
    "\n",
    "df_raw, df_all, updated_features = get_preprocessed_data_with_sourceId(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047019ea-4b13-4e90-bc72-76b8182b27f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_trained_model(model_name, model_class, model_kwargs={}):\n",
    "    model_file_prefix = os.path.join(settings.save_path, f\"{settings.outcome}_{model_name}\")\n",
    "    nn_file = model_file_prefix + \".pt\"\n",
    "    sk_file = model_file_prefix + \".pkl\"\n",
    "        \n",
    "    if model_name in ['CoxPH', 'RandomSurvivalForest', 'GradientBoosting', 'AalenAdditive']:\n",
    "        with open(sk_file, \"rb\") as f:\n",
    "            model = dill.load(f)\n",
    "        print(f\"Model {model_name} loaded from {sk_file}\")\n",
    "        return model\n",
    "    else:\n",
    "        model = model_class(**model_kwargs)\n",
    "    \n",
    "        state = torch.load(nn_file, map_location=torch.device('cpu'))\n",
    "        \n",
    "        model.model.net.load_state_dict(state['net_state'])\n",
    "    \n",
    "        if 'labtrans' in state:\n",
    "            model.labtrans             = state['labtrans']\n",
    "            model.model.duration_index = model.labtrans.cuts\n",
    "        \n",
    "        if 'baseline_hazards' in state:\n",
    "            model.model.baseline_hazards_ = state['baseline_hazards']\n",
    "            model.model.baseline_cumulative_hazards_ = state['baseline_cumulative_hazards']\n",
    "            \n",
    "            print(f\"Baseline hazards loaded for {model_name}.\")\n",
    "            \n",
    "        model.model.net.eval()     \n",
    "        print(f\"Model {model_name} loaded from {nn_file}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "def load_all_trained_models(X_train):\n",
    "    loaded_models = {}\n",
    "    config_mgr = ExperimentConfig(settings.json_config_file)\n",
    "    loaded_configs = config_mgr.load_model_configs()\n",
    "\n",
    "    for model_name, (model_class, model_kwargs) in loaded_configs.items():\n",
    "        print(model_name, model_class)\n",
    "        try:\n",
    "            loaded_model = load_trained_model(\n",
    "                model_name=model_name, \n",
    "                model_class=model_class, \n",
    "                model_kwargs=model_kwargs\n",
    "            )\n",
    "            loaded_models[model_name] = loaded_model\n",
    "\n",
    "            ModelTrainer._set_attention_indices(loaded_models[model_name], list(X_train.columns))\n",
    "        except:\n",
    "            print(f'Could not load: {model_name}')\n",
    "            continue\n",
    "    return loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6936415-0fbf-4e63-888b-4742b6fe22c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_models = load_all_trained_models(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac3420-95fe-4b04-84fd-dcbe4a8fc7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('src/main/python/data/treatment_combinations.json', 'r') as f:\n",
    "    valid_treatment_combinations = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c20be5-a000-4164-ba46-476f64e4f4be",
   "metadata": {
    "tags": []
   },
   "source": [
    "# C-for-benefit estimation based on the method described by Maas et al."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b91e5-87ef-4dfd-94f6-6b140b4b2f9f",
   "metadata": {},
   "source": [
    "Definition of treatment effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc49b88-14ee-4ee8-8f99-12d681742286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_patient_treatment_risks(\n",
    "    model,\n",
    "    df_all,\n",
    "    treatment_map,\n",
    "    treatment_prefix=\"systemicTreatmentPlan_\",\n",
    "    horizon_days=365\n",
    "):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    def apply_treatment(df, mapping, treatment_cols, msi_flag):\n",
    "        df_copy = df.copy()\n",
    "        df_copy[treatment_cols] = 0\n",
    "        for col, val in mapping.items():\n",
    "            if col in df_copy.columns:\n",
    "                df_copy[col] = val\n",
    "        if \"hasMsi\" in df_copy.columns:\n",
    "            df_copy[\"hasMsi\"] = msi_flag\n",
    "        df_copy[\"hasTreatment\"] = (df_copy[treatment_cols].sum(axis=1) > 0).astype(int)\n",
    "        return df_copy\n",
    "\n",
    "    def compute_survival_stats(time_grid: np.ndarray, surv_probs: np.ndarray):\n",
    "        \"\"\"\n",
    "        Match the logic from your plotting function:\n",
    "        - median_days = first time S(t) â‰¤ 0.5 (no interpolation)\n",
    "        - auc_days = area under survival curve\n",
    "        \"\"\"\n",
    "        below = np.where(surv_probs <= 0.5)[0]\n",
    "        if below.size:\n",
    "            median_days = time_grid[below[0]]\n",
    "        else:\n",
    "            median_days = time_grid[-1]\n",
    "\n",
    "        auc_days = np.trapz(surv_probs, time_grid)\n",
    "        return median_days, auc_days\n",
    "\n",
    "    results = []\n",
    "    treatment_cols = [col for col in df_all.columns if col.startswith(treatment_prefix)]\n",
    "\n",
    "    for idx, row in tqdm(df_all.iterrows(), total=len(df_all), desc=\"Processing patients\"):\n",
    "        source_id = row[\"sourceId\"]\n",
    "        survival_days = row[settings.duration_col]\n",
    "        event = row[settings.event_col]\n",
    "        msi_flag = int(row.get(\"hasMsi\", 0))\n",
    "\n",
    "        X_base = row.drop(labels=[\"sourceId\", settings.event_col, settings.duration_col]).to_frame().T\n",
    "\n",
    "        survival_fs = model.predict_survival_function(X_base)\n",
    "        time_start = max(sf.x[0] for sf in survival_fs)\n",
    "        time_end = min(sf.x[-1] for sf in survival_fs)\n",
    "        time_grid = np.linspace(time_start, time_end, 500)\n",
    "\n",
    "        actual_treatments = [col for col in treatment_cols if row[col] == 1]\n",
    "        actual_treatment_str = \", \".join(\n",
    "            [col.replace(treatment_prefix, \"\") for col in actual_treatments]\n",
    "        ) if actual_treatments else \"No Treatment\"\n",
    "\n",
    "        for treatment_label, mapping in treatment_map.items():\n",
    "            X_mod = apply_treatment(X_base.copy(), mapping, treatment_cols, msi_flag)\n",
    "\n",
    "            if hasattr(model, \"model\") and hasattr(model.model, \"predict\"):\n",
    "                risk_val = float(model.model.predict(X_mod.values.astype(\"float32\"))[0])\n",
    "            else:\n",
    "                risk_val = float(model.predict(X_mod)[0])\n",
    "\n",
    "            surv_fn, = model.predict_survival_function(X_mod)\n",
    "            surv_probs = surv_fn(time_grid)\n",
    "\n",
    "            prob_1yr = float(np.interp(horizon_days, time_grid, surv_probs))\n",
    "\n",
    "            median_survival, auc = compute_survival_stats(time_grid, surv_probs)\n",
    "\n",
    "            results.append({\n",
    "                \"sourceId\": source_id,\n",
    "                \"treatment\": treatment_label,\n",
    "                \"predicted_risk\": risk_val,\n",
    "                \"predicted_prob_1yr\": prob_1yr,\n",
    "                \"predicted_median_survival\": median_survival,\n",
    "                \"predicted_auc\": auc,\n",
    "                \"observed_survival\": survival_days,\n",
    "                \"event\": event,\n",
    "                \"actual_treatment\": actual_treatment_str\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b804d903-e25b-4e48-a591-63f5becd5a05",
   "metadata": {
    "tags": []
   },
   "source": [
    "risk_df = get_all_patient_treatment_risks(\n",
    "    model=trained_models[\"DeepSurv_attention\"],\n",
    "    df_all=df_all,\n",
    "    treatment_map=valid_treatment_combinations,\n",
    "    treatment_prefix=\"systemicTreatmentPlan_\"\n",
    ")\n",
    "\n",
    "\n",
    "print(risk_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8012af8-7aeb-409c-93c0-4704be8d7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "risk_path = \"1yr_surv_df_deepsurv_attention.csv\"\n",
    "recalculate = False\n",
    "max_patients = None\n",
    "\n",
    "df_input = df_all.copy()\n",
    "if max_patients is not None:\n",
    "    df_input = df_input.sample(n=max_patients, random_state=42).reset_index(drop=True)\n",
    "    print(f\"Limiting to {max_patients} patients for processing.\")\n",
    "\n",
    "if not recalculate and os.path.exists(risk_path):\n",
    "    print(f\"Loading risk_df from: {risk_path}\")\n",
    "    risk_df = pd.read_csv(risk_path)\n",
    "else:\n",
    "    print(\"Recalculating risk_df...\")\n",
    "    risk_df = get_all_patient_treatment_risks(\n",
    "        model=trained_models[\"DeepSurv_attention\"],\n",
    "        df_all=df_input,\n",
    "        treatment_map=valid_treatment_combinations,\n",
    "        treatment_prefix=\"systemicTreatmentPlan_\"\n",
    "    )\n",
    "    risk_df.to_csv(risk_path, index=False)\n",
    "    print(f\"Saved risk_df to: {risk_path}\")\n",
    "\n",
    "print(risk_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039fe793-93a0-4c53-a684-dc3ad8760142",
   "metadata": {},
   "source": [
    "Extraction of untreated and treated patient groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d63f8d-32e7-4b07-85bd-1f16af291c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "treat_control = \"No Treatment\"\n",
    "treat_active = \"5-FU + oxaliplatin + bevacizumab\"\n",
    "\n",
    "df_control = risk_df[risk_df[\"treatment\"] == treat_control][[\"sourceId\", \"predicted_prob_1yr\"]]\n",
    "df_active = risk_df[risk_df[\"treatment\"] == treat_active][[\"sourceId\", \"predicted_prob_1yr\"]]\n",
    "\n",
    "df_control = df_control.rename(columns={\"predicted_prob_1yr\": \"prob_untreated_pred\"})\n",
    "df_active = df_active.rename(columns={\"predicted_prob_1yr\": \"prob_treated_pred\"})\n",
    "\n",
    "df_ite = pd.merge(df_control, df_active, on=\"sourceId\")\n",
    "\n",
    "df_actual = risk_df.drop_duplicates(\"sourceId\")[[\n",
    "    \"sourceId\", \n",
    "    \"actual_treatment\", \n",
    "    \"event\", \n",
    "    \"observed_survival\"\n",
    "]]\n",
    "df_ite = pd.merge(df_ite, df_actual, on=\"sourceId\")\n",
    "\n",
    "df_ite[\"survived_1yr\"] = np.where(\n",
    "    df_ite[\"observed_survival\"] > 365,\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "df_ite[\"predicted_ite\"] = df_ite[\"prob_untreated_pred\"] - df_ite[\"prob_treated_pred\"]\n",
    "\n",
    "valid_actuals = [\"No Treatment\", \"5-FU, oxaliplatin, bevacizumab\"]\n",
    "df_ite = df_ite[df_ite[\"actual_treatment\"].isin(valid_actuals)].copy()\n",
    "\n",
    "print(\"Patients remaining after filtering:\", df_ite.shape[0])\n",
    "print(df_ite[\"actual_treatment\"].value_counts())\n",
    "print(\"\\nPreview:\")\n",
    "print(df_ite.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59d92e-02ad-43e6-8a25-4fc734ac8ce8",
   "metadata": {},
   "source": [
    "Create covariate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3b413-7df8-4105-8aed-7a20f301b876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exclude_cols = [\n",
    "    'hadSurvivalEvent',\n",
    "    'systemicTreatmentPlan_5-FU',\n",
    "    'systemicTreatmentPlan_oxaliplatin',\n",
    "    'systemicTreatmentPlan_irinotecan',\n",
    "    'systemicTreatmentPlan_bevacizumab',\n",
    "    'systemicTreatmentPlan_panitumumab',\n",
    "    'systemicTreatmentPlan_pembrolizumab',\n",
    "    'systemicTreatmentPlan_nivolumab',\n",
    "    'hasTreatment',\n",
    "    'survivalDaysSinceMetastaticDiagnosis'\n",
    "]\n",
    "\n",
    "covariate_cols = [col for col in df_all.columns if col not in exclude_cols + ['sourceId']]\n",
    "df_covariates = df_all[[\"sourceId\"] + covariate_cols].copy()\n",
    "\n",
    "print(\"Created df_covariates with shape:\", df_covariates.shape)\n",
    "print(\"Total covariates:\", len(covariate_cols))\n",
    "\n",
    "print(df_covariates.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec6ce79-408b-483b-8430-e5a8a1b7b7dc",
   "metadata": {},
   "source": [
    "Create pairs based on similarity in covariates\n",
    "Find for every untreated patient the closest treated match (without duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b719507-fa63-4dd9-9496-717e4f7e0c6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "output_path = \"matched_pairs_Maas.csv\"\n",
    "overwrite = False\n",
    "\n",
    "if os.path.exists(output_path) and not overwrite:\n",
    "    print(f\"Matched pairs file already exists at '{output_path}'.\")\n",
    "    print(\"Loading from file instead of recomputing. To overwrite, set overwrite = True.\\n\")\n",
    "    matched_pairs_df = pd.read_csv(output_path)\n",
    "else:\n",
    "    treated_df = df_ite[df_ite['actual_treatment'] != \"No Treatment\"].copy()\n",
    "    untreated_df = df_ite[df_ite['actual_treatment'] == \"No Treatment\"].copy()\n",
    "\n",
    "    treated_cov = treated_df.merge(df_covariates, on='sourceId')\n",
    "    untreated_cov = untreated_df.merge(df_covariates, on='sourceId')\n",
    "\n",
    "    exclude_cols = [\n",
    "        'sourceId', 'actual_treatment', 'event', 'observed_survival',\n",
    "        'prob_untreated_pred', 'prob_treated_pred', 'predicted_ite'\n",
    "    ]\n",
    "    X_treated = treated_cov.drop(columns=[col for col in exclude_cols if col in treated_cov.columns])\n",
    "    X_untreated = untreated_cov.drop(columns=[col for col in exclude_cols if col in untreated_cov.columns])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_all = pd.concat([X_treated, X_untreated], axis=0)\n",
    "    scaler.fit(X_all)\n",
    "    X_treated_scaled = scaler.transform(X_treated)\n",
    "    X_untreated_scaled = scaler.transform(X_untreated)\n",
    "\n",
    "    cov_matrix = np.cov(X_all.T, rowvar=False)\n",
    "    VI = np.linalg.inv(cov_matrix)\n",
    "    dist_matrix = cdist(X_untreated_scaled, X_treated_scaled, metric='mahalanobis', VI=VI)\n",
    "\n",
    "    treated_indices_used = set()\n",
    "    matched_pairs = []\n",
    "\n",
    "    print(\"Matching untreated patients to nearest treated patient:\")\n",
    "    for i in tqdm(range(len(dist_matrix))):\n",
    "        row = dist_matrix[i]\n",
    "        sorted_indices = np.argsort(row)\n",
    "        for j in sorted_indices:\n",
    "            if j not in treated_indices_used:\n",
    "                treated_indices_used.add(j)\n",
    "                matched_pairs.append({\n",
    "                    'untreated_id': untreated_cov.iloc[i]['sourceId'],\n",
    "                    'treated_id': treated_cov.iloc[j]['sourceId'],\n",
    "                    'distance': row[j]\n",
    "                })\n",
    "                break\n",
    "\n",
    "    matched_pairs_df = pd.DataFrame(matched_pairs).reset_index(drop=True)\n",
    "\n",
    "    expected_matches = len(untreated_cov)\n",
    "    actual_matches = len(matched_pairs_df)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(matched_pairs_df['distance'], bins=30, edgecolor='k')\n",
    "    plt.xlabel(\"Mahalanobis Distance\")\n",
    "    plt.ylabel(\"Number of Matched Pairs\")\n",
    "    plt.title(\"Distribution of Matching Distances\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    matched_pairs_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved matched pairs to: {output_path}\")\n",
    "\n",
    "matched_pairs_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fccb79-48e1-4b78-930c-414881964a57",
   "metadata": {},
   "source": [
    "Calculate pairwise effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075347a-2eda-4f73-aac5-fa3c1eb32a53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_lookup = df_ite.set_index(\"sourceId\")[[\n",
    "    \"prob_untreated_pred\", \"prob_treated_pred\", \"survived_1yr\"\n",
    "]]\n",
    "\n",
    "matched = matched_pairs_df.copy()\n",
    "matched = matched.merge(df_lookup, left_on=\"untreated_id\", right_index=True)\n",
    "\n",
    "matched = matched.merge(df_lookup, left_on=\"treated_id\", right_index=True)\n",
    "\n",
    "matched[\"pred_pairwise_effect\"] = matched[\"prob_treated_pred_y\"] - matched[\"prob_untreated_pred_x\"]\n",
    "\n",
    "matched[\"obs_pairwise_effect\"] = np.select(\n",
    "    [\n",
    "        (matched[\"survived_1yr_x\"] == 0) & (matched[\"survived_1yr_y\"] == 1),\n",
    "        (matched[\"survived_1yr_x\"] == 1) & (matched[\"survived_1yr_y\"] == 0),\n",
    "        (matched[\"survived_1yr_x\"] == matched[\"survived_1yr_y\"])\n",
    "    ],\n",
    "    [1, -1, 0]\n",
    ")\n",
    "\n",
    "# --- Final preview ---\n",
    "matched[[\n",
    "    \"untreated_id\", \"treated_id\", \"distance\",\n",
    "    \"prob_untreated_pred_x\", \"prob_treated_pred_y\",\n",
    "    \"survived_1yr_x\", \"survived_1yr_y\",\n",
    "    \"pred_pairwise_effect\", \"obs_pairwise_effect\"\n",
    "]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e723a3e1-6024-48ce-beb9-5bb1f0be95ea",
   "metadata": {},
   "source": [
    "Calibration of benefit and average absolute vertical distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43546ee-20b8-44fd-86b5-8530e14d409c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "n_bins = 4\n",
    "\n",
    "matched[\"quantile_bin\"] = pd.qcut(matched[\"pred_pairwise_effect\"], q=n_bins, duplicates='drop')\n",
    "\n",
    "quantile_df = matched.groupby(\"quantile_bin\").agg({\n",
    "    \"pred_pairwise_effect\": \"mean\",\n",
    "    \"obs_pairwise_effect\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "lowess = sm.nonparametric.lowess\n",
    "smoothed = lowess(\n",
    "    matched[\"obs_pairwise_effect\"],\n",
    "    matched[\"pred_pairwise_effect\"],\n",
    "    frac=0.3\n",
    ")\n",
    "smoothed_df = pd.DataFrame(smoothed, columns=[\"pred_pairwise_effect\", \"smoothed_obs\"])\n",
    "\n",
    "calib_df = matched[[\"pred_pairwise_effect\"]].copy()\n",
    "calib_df[\"smoothed_obs\"] = np.interp(\n",
    "    calib_df[\"pred_pairwise_effect\"],\n",
    "    smoothed_df[\"pred_pairwise_effect\"],\n",
    "    smoothed_df[\"smoothed_obs\"]\n",
    ")\n",
    "calib_df[\"abs_error\"] = np.abs(calib_df[\"smoothed_obs\"] - calib_df[\"pred_pairwise_effect\"])\n",
    "Eavg = calib_df[\"abs_error\"].mean()\n",
    "E50 = calib_df[\"abs_error\"].median()\n",
    "E90 = calib_df[\"abs_error\"].quantile(0.9)\n",
    "\n",
    "print(f\"Eavg-for-benefit: {Eavg:.4f}\")\n",
    "print(f\"E50-for-benefit:  {E50:.4f}\")\n",
    "print(f\"E90-for-benefit:  {E90:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot([-1, 1], [-1, 1], linestyle=\"--\", color=\"gray\", label=\"Perfect calibration\")\n",
    "plt.plot(smoothed_df[\"pred_pairwise_effect\"], smoothed_df[\"smoothed_obs\"], color=\"blue\", label=\"LOWESS-smoothed\")\n",
    "plt.scatter(\n",
    "    quantile_df[\"pred_pairwise_effect\"],\n",
    "    quantile_df[\"obs_pairwise_effect\"],\n",
    "    color=\"red\", s=50, label=\"Quantile averages\"\n",
    ")\n",
    "plt.xlabel(\"Predicted pairwise treatment effect\")\n",
    "plt.ylabel(\"Observed pairwise treatment effect\")\n",
    "plt.title(\"Calibration of benefit\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed291bc-0431-4472-b488-e21b2ae87721",
   "metadata": {},
   "source": [
    "Estimate C-for benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae2166-970d-4c24-b3bd-1d96a10671f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "df_c = matched[[\"pred_pairwise_effect\", \"obs_pairwise_effect\"]].copy()\n",
    "\n",
    "concordant = discordant = tied = 0\n",
    "\n",
    "for (i, row_i), (j, row_j) in combinations(df_c.iterrows(), 2):\n",
    "    obs_diff = row_i[\"obs_pairwise_effect\"] - row_j[\"obs_pairwise_effect\"]\n",
    "    \n",
    "    if obs_diff == 0:\n",
    "        continue\n",
    "\n",
    "    pred_diff = row_i[\"pred_pairwise_effect\"] - row_j[\"pred_pairwise_effect\"]\n",
    "\n",
    "    if np.sign(obs_diff) == np.sign(pred_diff):\n",
    "        concordant += 1\n",
    "    elif pred_diff == 0:\n",
    "        tied += 1\n",
    "    else:\n",
    "        discordant += 1\n",
    "\n",
    "n_informative = concordant + discordant\n",
    "if n_informative > 0:\n",
    "    c_for_benefit = concordant / n_informative\n",
    "else:\n",
    "    c_for_benefit = np.nan\n",
    "\n",
    "print(f\"C-for-benefit: {c_for_benefit:.4f}\")\n",
    "print(f\"Concordant: {concordant}, Discordant: {discordant}, Tied: {tied}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676dd427-31e1-41f6-837c-2aebf77bd9b1",
   "metadata": {},
   "source": [
    "Sped up version for C-for-benefit estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6e49ab-c5d5-4b15-a39f-06fdb7a8b0a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "valid_pairs = matched.reset_index(drop=True)\n",
    "\n",
    "random.seed(42)\n",
    "pair_indices = list(combinations(valid_pairs.index, 2))\n",
    "sample_indices = random.sample(pair_indices, 100000)\n",
    "\n",
    "records = []\n",
    "for i, j in sample_indices:\n",
    "    row_i = valid_pairs.loc[i]\n",
    "    row_j = valid_pairs.loc[j]\n",
    "\n",
    "    if row_i[\"obs_pairwise_effect\"] == row_j[\"obs_pairwise_effect\"]:\n",
    "        continue\n",
    "\n",
    "    if row_i[\"obs_pairwise_effect\"] > row_j[\"obs_pairwise_effect\"]:\n",
    "        winner = \"i\"\n",
    "    else:\n",
    "        winner = \"j\"\n",
    "\n",
    "    if row_i[\"pred_pairwise_effect\"] > row_j[\"pred_pairwise_effect\"]:\n",
    "        predicted = \"i\"\n",
    "    else:\n",
    "        predicted = \"j\"\n",
    "\n",
    "    concordant = (winner == predicted)\n",
    "\n",
    "    records.append({\n",
    "        \"pair_i_untreated\": row_i[\"untreated_id\"],\n",
    "        \"pair_i_treated\": row_i[\"treated_id\"],\n",
    "        \"pair_j_untreated\": row_j[\"untreated_id\"],\n",
    "        \"pair_j_treated\": row_j[\"treated_id\"],\n",
    "        \"effect_i\": row_i[\"obs_pairwise_effect\"],\n",
    "        \"effect_j\": row_j[\"obs_pairwise_effect\"],\n",
    "        \"benefit_i\": row_i[\"pred_pairwise_effect\"],\n",
    "        \"benefit_j\": row_j[\"pred_pairwise_effect\"],\n",
    "        \"predicted_winner\": predicted,\n",
    "        \"observed_winner\": winner,\n",
    "        \"concordant\": concordant\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(records)\n",
    "comparison_df[\"concordant\"] = comparison_df[\"concordant\"].astype(int)\n",
    "\n",
    "if len(comparison_df) > 0:\n",
    "    c_for_benefit_sample = comparison_df[\"concordant\"].mean()\n",
    "    print(f\"Sampled C-for-benefit (1000 comparisons): {c_for_benefit_sample:.3f}\")\n",
    "else:\n",
    "    print(\"No informative pairs (with different observed effects) found.\")\n",
    "\n",
    "comparison_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913f3b3-8434-4eb2-8c78-0b5a857ef8ae",
   "metadata": {},
   "source": [
    "Distribution of pairwise effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a68cba-9f9c-4e8d-87c1-16d5e2db180d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "benefits_i = comparison_df[[\"benefit_i\"]].copy()\n",
    "benefits_i.columns = [\"benefit\"]\n",
    "benefits_i[\"source\"] = \"pair_i\"\n",
    "\n",
    "benefits_j = comparison_df[[\"benefit_j\"]].copy()\n",
    "benefits_j.columns = [\"benefit\"]\n",
    "benefits_j[\"source\"] = \"pair_j\"\n",
    "\n",
    "benefits = pd.concat([benefits_i, benefits_j], ignore_index=True)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.kdeplot(data=benefits, x=\"benefit\", hue=\"source\", common_norm=False, linewidth=2)\n",
    "plt.axvline(0, color=\"gray\", linestyle=\":\")\n",
    "plt.title(\"Distribution of Predicted Pairwise Effects (from comparison_df)\")\n",
    "plt.xlabel(\"Predicted Pairwise Effect\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fc94de-d97a-4681-99bc-2f498fc48df0",
   "metadata": {},
   "source": [
    "perform brier and cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf566b-b7de-4098-9d3d-ca7e85ddb3bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import log_loss, brier_score_loss\n",
    "\n",
    "discordant = matched[matched[\"obs_pairwise_effect\"].isin([1, -1])].copy()\n",
    "\n",
    "discordant[\"label\"] = (discordant[\"obs_pairwise_effect\"] == 1).astype(int)\n",
    "\n",
    "discordant[\"pred_prob_benefit\"] = 1 / (1 + np.exp(discordant[\"pred_pairwise_effect\"]))\n",
    "\n",
    "brier = brier_score_loss(discordant[\"label\"], discordant[\"pred_prob_benefit\"])\n",
    "cross_entropy = log_loss(discordant[\"label\"], discordant[\"pred_prob_benefit\"])\n",
    "\n",
    "print(f\"Brier-for-benefit:         {brier:.4f}\")\n",
    "print(f\"Cross-entropy-for-benefit: {cross_entropy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
