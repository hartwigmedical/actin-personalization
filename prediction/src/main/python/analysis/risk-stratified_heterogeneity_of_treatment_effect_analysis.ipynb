{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5725a415-fbbb-416d-bc89-d7269c2db226",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43006d-0322-4efe-8962-88e75e2776d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986eb0aa-e5c5-4de2-8d5d-dab2e25bd90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import dill\n",
    "import torch\n",
    "import nbimporter\n",
    "import shap\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('/data/repos/actin-personalization/prediction')\n",
    "sys.path.insert(0, os.path.abspath(\"src/main/python\"))\n",
    "\n",
    "from models import *\n",
    "from data.data_processing import DataSplitter, DataPreprocessor\n",
    "from data.lookups import lookup_manager\n",
    "from utils.settings import settings\n",
    "from src.main.python.analysis.predictive_algorithms_training import get_data, plot_different_models_survival_curves\n",
    "\n",
    "preprocessor = DataPreprocessor(settings.db_config_path, settings.db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d197db6a-904f-40d7-bfb8-06e423df9b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df, X_train, X_test, y_train, y_test, encoded_columns = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07546771-ef45-4311-86a8-d40621301b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_preprocessed_data_with_sourceId(preprocessor):\n",
    "    df_raw = preprocessor.load_data()\n",
    "    df_all, updated_features, _ = preprocessor.preprocess_data(\n",
    "        lookup_manager.features, df=df_raw\n",
    "    )\n",
    "    df_all[\"sourceId\"] = df_raw.loc[df_all.index, \"sourceId\"]\n",
    "    #df_all[\"reasonRefrainmentFromTreatment\"] = df_raw.loc[df_all.index, \"reasonRefrainmentFromTreatment\"]\n",
    "    return df_raw, df_all, updated_features\n",
    "\n",
    "df_raw, df_all, updated_features = get_preprocessed_data_with_sourceId(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047019ea-4b13-4e90-bc72-76b8182b27f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_trained_model(model_name, model_class, model_kwargs={}):\n",
    "    model_file_prefix = os.path.join(settings.save_path, f\"{settings.outcome}_{model_name}\")\n",
    "    nn_file = model_file_prefix + \".pt\"\n",
    "    sk_file = model_file_prefix + \".pkl\"\n",
    "        \n",
    "    if model_name in ['CoxPH', 'RandomSurvivalForest', 'GradientBoosting', 'AalenAdditive']:\n",
    "        with open(sk_file, \"rb\") as f:\n",
    "            model = dill.load(f)\n",
    "        print(f\"Model {model_name} loaded from {sk_file}\")\n",
    "        return model\n",
    "    else:\n",
    "        model = model_class(**model_kwargs)\n",
    "    \n",
    "        state = torch.load(nn_file, map_location=torch.device('cpu'))\n",
    "        \n",
    "        model.model.net.load_state_dict(state['net_state'])\n",
    "    \n",
    "        if 'labtrans' in state:\n",
    "            model.labtrans             = state['labtrans']\n",
    "            model.model.duration_index = model.labtrans.cuts\n",
    "        \n",
    "        if 'baseline_hazards' in state:\n",
    "            model.model.baseline_hazards_ = state['baseline_hazards']\n",
    "            model.model.baseline_cumulative_hazards_ = state['baseline_cumulative_hazards']\n",
    "            \n",
    "            print(f\"Baseline hazards loaded for {model_name}.\")\n",
    "            \n",
    "        model.model.net.eval()     \n",
    "        print(f\"Model {model_name} loaded from {nn_file}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "def load_all_trained_models(X_train):\n",
    "    loaded_models = {}\n",
    "    config_mgr = ExperimentConfig(settings.json_config_file)\n",
    "    loaded_configs = config_mgr.load_model_configs()\n",
    "\n",
    "    for model_name, (model_class, model_kwargs) in loaded_configs.items():\n",
    "        print(model_name, model_class)\n",
    "        try:\n",
    "            loaded_model = load_trained_model(\n",
    "                model_name=model_name, \n",
    "                model_class=model_class, \n",
    "                model_kwargs=model_kwargs\n",
    "            )\n",
    "            loaded_models[model_name] = loaded_model\n",
    "\n",
    "            ModelTrainer._set_attention_indices(loaded_models[model_name], list(X_train.columns))\n",
    "        except:\n",
    "            print(f'Could not load: {model_name}')\n",
    "            continue\n",
    "    return loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6936415-0fbf-4e63-888b-4742b6fe22c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_models = load_all_trained_models(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c20be5-a000-4164-ba46-476f64e4f4be",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Risk-stratified heterogeneity of treatment effect analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9599e0-57a2-4e0c-8334-3c0c31a9c85f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lifelines import CoxPHFitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674761ba-57a5-4439-8b02-757d7f42b33b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = trained_models[\"DeepSurv_attention\"]\n",
    "X_input = X_test.copy()\n",
    "\n",
    "if hasattr(model, \"model\") and hasattr(model.model, \"predict\"):\n",
    "    predicted_risks = model.model.predict(X_input.values.astype(\"float32\"))\n",
    "else:\n",
    "    predicted_risks = model.predict(X_input)\n",
    "\n",
    "if isinstance(predicted_risks, (np.ndarray, torch.Tensor)) and predicted_risks.ndim > 1:\n",
    "    predicted_risks = predicted_risks.ravel()\n",
    "\n",
    "risk_df = pd.DataFrame({\n",
    "    \"sourceId\": df_all.loc[X_input.index, \"sourceId\"].values,\n",
    "    \"predicted_risk\": predicted_risks,\n",
    "    \"duration\": y_test[\"survivalDaysSinceMetastaticDiagnosis\"],\n",
    "    \"event\": y_test[\"hadSurvivalEvent\"]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b135a7e-39e0-4b97-b931-dc91ccfbab54",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 1: General definition of the research aim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baeb3f4-0e86-4599-b6fe-a5d7eb490ee3",
   "metadata": {},
   "source": [
    "The typical research aim is: â€œto compare the effect of treatment to a comparator treatment in patients with a disease with respect to outcomes ð‘‚1,â€¦,ð‘‚ð‘›â€.\n",
    "\n",
    "We use a comparative cohort design. This means that at least three cohorts of patients need to be defined at this stage of the framework:\n",
    "\n",
    "A single treatment cohort (ð‘‡), which includes patients with disease receiving the target treatment of interest.\n",
    "\n",
    "A single comparator cohort (ð¶), which includes patients with disease receiving the comparator treatment.\n",
    "\n",
    "One or more outcome cohorts (ð‘‚1,â€¦,ð‘‚ð‘›) that contain patients developing the outcomes of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ccfc0-cfd6-452e-ac24-5b44c4bff4d6",
   "metadata": {},
   "source": [
    "# Step 2: Identification of the databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42036db5-26a0-43c1-b6e0-1b83c706b456",
   "metadata": {},
   "source": [
    "Including in our analyses multiple databases representing the population of interest potentially increases the generalizability of results. Furthermore, the cohorts should preferably have adequate sample size with adequate follow-up time to ensure precise effect estimation, even within smaller risk strata. Other relevant issues such as the depth of data capture (the precision at which measurements, lab tests, conditions are recorded) and the reliability of data entry should also be considere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480fd0c5-f781-4ff4-90f9-d8ba28034d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exclude_cols = [\n",
    "    'sourceId', 'hasTreatment', 'hadSurvivalEvent',\n",
    "    'survivalDaysSinceMetastaticDiagnosis', 'predicted_risk', 'risk_score', 'risk_group'\n",
    "]\n",
    "covariates = [\n",
    "    col for col in df_all.columns\n",
    "    if col not in exclude_cols and not col.startswith(\"systemicTreatmentPlan\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3afd0d5-b1b7-47a4-9601-18c7b5b30ff7",
   "metadata": {},
   "source": [
    "# Step 3: Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb41ad9-1be3-4b8f-a9a6-81d8e4a5578e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all = df_all.merge(risk_df[['sourceId', 'predicted_risk']], on='sourceId', how='inner')\n",
    "\n",
    "df_all['risk_score'] = df_all['predicted_risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d6c530-8749-476f-83f0-209bc2cdba4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all[\"risk_group\"] = pd.qcut(df_all[\"predicted_risk\"], q=3, labels=[\"Low\", \"Medium\", \"High\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fbd0f0-4e24-44a1-a313-f11e3cfb49fb",
   "metadata": {},
   "source": [
    "# Step 4: Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4ca1f-386b-4647-b7e5-de762ae56f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X = df_all[covariates]\n",
    "y = df_all[\"hasTreatment\"]\n",
    "\n",
    "ps_model = LogisticRegression(solver=\"liblinear\", max_iter=1000)\n",
    "ps_model.fit(X, y)\n",
    "df_all[\"propensity_score\"] = ps_model.predict_proba(X)[:, 1]\n",
    "\n",
    "treatment_rate = y.mean()\n",
    "ps = df_all[\"propensity_score\"]\n",
    "df_all[\"preference_score\"] = ps / (ps + (1 - ps) * (1 - treatment_rate) / treatment_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80b36c-6cfd-47c8-b021-f36ae5e5f246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    df_all,\n",
    "    col=\"risk_group\",\n",
    "    hue=\"hasTreatment\",\n",
    "    palette={0: \"orange\", 1: \"blue\"},\n",
    "    height=4, aspect=1.2,\n",
    "    sharex=True, sharey=True\n",
    ")\n",
    "g.map_dataframe(sns.kdeplot, x=\"preference_score\", fill=True, alpha=0.4)\n",
    "g.add_legend(title=\"Treatment\", labels=[\"Control\", \"Treated\"])\n",
    "g.set_axis_labels(\"Preference Score\", \"Density\")\n",
    "g.set_titles(\"Risk Group: {col_name}\")\n",
    "g.fig.subplots_adjust(top=0.85)\n",
    "g.fig.suptitle(\"Preference Score Overlap by Predicted Risk Group\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94e863-989c-483e-95cb-cfc463a75c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_smd(x_treated, x_control):\n",
    "    \"\"\"Standardized Mean Difference\"\"\"\n",
    "    mean_t = np.nanmean(x_treated)\n",
    "    mean_c = np.nanmean(x_control)\n",
    "    sd_pooled = np.nanstd(np.concatenate([x_treated, x_control]))\n",
    "    if sd_pooled == 0:\n",
    "        return 0.0\n",
    "    return np.abs(mean_t - mean_c) / sd_pooled\n",
    "\n",
    "smd_data = []\n",
    "\n",
    "for group in df_all[\"risk_group\"].unique():\n",
    "    group_data = df_all[df_all[\"risk_group\"] == group].copy()\n",
    "    group_data[\"ps_bin\"] = pd.qcut(group_data[\"preference_score\"], q=5, labels=False, duplicates=\"drop\")\n",
    "\n",
    "    for cov in covariates:\n",
    "        treated = group_data[group_data[\"hasTreatment\"] == 1][cov]\n",
    "        control = group_data[group_data[\"hasTreatment\"] == 0][cov]\n",
    "        smd_before = compute_smd(treated.values, control.values)\n",
    "        \n",
    "        smd_bins = []\n",
    "        for b in group_data[\"ps_bin\"].dropna().unique():\n",
    "            bin_data = group_data[group_data[\"ps_bin\"] == b]\n",
    "            t_bin = bin_data[bin_data[\"hasTreatment\"] == 1][cov]\n",
    "            c_bin = bin_data[bin_data[\"hasTreatment\"] == 0][cov]\n",
    "            if len(t_bin) > 0 and len(c_bin) > 0:\n",
    "                smd_bins.append(compute_smd(t_bin.values, c_bin.values))\n",
    "        smd_after = np.mean(smd_bins) if smd_bins else np.nan\n",
    "\n",
    "        smd_data.append({\n",
    "            \"Risk Group\": group,\n",
    "            \"Covariate\": cov,\n",
    "            \"SMD Before\": smd_before,\n",
    "            \"SMD After\": smd_after\n",
    "        })\n",
    "\n",
    "smd_df = pd.DataFrame(smd_data)\n",
    "\n",
    "g = sns.FacetGrid(smd_df, col=\"Risk Group\", height=4, aspect=1)\n",
    "g.map_dataframe(sns.scatterplot, x=\"SMD Before\", y=\"SMD After\", alpha=0.7)\n",
    "for ax in g.axes.flat:\n",
    "    ax.plot([0, 1], [0, 1], ls=\"--\", color=\"gray\")  # Diagonal reference line\n",
    "\n",
    "g.set_axis_labels(\"Before stratification on PS\", \"After stratification on PS\")\n",
    "g.set_titles(\"Risk Group: {col_name}\")\n",
    "g.fig.suptitle(\"Covariate Balance Before vs. After PS Stratification\", y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5617efc-41b2-4dda-8868-acdf05a16348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "df_all[\"ps_bin\"] = pd.qcut(df_all[\"preference_score\"], q=5, labels=False, duplicates=\"drop\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for group in df_all[\"risk_group\"].unique():\n",
    "    df_rg = df_all[df_all[\"risk_group\"] == group].copy()\n",
    "\n",
    "    df_rg[\"ps_bin\"] = df_rg[\"ps_bin\"].astype(\"category\")\n",
    "    cph = CoxPHFitter()\n",
    "\n",
    "    cols = [\"hasTreatment\", \"ps_bin\"]\n",
    "    cph.fit(\n",
    "        df_rg[[\"survivalDaysSinceMetastaticDiagnosis\", \"hadSurvivalEvent\"] + cols],\n",
    "        duration_col=\"survivalDaysSinceMetastaticDiagnosis\",\n",
    "        event_col=\"hadSurvivalEvent\"\n",
    "    )\n",
    "\n",
    "    hr = cph.hazard_ratios_[\"hasTreatment\"]\n",
    "    ci_log = cph.confidence_intervals_.loc[\"hasTreatment\"]\n",
    "    ci_lower = np.exp(ci_log[\"95% lower-bound\"])\n",
    "    ci_upper = np.exp(ci_log[\"95% upper-bound\"])\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        \"Risk Group\": group,\n",
    "        \"HR\": hr,\n",
    "        \"CI Lower\": ci_lower,\n",
    "        \"CI Upper\": ci_upper\n",
    "    })\n",
    "\n",
    "hr_df = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e2282-4e25-47fb-abb7-1e8f2a291fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "order = [\"Low\", \"Medium\", \"High\"]\n",
    "hr_df[\"Risk Group\"] = pd.Categorical(hr_df[\"Risk Group\"], categories=order, ordered=True)\n",
    "hr_df = hr_df.sort_values(\"Risk Group\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.errorbar(\n",
    "    x=hr_df[\"Risk Group\"],\n",
    "    y=hr_df[\"HR\"],\n",
    "    yerr=[hr_df[\"HR\"] - hr_df[\"CI Lower\"], hr_df[\"CI Upper\"] - hr_df[\"HR\"]],\n",
    "    fmt='o',\n",
    "    capsize=5,\n",
    "    label=\"Hazard Ratio\"\n",
    ")\n",
    "plt.axhline(1.0, color='gray', linestyle='--')\n",
    "plt.title(\"Heterogeneity of Treatment Effect by Risk Group\")\n",
    "plt.ylabel(\"Hazard Ratio (Treated vs. Untreated)\")\n",
    "plt.xlabel(\"Baseline Risk Group\")\n",
    "plt.ylim(0, max(hr_df[\"CI Upper\"].max(), 2))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
