{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5725a415-fbbb-416d-bc89-d7269c2db226",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43006d-0322-4efe-8962-88e75e2776d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986eb0aa-e5c5-4de2-8d5d-dab2e25bd90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import dill\n",
    "import torch\n",
    "import nbimporter\n",
    "import shap\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('/data/repos/actin-personalization/prediction')\n",
    "sys.path.insert(0, os.path.abspath(\"src/main/python\"))\n",
    "\n",
    "from models import *\n",
    "from data.data_processing import DataSplitter, DataPreprocessor\n",
    "from data.lookups import lookup_manager\n",
    "from utils.settings import settings\n",
    "from src.main.python.analysis.predictive_algorithms_training import get_data, plot_different_models_survival_curves\n",
    "\n",
    "preprocessor = DataPreprocessor(settings.db_config_path, settings.db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07546771-ef45-4311-86a8-d40621301b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_preprocessed_data_with_sourceId(preprocessor):\n",
    "    df_raw = preprocessor.load_data()\n",
    "    df_all, updated_features, _ = preprocessor.preprocess_data(\n",
    "        lookup_manager.features, df=df_raw\n",
    "    )\n",
    "    df_all[\"sourceId\"] = df_raw.loc[df_all.index, \"sourceId\"]\n",
    "    #df_all[\"reasonRefrainmentFromTreatment\"] = df_raw.loc[df_all.index, \"reasonRefrainmentFromTreatment\"]\n",
    "    return df_raw, df_all, updated_features\n",
    "\n",
    "df_raw, df_all, updated_features = get_preprocessed_data_with_sourceId(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac3420-95fe-4b04-84fd-dcbe4a8fc7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('src/main/python/data/treatment_combinations.json', 'r') as f:\n",
    "    valid_treatment_combinations = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c20be5-a000-4164-ba46-476f64e4f4be",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare propensity scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa817670-c4dd-4a4c-a43a-98801fa8e8ad",
   "metadata": {},
   "source": [
    "Exclude non covariate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bb3e60-c3fd-4bd9-844d-127a63e62d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = [\n",
    "    'hadSurvivalEvent',\n",
    "    'systemicTreatmentPlan_5-FU',\n",
    "    'systemicTreatmentPlan_oxaliplatin',\n",
    "    'systemicTreatmentPlan_irinotecan',\n",
    "    'systemicTreatmentPlan_bevacizumab',\n",
    "    'systemicTreatmentPlan_panitumumab',\n",
    "    'systemicTreatmentPlan_pembrolizumab',\n",
    "    'systemicTreatmentPlan_nivolumab',\n",
    "    'hasTreatment',\n",
    "    'survivalDaysSinceMetastaticDiagnosis',\n",
    "    'investigatedLymphNodesCountPrimaryDiagnosis',\n",
    "    'hasRasMutation'\n",
    "]\n",
    "\n",
    "df_covariate = df_all.copy()\n",
    "\n",
    "#df_covariate[\"hasInvestigatedLymphNodes\"] = (\n",
    "#    df_covariate[\"investigatedLymphNodesCountPrimaryDiagnosis\"] > 0\n",
    "#)\n",
    "\n",
    "df_covariate = df_covariate.drop(columns=exclude, errors='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4222f9e4-1a12-4e3b-9c67-2af206247e96",
   "metadata": {},
   "source": [
    "Create treatment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6abf6a7-a8e8-4ac4-9df9-9b2a19684ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "treatment_prefix = \"systemicTreatmentPlan_\"\n",
    "treatment_cols = [col for col in df_all.columns if col.startswith(treatment_prefix)]\n",
    "\n",
    "def extract_actual_treatment(row):\n",
    "    actual_treatments = [col for col in treatment_cols if row[col] == 1]\n",
    "    if actual_treatments:\n",
    "        return \", \".join([col.replace(treatment_prefix, \"\") for col in actual_treatments])\n",
    "    else:\n",
    "        return \"No Treatment\"\n",
    "\n",
    "df_all[\"actual_treatment\"] = df_all.apply(extract_actual_treatment, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f277a100-76d9-4799-8cb9-ae29337aa7a8",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea5032f-ed3d-498f-8099-e09b9497b760",
   "metadata": {},
   "source": [
    "Model trained on all data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e583dcde-dc62-4b4e-9c96-26d81038685c",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Prepare treatments and covariates\n",
    "treatments = pd.Categorical(df_all[\"actual_treatment\"])  # treat as categorical\n",
    "treatments_encoded = treatments.codes                             # integer-encoded labels\n",
    "treatment_labels = treatments.categories                 # original treatment names\n",
    "\n",
    "covariates = df_covariate.copy()\n",
    "covariates_encoded = pd.get_dummies(covariates, drop_first=True)\n",
    "\n",
    "# 2. Drop constant columns (needed before scaling)\n",
    "constant_cols = covariates_encoded.columns[covariates_encoded.std() == 0]\n",
    "if len(constant_cols) > 0:\n",
    "    print(f\"Dropping constant columns: {list(constant_cols)}\")\n",
    "    covariates_encoded = covariates_encoded.drop(columns=constant_cols)\n",
    "\n",
    "# 3. Reset index for alignment\n",
    "covariates_encoded = covariates_encoded.reset_index(drop=True)\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "# 4. Build pipeline with StandardScaler and XGBClassifier\n",
    "pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"xgb\", XGBClassifier(\n",
    "        objective=\"multi:softprob\",           # output class probabilities\n",
    "        num_class=len(treatment_labels),      # number of unique treatments\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        max_depth=4,\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 5. Fit the model\n",
    "pipe.fit(covariates_train, treatments_train)\n",
    "\n",
    "# 6. Predict propensity scores\n",
    "propensity_probs = pipe.predict_proba(covariates_encoded)\n",
    "\n",
    "# 7. Add propensity scores to df_all using original treatment labels\n",
    "for i, label in enumerate(treatment_labels):\n",
    "    df_all[f\"propensity_{label}\"] = propensity_probs[:, i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9ae3f-ac4a-484d-a8a3-e36b36cc603d",
   "metadata": {},
   "source": [
    "Model trained on train data (with split test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff55064-c409-4829-b7a1-df462a4a0920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "treatments = pd.Categorical(df_all[\"actual_treatment\"])\n",
    "treatments_encoded = treatments.codes\n",
    "treatment_labels = treatments.categories\n",
    "\n",
    "covariates = df_covariate.copy()\n",
    "covariates_encoded = pd.get_dummies(covariates, drop_first=True)\n",
    "\n",
    "constant_cols = covariates_encoded.columns[covariates_encoded.std() == 0]\n",
    "if len(constant_cols) > 0:\n",
    "    print(f\"Dropping constant columns: {list(constant_cols)}\")\n",
    "    covariates_encoded = covariates_encoded.drop(columns=constant_cols)\n",
    "\n",
    "covariates_encoded = covariates_encoded.reset_index(drop=True)\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "covariates_train, covariates_test, treatments_train, treatments_test = train_test_split(\n",
    "    covariates_encoded, treatments_encoded, test_size=0.2, random_state=42, stratify=treatments_encoded\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"xgb\", XGBClassifier(\n",
    "        objective=\"multi:softprob\",      \n",
    "        num_class=len(treatment_labels),\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        max_depth=4,                     \n",
    "        n_estimators=100,                  \n",
    "        learning_rate=0.1,                 \n",
    "        subsample=0.7,                      \n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe.fit(covariates_train, treatments_train)\n",
    "\n",
    "propensity_probs = pipe.predict_proba(covariates_encoded)\n",
    "\n",
    "for i, label in enumerate(treatment_labels):\n",
    "    df_all[f\"propensity_{label}\"] = propensity_probs[:, i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dfb805-3f5c-4a86-94ca-3f38771c629f",
   "metadata": {},
   "source": [
    "# Random patient generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9bb6e7-39e9-4c18-ac05-ddfe7081aa13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "valid_ids = set(df_all['sourceId'].unique())\n",
    "\n",
    "def get_valid_random_patient_id():\n",
    "    while True:\n",
    "        random_id = random.choice(range(1, 10000000))\n",
    "        if random_id in valid_ids:\n",
    "            return random_id\n",
    "\n",
    "random_patient_id = get_valid_random_patient_id()\n",
    "print(random_patient_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608ea79-2aea-4fe2-b540-fe68e40a4fce",
   "metadata": {
    "tags": []
   },
   "source": [
    "import random\n",
    "threshold_days = 2000 \n",
    "eligible_patients = df_all[\n",
    "    (df_all['hasTreatment'] == 0) &\n",
    "    (df_all['survivalDaysSinceMetastaticDiagnosis'] > threshold_days)\n",
    "]\n",
    "\n",
    "valid_ids = set(eligible_patients['sourceId'].unique())\n",
    "\n",
    "def get_valid_random_patient_id():\n",
    "    if not valid_ids:\n",
    "        raise ValueError(\"No valid patients meet the criteria.\")\n",
    "    return random.choice(list(valid_ids))\n",
    "\n",
    "random_patient_id = get_valid_random_patient_id()\n",
    "print(random_patient_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7c463c-c0f6-48e2-8abb-18baa39564ec",
   "metadata": {},
   "source": [
    "# Personalized patient propensity score estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f518ae5-d0ee-47c0-9ef2-ecbc600b0799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "from IPython.display import display, Markdown\n",
    "import shap\n",
    "\n",
    "patient_id = random_patient_id\n",
    "row = df_all[df_all[\"sourceId\"] == patient_id]\n",
    "treatment_row = df_all[df_all[\"sourceId\"] == patient_id].squeeze()\n",
    "raw_row = df_raw[df_raw[\"sourceId\"] == patient_id].squeeze()\n",
    "\n",
    "model = pipe.named_steps[\"xgb\"]\n",
    "scaler = pipe.named_steps[\"scale\"]\n",
    "feature_names = covariates_encoded.columns\n",
    "treatment_labels = pd.Categorical(df_all[\"actual_treatment\"]).categories\n",
    "\n",
    "X_scaled = scaler.transform(covariates_encoded)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_scaled) \n",
    "\n",
    "patient_idx = df_all.index[df_all[\"sourceId\"] == patient_id][0]\n",
    "shap_patient = [sv[patient_idx] for sv in shap_values]\n",
    "base_values = explainer.expected_value\n",
    "logits = np.array([base_values[i] + shap_patient[i].sum() for i in range(len(base_values))])\n",
    "probs = np.exp(logits) / np.sum(np.exp(logits))\n",
    "\n",
    "top_two_idx = np.argsort(probs)[-2:][::-1]\n",
    "top_idx, second_idx = top_two_idx\n",
    "top_class = treatment_labels[top_idx]\n",
    "second_class = treatment_labels[second_idx]\n",
    "top_contrib = shap_patient[top_idx]\n",
    "second_contrib = shap_patient[second_idx]\n",
    "\n",
    "avg_other_contrib = np.mean([shap_patient[i] for i in range(len(treatment_labels)) if i != top_idx], axis=0)\n",
    "delta_contrib_first = top_contrib - avg_other_contrib\n",
    "delta_contrib_second = top_contrib - second_contrib\n",
    "actual_values = row[feature_names].values.flatten()\n",
    "\n",
    "df_first = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"value\": np.round(actual_values, 2),\n",
    "    \"top_contribution\": np.round(top_contrib, 2),\n",
    "    \"weighted_avg_other_contribution\": np.round(avg_other_contrib, 2),\n",
    "    \"Δ_contribution\": np.round(delta_contrib_first, 2)\n",
    "})\n",
    "df_first = df_first[df_first[\"Δ_contribution\"] > 0].sort_values(\"Δ_contribution\", ascending=False)\n",
    "\n",
    "df_second = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"value\": np.round(actual_values, 2),\n",
    "    f\"{top_class} contribution\": np.round(top_contrib, 2),\n",
    "    f\"{second_class} contribution\": np.round(second_contrib, 2),\n",
    "    \"Δ_contribution\": np.round(delta_contrib_second, 2)\n",
    "})\n",
    "df_second[\"abs_Δ_contribution\"] = df_second[\"Δ_contribution\"].abs()\n",
    "df_second = df_second.sort_values(\"abs_Δ_contribution\", ascending=False)\n",
    "\n",
    "def interpret_value(v):\n",
    "    if v == 1.0: return \"positive\"\n",
    "    if v == 0.0: return \"negative\"\n",
    "    if v > 0: return \"relatively high\"\n",
    "    if v < 0: return \"relatively low\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def get_raw_value(encoded_feature):\n",
    "    if encoded_feature in raw_row:\n",
    "        return raw_row[encoded_feature]\n",
    "    prefix = encoded_feature.split('_')[0]\n",
    "    return raw_row.get(prefix, np.nan)\n",
    "\n",
    "def prettify_feature(feat):\n",
    "    if \"_\" in feat and not feat.startswith(\"has\"):\n",
    "        base, category = feat.split(\"_\", 1)\n",
    "        base = re.sub(r'(?<!^)(?=[A-Z])', ' ', base).strip().capitalize()\n",
    "        category = category.replace(\"_\", \" \").lower().capitalize()\n",
    "        return f\"{base}: {category}\"\n",
    "    else:\n",
    "        return re.sub(r'(?<!^)(?=[A-Z])', ' ', feat).strip().capitalize()\n",
    "\n",
    "for df in [df_first, df_second]:\n",
    "    df[\"interpretation\"] = df[\"value\"].apply(interpret_value)\n",
    "    df[\"actual_value\"] = df[\"feature\"].apply(get_raw_value)\n",
    "    df[\"feature_written\"] = df[\"feature\"].apply(prettify_feature)\n",
    "\n",
    "propensity_cols = [col for col in df_all.columns if col.startswith(\"propensity_\")]\n",
    "patient_propensity = row[propensity_cols].T\n",
    "patient_propensity.columns = [\"Propensity Score\"]\n",
    "patient_propensity.index = [col.replace(\"propensity_\", \"\") for col in patient_propensity.index]\n",
    "patient_propensity[\"Propensity Score\"] = patient_propensity[\"Propensity Score\"].astype(float).round(2)\n",
    "patient_propensity = patient_propensity[patient_propensity[\"Propensity Score\"] >= 0.05]\n",
    "patient_propensity = patient_propensity.sort_values(by=\"Propensity Score\", ascending=False)\n",
    "\n",
    "treatment_cols = [col for col in treatment_row.index if col.startswith(\"systemicTreatmentPlan_\")]\n",
    "actual_treatments = [\n",
    "    col.replace(\"systemicTreatmentPlan_\", \"\")\n",
    "    for col in treatment_cols\n",
    "    if str(treatment_row[col]).strip() in {\"1\", \"1.0\", \"True\", \"true\"}\n",
    "]\n",
    "actual_treatment_str = \" + \".join(actual_treatments) if actual_treatments else \"No treatment\"\n",
    "survival_days = treatment_row.get(\"survivalDaysSinceMetastaticDiagnosis\", \"Unknown\")\n",
    "\n",
    "top_score_percent = f\"{patient_propensity.loc[top_class, 'Propensity Score'] * 100:.0f}%\" if top_class in patient_propensity.index else \"N/A\"\n",
    "if second_class in patient_propensity.index:\n",
    "    second_score_percent = f\"{patient_propensity.loc[second_class, 'Propensity Score'] * 100:.0f}%\"\n",
    "    show_second = True\n",
    "else:\n",
    "    second_score_percent = None\n",
    "    show_second = False\n",
    "\n",
    "output = [\n",
    "    f\"**Actual Treatment:** {actual_treatment_str}  \",\n",
    "    f\"**Observed Survival:** {survival_days} days\",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "output.append(f\"**{top_class}** ({top_score_percent})\")\n",
    "for _, row_ in df_first[df_first[\"Δ_contribution\"] > 0.1].iterrows():\n",
    "    output.append(f\"- **{row_['feature_written']} →** {row_['interpretation']} ({row_['actual_value']})\")\n",
    "\n",
    "if show_second:\n",
    "    output.append(\"\")\n",
    "    output.append(f\"**{second_class}** ({second_score_percent})\")\n",
    "    for _, row_ in df_second[df_second[\"Δ_contribution\"] < -0.1].iterrows():\n",
    "        output.append(f\"- **{row_['feature_written']} →** {row_['interpretation']} ({row_['actual_value']})\")\n",
    "\n",
    "output.append(\"\")\n",
    "for treatment, score in patient_propensity[\"Propensity Score\"].items():\n",
    "    if treatment not in [top_class, second_class] and score >= 0.05:\n",
    "        output.append(f\"**{treatment}** ({score * 100:.0f}%)\")\n",
    "        output.append(\"\")\n",
    "\n",
    "display(Markdown(\"\\n\".join(output)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8748ce4-503d-46e8-994c-8b08ebc15955",
   "metadata": {},
   "source": [
    "# Accuracy estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38019a93-12c7-4f74-bf35-ebf7aa207f4c",
   "metadata": {},
   "source": [
    "Based on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66fcc3-39a7-4bea-95cd-d944a23b13a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def normalize_treatment_string(treat_str):\n",
    "    if not treat_str or treat_str.strip().lower() in {\"none\", \"no treatment\"}:\n",
    "        return set()\n",
    "    parts = re.split(r\"[,+]\", treat_str)\n",
    "    return set(p.strip().lower() for p in parts if p.strip())\n",
    "\n",
    "model = pipe.named_steps[\"xgb\"]\n",
    "scaler = pipe.named_steps[\"scale\"]\n",
    "feature_names = covariates_encoded.columns\n",
    "treatment_labels = pd.Categorical(df_all[\"actual_treatment\"]).categories\n",
    "\n",
    "X_scaled = scaler.transform(covariates_encoded)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values_all = explainer.shap_values(X_scaled) \n",
    "base_values = explainer.expected_value\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, row in tqdm(df_all.iterrows(), total=len(df_all)):\n",
    "    source_id = row[\"sourceId\"]\n",
    "    \n",
    "    treatment_cols = [col for col in row.index if col.startswith(\"systemicTreatmentPlan_\")]\n",
    "    actual_treatments = [\n",
    "        col.replace(\"systemicTreatmentPlan_\", \"\")\n",
    "        for col in treatment_cols\n",
    "        if str(row[col]).strip() in {\"1\", \"1.0\", \"True\", \"true\"}\n",
    "    ]\n",
    "    actual_treatment_str = \" + \".join(actual_treatments) if actual_treatments else \"No treatment\"\n",
    "\n",
    "    shap_patient = [sv[i] for sv in shap_values_all]\n",
    "    logits = np.array([base_values[j] + shap_patient[j].sum() for j in range(len(base_values))])\n",
    "    probs = np.exp(logits) / np.sum(np.exp(logits))\n",
    "    top_idx = np.argmax(probs)\n",
    "    top_class = treatment_labels[top_idx]\n",
    "    top_prob = probs[top_idx]\n",
    "\n",
    "    predicted_set = normalize_treatment_string(top_class)\n",
    "    actual_set = normalize_treatment_string(actual_treatment_str)\n",
    "    correct = predicted_set == actual_set\n",
    "\n",
    "    results.append({\n",
    "        \"sourceId\": source_id,\n",
    "        \"predicted_treatment\": top_class,\n",
    "        \"predicted_probability\": round(top_prob, 3),\n",
    "        \"actual_treatment\": actual_treatment_str,\n",
    "        \"correct_match\": correct\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "accuracy = df_results[\"correct_match\"].mean()\n",
    "print(f\"XGBoost Model Accuracy: {accuracy:.2%} ({df_results['correct_match'].sum()}/{len(df_results)})\")\n",
    "\n",
    "df_mismatches = df_results[~df_results[\"correct_match\"]]\n",
    "display(df_mismatches.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc2c072-790e-4f66-9e40-4cd7d22ff8b5",
   "metadata": {},
   "source": [
    "Based on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b761da53-c31a-4e2f-b4e7-e788811aa096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_treatment_string(treat_str):\n",
    "    if not treat_str or treat_str.strip().lower() in {\"none\", \"no treatment\"}:\n",
    "        return set()\n",
    "    parts = re.split(r\"[,+]\", treat_str)\n",
    "    return set(p.strip().lower() for p in parts if p.strip())\n",
    "\n",
    "df_test = df_all[df_all[\"sourceId\"].isin(df_all.loc[covariates_test.index, \"sourceId\"])].reset_index(drop=True)\n",
    "X_test = covariates_test.reset_index(drop=True)\n",
    "\n",
    "model = pipe.named_steps[\"xgb\"]\n",
    "scaler = pipe.named_steps[\"scale\"]\n",
    "feature_names = covariates_encoded.columns\n",
    "treatment_labels = pd.Categorical(df_all[\"actual_treatment\"]).categories\n",
    "\n",
    "X_scaled_test = scaler.transform(X_test)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values_test = explainer.shap_values(X_scaled_test) \n",
    "base_values = explainer.expected_value\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
    "    source_id = row[\"sourceId\"]\n",
    "\n",
    "    # Actual treatment from original encoding\n",
    "    treatment_cols = [col for col in row.index if col.startswith(\"systemicTreatmentPlan_\")]\n",
    "    actual_treatments = [\n",
    "        col.replace(\"systemicTreatmentPlan_\", \"\")\n",
    "        for col in treatment_cols\n",
    "        if str(row[col]).strip() in {\"1\", \"1.0\", \"True\", \"true\"}\n",
    "    ]\n",
    "    actual_treatment_str = \" + \".join(actual_treatments) if actual_treatments else \"No treatment\"\n",
    "\n",
    "    shap_patient = [sv[i] for sv in shap_values_test]\n",
    "    logits = np.array([base_values[j] + shap_patient[j].sum() for j in range(len(base_values))])\n",
    "    probs = np.exp(logits) / np.sum(np.exp(logits))\n",
    "    top_idx = np.argmax(probs)\n",
    "    top_class = treatment_labels[top_idx]\n",
    "    top_prob = probs[top_idx]\n",
    "\n",
    "    predicted_set = normalize_treatment_string(top_class)\n",
    "    actual_set = normalize_treatment_string(actual_treatment_str)\n",
    "    correct = predicted_set == actual_set\n",
    "\n",
    "    results.append({\n",
    "        \"sourceId\": source_id,\n",
    "        \"predicted_treatment\": top_class,\n",
    "        \"predicted_probability\": round(top_prob, 3),\n",
    "        \"actual_treatment\": actual_treatment_str,\n",
    "        \"correct_match\": correct\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "accuracy = df_results[\"correct_match\"].mean()\n",
    "print(f\"XGBoost Model Accuracy (Test Set): {accuracy:.2%} ({df_results['correct_match'].sum()}/{len(df_results)})\")\n",
    "\n",
    "df_mismatches = df_results[~df_results[\"correct_match\"]]\n",
    "display(df_mismatches.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383413b-59b8-41a7-9942-fa599d34b73f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa110a64-1c51-4f01-a49c-87fe5d31eb09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_results['actual_treatment'] = df_results['actual_treatment'].str.replace(\" \\+ \", \", \").str.title()\n",
    "df_results['predicted_treatment'] = df_results['predicted_treatment'].str.title()\n",
    "\n",
    "\n",
    "cross_tab = pd.crosstab(\n",
    "    df_results['predicted_treatment'],\n",
    "    df_results['actual_treatment'],\n",
    "    normalize='index'\n",
    ") * 100\n",
    "\n",
    "\n",
    "ax = cross_tab.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "plt.ylabel('Percentage of Actual Treatments')\n",
    "plt.title('Distribution of Actual Treatments per Predicted Treatment')\n",
    "plt.legend(title='Actual Treatment', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53267019-4c52-4c1c-a4b6-1c0d482e7d4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051d5e7-ae18-4c1f-b348-2aa79a72abe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    \"xgb__n_estimators\": randint(100, 800),\n",
    "    \"xgb__max_depth\": randint(3, 10),\n",
    "    \"xgb__learning_rate\": uniform(0.01, 0.3),\n",
    "    \"xgb__subsample\": uniform(0.5, 0.5),\n",
    "    \"xgb__colsample_bytree\": uniform(0.5, 0.5),\n",
    "    \"xgb__gamma\": uniform(0, 5),\n",
    "    \"xgb__reg_lambda\": uniform(0, 5),\n",
    "    \"xgb__reg_alpha\": uniform(0, 5),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138296f-d405-48c9-b186-9a3f54e56843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"xgb\", XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=len(np.unique(treatments_encoded)),\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,               \n",
    "    scoring=\"neg_log_loss\",    \n",
    "    n_jobs=-1,\n",
    "    cv=3,                  \n",
    "    verbose=3,\n",
    "    random_state=42,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "search.fit(covariates_train, treatments_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
