{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d61ed0d-783d-45f7-99a2-f3c87dbccfc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predictive Algorithms for Survival Analysis for predicting survival days\n",
    "\n",
    "This notebook was made to test the feasability of predicting specific survival days and contains a full pipeline for training and evaluating predictive models for survival analysis. We handle both overall survival (OS) and progression‑free survival (PFS) by reusing the same functions. The pipeline loads and preprocesses data, visualizes the target distributions (before and after log transformation), displays correlation heatmaps and residual plots, evaluates a set of regression models, and performs hyperparameter optimization (using random search) for selected models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00789d13-178f-42bd-81a8-947b666139f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbff7b-ecbb-418e-83c5-84b5d19c1e48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('/data/repos/actin-personalization/prediction')\n",
    "sys.path.insert(0, os.path.abspath(\"src/main/python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b78c7cb-fe63-46a0-9873-be7edde348b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data.data_processing import DataSplitter, DataPreprocessor\n",
    "from data.lookups import LookupManager\n",
    "from utils.settings import settings\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f5b2e-bc29-4325-8a49-63bac2552dc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor(settings.db_config_path, settings.db_name)\n",
    "\n",
    "lookup_manager = LookupManager()\n",
    "features = lookup_manager.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d87935-155b-40c6-8edc-d7c8326d2ef5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "We define a function to load and prepare the data. We load the data, filter for rows with the event of interest, apply a log transformation to the survival days target, and splits the features and target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a8049d-485b-4da4-913f-510906547b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(features):\n",
    "    splitter = DataSplitter(test_size=0.1, random_state=42)\n",
    "    \n",
    "    raw_df = preprocessor.load_data()\n",
    "    raw_df = raw_df[ raw_df[settings.event_col] == 1 ].copy()\n",
    "\n",
    "    df, features, encoded_columns = preprocessor.preprocess_data(features, df=raw_df)\n",
    "\n",
    "    y_df = df[[settings.event_col, settings.duration_col]].copy()\n",
    "\n",
    "    X_train, X_test, y_train_df, y_test_df = splitter.split(df[features],y_df,encoded_columns)\n",
    "\n",
    "    y_train = y_train_df[settings.duration_col].astype(float)\n",
    "    y_test  = y_test_df [settings.duration_col].astype(float)\n",
    "\n",
    "    return df, X_train, X_test, y_train, y_test, features, encoded_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfbf72a-d031-43fe-ae55-812bb0cbef2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df, X_train, X_test, y_train, y_test, features, encoded_columns = get_data(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4020806d-93fd-4f19-b959-82123678024e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualization of Target\n",
    "\n",
    "We now visualize the distribution of the OS target before and after log transformation. This helps us understand the skewness of the data and the effect of the transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb0d7a3-27d7-4749-b6cc-86bce10e978a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def visualize_target_distribution(df, target_col):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.histplot(df[target_col], kde=True, bins=30)\n",
    "    plt.title(f\"Distribution of {target_col} (Days)\")\n",
    "    plt.xlabel(f\"{target_col} (Days)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "    log_target = np.log1p(df[target_col])\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns.histplot(log_target, kde=True, bins=30, color='green')\n",
    "    plt.title(f\"Distribution of Log-Transformed {target_col}\")\n",
    "    plt.xlabel(f\"Log({target_col} + 1)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "    return log_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4890728-6b86-41a2-a696-a6727e3d2e9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visualize_target_distribution(df, settings.duration_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc1b03-50eb-4a52-8ff2-10eabb877459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_correlation_with_target(df, target_col):\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    ignore_cols = ['hadSurvivalEvent', 'hadProgressionEvent']\n",
    "    for col in ignore_cols:\n",
    "        if col in numeric_cols:\n",
    "            numeric_cols.remove(col)\n",
    "    \n",
    "    if target_col in numeric_cols:\n",
    "        numeric_cols.remove(target_col)\n",
    "    \n",
    "    corrs = df[numeric_cols].corrwith(df[target_col]).sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(8, 12))\n",
    "    sns.barplot(x=corrs.values, y=corrs.index)\n",
    "    plt.title(f\"Correlation of Numeric Features with {target_col}\")\n",
    "    plt.xlabel(\"Correlation Coefficient\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6144f913-c0e8-4b50-a173-0afa0dab2947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_correlation_with_target(df, settings.duration_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceeb9e4-fb25-4ff1-8fc6-59924e63dde1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### KNN and Best-K Determination\n",
    "\n",
    "The function `determine_best_k_nn` runs cross‑validation over a range of K values for a K‑Nearest Neighbors regressor (using log‑transformed target values) and plots the cross‑validated negative MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82a715-9e79-4f8f-ab30-207f88ca4b06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def determine_best_k_nn(X_train, y_train, k_range):\n",
    "    scores = {}\n",
    "    for k in k_range:\n",
    "        knn = KNeighborsRegressor(n_neighbors=k)\n",
    "        cv_scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "        scores[k] = np.mean(cv_scores)\n",
    "    best_k = max(scores, key=scores.get)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(list(scores.keys()), list(scores.values()), marker='o')\n",
    "    plt.title(\"Cross-Validated Negative MSE for Different k\")\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"CV Negative MSE\")\n",
    "    plt.show()\n",
    "    return best_k, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520eeb0b-ab57-47c9-b7f7-c7b38f712d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_knn_k, knn_scores = determine_best_k_nn(X_train, y_train, range(1, 21))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787264b-b15a-4abf-808e-08e92cf49baf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Evaluation and Optimization Functions\n",
    "\n",
    "The `evaluate_models` function trains a set of models on the log-transformed target and reports performance on both the log scale and the original scale. The `optimize_model_random_search` function performs randomized hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea23aef-faba-49de-98b8-5362cd6b19bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69af702-0622-49e3-9d8c-52a2f405bb26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_models(models, X_train, X_test, y_train, y_test, label):\n",
    "    trained_models = {}\n",
    "    results = []\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse_ = mean_squared_error(y_test, y_pred)\n",
    "        r2_ = r2_score(y_test, y_pred)\n",
    "        \n",
    "        trained_models[model_name] = model\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"MSE (raw)\": mse_,\n",
    "            \"R² (raw)\": r2_\n",
    "        })\n",
    "        model.predict\n",
    "    \n",
    "    plot_best_model(models, results, X_train, X_test, y_train, y_test, label, metric = \"R² (raw)\")\n",
    "    \n",
    "    return trained_models, results\n",
    "\n",
    "def evaluate_models_logtarget(models, X_train, X_test, y_train, y_test, label):\n",
    "    trained_models = {}\n",
    "    results = []\n",
    "    \n",
    "    y_train_log = np.log1p(y_train)\n",
    "    y_test_log = np.log1p(y_test)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train_log)\n",
    "        y_pred_log = model.predict(X_test)\n",
    "        \n",
    "        mse_log = mean_squared_error(y_test_log, y_pred_log)\n",
    "        r2_log = r2_score(y_test_log, y_pred_log)\n",
    "        \n",
    "        y_pred_orig = np.expm1(y_pred_log)\n",
    "        mse_orig = mean_squared_error(y_test, y_pred_orig)\n",
    "        r2_orig = r2_score(y_test, y_pred_orig)\n",
    "        \n",
    "        trained_models[model_name] = model\n",
    "        results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"MSE (log)\": mse_log,\n",
    "            \"R² (log)\": r2_log,\n",
    "            \"MSE (orig)\": mse_orig,\n",
    "            \"R² (orig)\": r2_orig\n",
    "        })\n",
    "    \n",
    "    plot_best_model(models, results, X_train, X_test, y_train_log, y_test_log, label, metric = \"R² (orig)\")\n",
    "    \n",
    "    return trained_models, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37c1b0-0e3b-4dc6-b61b-8608e04cd60d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_predictions(y_test, y_pred, title, is_log=False):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(x=y_test, y=y_pred)\n",
    "    \n",
    "    min_val = min(y_test.min(), y_pred.min())\n",
    "    max_val = max(y_test.max(), y_pred.max())\n",
    "    \n",
    "    plt.plot([min_val, max_val], [min_val, max_val], color='red', lw=2)\n",
    "    scale_label = \"Log(Observed Days)\" if is_log else \"Observed Days\"\n",
    "    plt.xlabel(f\"Actual ({scale_label})\")\n",
    "    plt.ylabel(f\"Predicted ({scale_label})\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_residuals(y_true, y_pred, is_log=False):\n",
    "    residuals = y_true - y_pred\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.histplot(residuals, kde=True, bins=30)\n",
    "    scale_label = \"Log Scale\" if is_log else \"Raw Scale\"\n",
    "    plt.title(f\"Residuals Distribution ({scale_label})\")\n",
    "    plt.xlabel(\"Residuals\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(x=y_pred, y=residuals)\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.title(f\"Residuals vs Predicted ({scale_label})\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_best_model(models, results, X_train, X_test, y_train, y_test, label, metric = \"R²\"):\n",
    "    results_df = pd.DataFrame(results)\n",
    "    best_model_name = results_df.sort_values(by=metric, ascending=False).iloc[0][\"Model\"]\n",
    "\n",
    "    best_model = models[best_model_name]\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    plot_predictions(y_test, y_pred, f\"{best_model_name}: Predicted vs Actual {label}\")\n",
    "    plot_residuals(y_test, y_pred)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae110bf-0955-48d2-b24f-d7b7713f4068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "def r2_original_score(y_true_log, y_pred_log):\n",
    "    y_true_orig = np.expm1(y_true_log)\n",
    "    y_pred_orig = np.expm1(y_pred_log)\n",
    "    return r2_score(y_true_orig, y_pred_orig)\n",
    "\n",
    "def hyperparameter_search(model, param_dist, X_train, y_train, use_log=False, cv_folds=5, n_iter=20):\n",
    "    if use_log:\n",
    "        scoring = make_scorer(r2_original_score, greater_is_better=True)\n",
    "    else:\n",
    "        scoring = 'r2'\n",
    "        \n",
    "    random_search = RandomizedSearchCV(model, param_dist, n_iter=n_iter, cv=cv_folds,\n",
    "                                       scoring=scoring, verbose=1,\n",
    "                                       n_jobs=-1, random_state=42)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    return random_search.best_estimator_, random_search.best_params_, random_search.best_score_\n",
    "\n",
    "def optimize_models(models, X_train, y_train, use_log=False, cv_folds=5, n_iter=20):\n",
    "    optimized_results = {}\n",
    "    y_train_mod = np.log1p(y_train) if use_log else y_train\n",
    "    for model_name, model in models.items():\n",
    "        if model_name in days_param_grids:\n",
    "            param_grid = days_param_grids[model_name][0]\n",
    "            best_est, best_params, best_score = hyperparameter_search(\n",
    "                model, param_grid, X_train, y_train_mod, use_log=use_log, cv_folds=cv_folds, n_iter=n_iter\n",
    "            )\n",
    "            optimized_results[model_name] = {\n",
    "                \"best_estimator\": best_est,\n",
    "                \"best_params\": best_params,\n",
    "                \"best_score\": best_score\n",
    "            }\n",
    "            print(f\"{model_name} optimized: best_params: {best_params}, best_score (R²): {best_score}\")\n",
    "        else:\n",
    "            print(f\"No parameter grid defined for {model_name}. Skipping optimization.\")\n",
    "    return optimized_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c8e85-2729-405e-958c-ef0e49dabc01",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Full Pipeline Function\n",
    "\n",
    "The `run_pipeline` function runs the entire workflow for a given survival type (\"OS\" or \"PFS\"). It loads data, performs visualizations, evaluates models, plots predictions, and executes hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aad551-3abb-43ab-9fdb-595fbed555b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_pipeline(models,  X_train, X_test, y_train, y_test, survival_type, optimize=False):\n",
    "    if survival_type.lower() == 'os':\n",
    "        event_col = 'hadSurvivalEvent'\n",
    "        duration_col = 'observedOsFromTreatmentStartDays'\n",
    "        label = \"Observed OS\"\n",
    "    elif survival_type.lower() == 'pfs':\n",
    "        event_col = 'hadProgressionEvent'\n",
    "        duration_col = 'observedPfsDays'\n",
    "        label = \"Observed PFS\"\n",
    "    else:\n",
    "        raise ValueError(\"survival_type must be 'OS' or 'PFS'\")\n",
    "    \n",
    "    print(\"=== Evaluating Models on Raw Target ===\")\n",
    "    trained_models, results = evaluate_models(models, X_train, X_test, y_train, y_test, label)\n",
    "    print(pd.DataFrame(results))\n",
    "    \n",
    "    print(\"=== Evaluating Models on Log-Transformed Target ===\")\n",
    "    log_trained_models, log_results = evaluate_models_logtarget(models, X_train, X_test, y_train, y_test, label)\n",
    "    print(pd.DataFrame(log_results))\n",
    "    \n",
    "    if optimize:\n",
    "        print(\"\\n=== Hyperparameter Optimization for non-transformed output===\")\n",
    "        optimized_models = optimize_models(models, X_train, y_train, use_log=False, n_iter = 10)\n",
    "        print(\"Optimized Models Summary:\")\n",
    "        print(pd.DataFrame(optimized_models).T)\n",
    "        \n",
    "        print(\"\\n=== Hyperparameter Optimization for log transformed output===\")\n",
    "        optimized_models = optimize_models(models, X_train, y_train, use_log=True, n_iter = 10)\n",
    "        print(\"Optimized Models Summary:\")\n",
    "        print(pd.DataFrame(optimized_models).T)\n",
    "    \n",
    "    return trained_models, log_trained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a27d5-16dd-40eb-a277-db4ddde4b1fe",
   "metadata": {},
   "source": [
    "### Running the Pipeline\n",
    "\n",
    "Call `run_pipeline` with either `\"OS\"` or `\"PFS\"` to execute the entire workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2304ef-445b-4520-9b3d-fcf4dcb0b9f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(solver='svd', alpha= 10.0, random_state=42),\n",
    "    \"Lasso\": Lasso(max_iter=5000, alpha=1.0, random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=500, min_samples_split = 10, min_samples_leaf = 2, max_features = 'sqrt', max_depth = 20, random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"MLPRegressor\": MLPRegressor(solver = 'adam', learning_rate_init = 0.001, hidden_layer_sizes=(32,), alpha=0.001, activation='relu', random_state=42),\n",
    "    \"SVR_RBF\": SVR(gamma = 'auto', kernel='rbf', C=10.0),\n",
    "    \"XGBRegressor\": XGBRegressor(subsample = 0.6, n_estimators = 300, max_depth=5, learning_rate=0.01, random_state=42), \n",
    "    \"KNN\": KNeighborsRegressor(weights='distance', p=1, n_neighbors=9)\n",
    "}\n",
    "\n",
    "trained_models, log_trained_models = run_pipeline(models,  X_train, X_test, y_train, y_test, settings.outcome, optimize = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991fd74-ed16-46c3-97cd-2f97a90a1571",
   "metadata": {},
   "source": [
    "### Patient outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97db48b9-d60b-4028-bec0-cfc3b964b1e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_patient(model, df, features, target_col, patient_index, use_log=False):\n",
    "    patient_row = df.iloc[[patient_index]]\n",
    "    patient_features = patient_row[features]\n",
    "    \n",
    "    pred = model.predict(patient_features)\n",
    "    if use_log:\n",
    "        pred = np.expm1(pred)\n",
    "    \n",
    "    actual_value = patient_row[target_col].iloc[0]\n",
    "    \n",
    "    print(f\"--- Prediction for Patient at Index {patient_index} ---\")\n",
    "    print(\"Patient Features:\")\n",
    "    display(patient_features) \n",
    "    print(f\"\\nActual {target_col}: {actual_value}\")\n",
    "    print(f\"Predicted {target_col}: {pred[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd8f59-433e-4e50-ad03-bbfa2e9f2ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_patient(\n",
    "    model=trained_models[\"GradientBoosting\"], \n",
    "    df=df, \n",
    "    features=features, \n",
    "    target_col=settings.duration_col, \n",
    "    patient_index=12,     \n",
    "    use_log=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (prediction_env)",
   "language": "python",
   "name": "prediction_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
